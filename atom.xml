<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>lihuimintu</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-04-07T06:55:04.841Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>图</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>零拷贝</title>
    <link href="http://yoursite.com/2021/04/07/test/"/>
    <id>http://yoursite.com/2021/04/07/test/</id>
    <published>2021-04-06T16:00:00.000Z</published>
    <updated>2021-04-07T06:55:04.841Z</updated>
    
    <content type="html"><![CDATA[<p>零拷贝是指计算机在网络上发送文件时，不需要将文件内容拷贝到用户空间（User Space）而直接在内核空间（Kernel Space）中传输到网络的方式</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>阅读艾小仙的<a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA" target="_blank" rel="noopener">阿里二面：什么是mmap？</a> ，挺通俗易懂的，把之前学的零拷贝在回顾了下</p><h4 id="传统I-O"><a href="#传统I-O" class="headerlink" title="传统I/O"></a>传统I/O</h4><p>首先要对传统的IO方式有一个概念</p><p>基于传统的IO方式，底层实际上通过调用read()和write()来实现</p><p>通过read()把数据从硬盘读取到内核缓冲区，再复制到用户缓冲区；然后再通过write()写入到socket缓冲区，最后写入网卡设备。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read(file,tmp_buf,len)</span><br><span class="line">write(socket,tmp_buf,len)</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-1.png" alt></p><p>从磁盘文件读取并且通过socket写出的过程发生了4次用户态和内核态的上下文切换和4次拷贝</p><ol><li>用户进程通过read()方法向操作系统发起调用，此时上下文从用户态切换为内核态</li><li>DMA控制器把数据从硬盘中拷贝到读缓冲区</li><li>CPU把读缓冲区数据拷贝到应用缓冲区，上下文从内核态切换为用户态，read()返回</li><li>用户进程通过write()方法发起调用，上下文从用户态切换为内核态</li><li>CPU把用户缓冲区的数据拷贝到socket缓冲区</li><li>DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，write()返回</li></ol><blockquote><p>用户态、内核态指的是什么？上下文切换又是什么？</p><p>简单来说，用户空间指的就是用户进程的运行空间，内核空间就是内核的运行空间。</p><p>如果进程运行在内核空间就是内核态，运行在用户空间就是用户态。</p><p>为了安全起见，他们之间是互相隔离的，而在用户态和内核态之间的上下文切换也是比较耗时的。</p></blockquote><blockquote><p>什么又是DMA拷贝呢？</p><p>因为对于一个IO操作而言，都是通过CPU发出对应的指令来完成，但是相比CPU来说，IO的速度太慢了，CPU有大量的时间处于等待IO的状态。</p><p>因此就产生了DMA（Direct Memory Access）直接内存访问技术，本质上来说他就是一块主板上独立的芯片，通过它来进行内存和IO设备的数据传输，从而减少CPU的等待时间。</p></blockquote><h4 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h4><p>接下来有针对性的来谈谈几种常见的零拷贝技术</p><h5 id="mmap-write"><a href="#mmap-write" class="headerlink" title="mmap+write"></a>mmap+write</h5><p>简单来说就是使用mmap替换了read+write中的read操作，减少了一次CPU的拷贝。</p><p>mmap主要实现方式是将读缓冲区的地址和用户缓冲区的地址进行映射，内核缓冲区和应用缓冲区共享，从而减少了从读缓冲区到用户缓冲区的一次CPU拷贝。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp_buf &#x3D; mmap(file, len);</span><br><span class="line">write(socket, tmp_buf, len);</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-2.png" alt></p><p>整个过程发生了4次用户态和内核态的上下文切换和3次拷贝</p><ol><li>用户进程通过mmap()方法向操作系统发起调用，上下文从用户态转向内核态</li></ol><h5 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h5><p>相比mmap来说，sendfile同样减少了一次CPU拷贝，而且还减少了2次上下文切换。</p><p>sendfile是Linux2.1内核版本后引入的一个系统调用函数，通过使用sendfile数据可以直接在内核空间进行传输，因此避免了用户空间和内核空间的拷贝，同时由于使用sendfile替代了read+write从而节省了一次系统调用，也就是2次上下文切换。</p><p><img src="/images/blog/2021-04-05-3.png" alt></p><p>整个过程发生了2次用户态和内核态的上下文切换和3次拷贝，具体流程如下：</p><ol><li>用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态切换为内核态</li><li>DMA控制器把数据从硬盘中拷贝到读缓冲区</li><li>CPU将读缓冲区中数据拷贝到socket缓冲区</li><li>DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换为用户态，sendfile调用返回</li></ol><p><strong>sendfile方法IO数据对用户空间完全不可见，所以只能适用于完全不需要用户空间处理的情况，比如静态文件服务器。</strong></p><h5 id="sendfile-DMA-Scatter-Gather"><a href="#sendfile-DMA-Scatter-Gather" class="headerlink" title="sendfile+DMA Scatter/Gather"></a>sendfile+DMA Scatter/Gather</h5><p>Linux2.4内核版本之后对sendfile做了进一步优化，通过引入新的硬件支持，这个方式叫做DMA Scatter/Gather 分散/收集功能。</p><p>将读缓冲区中的数据描述信息–内存地址和偏移量记录到socket缓冲区，由 DMA 根据这些将数据从读缓冲区拷贝到网卡，相比之前版本减少了一次CPU拷贝的过程</p><blockquote><p>之前是把读缓冲区的数据拷贝到socket缓存中，实际上，仅仅需要把读缓冲区描述符传到socket缓冲区，再把数据长度传过去，这样DMA控制器直接将页缓存中的数据打包发送到网络中就可以了。</p></blockquote><p>依旧是系统调用sendfile()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sendfile(socket, file, len);</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-4.png" alt></p><ol><li>用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态转向内核态</li><li>DMA控制器利用scatter把数据从硬盘中拷贝到读缓冲区离散存储</li><li>CPU把读缓冲区中的文件描述符和数据长度发送到socket缓冲区</li><li>DMA控制器根据文件描述符和数据长度，使用scatter/gather把数据从内核缓冲区拷贝到网卡</li><li>sendfile()调用返回，上下文从内核态切换回用户态</li></ol><p>DMA gather和sendfile一样数据对用户空间不可见，而且需要硬件支持，同时输入文件描述符只能是文件，但是过程中完全没有CPU拷贝过程，极大提升了性能。</p><blockquote><p>这种模式实现起来需要硬件的支持，但对于基于操作系统的用户来讲，操作系统已经屏蔽了这种差异，它会根据不同的硬件平台来实现这个系统调用</p></blockquote><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>RocketMQ和Kafka都使用到了零拷贝的技术</p><p>对于MQ而言，无非就是生产者发送数据到MQ然后持久化到磁盘，之后消费者从MQ读取数据。</p><p>对于RocketMQ来说这两个步骤使用的是mmap+write，而Kafka则是使用mmap+write持久化数据，发送数据使用sendfile。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>由于CPU和IO速度的差异问题，产生了DMA技术，通过DMA搬运来减少CPU的等待时间。</p><p>传统的IO read+write方式会产生2次DMA拷贝+2次CPU拷贝，同时有4次上下文切换。</p><p>而通过mmap+write方式则产生2次DMA拷贝+1次CPU拷贝，4次上下文切换，通过内存映射减少了一次CPU拷贝，可以减少内存使用，适合大文件的传输。</p><p>sendfile方式是新增的一个系统调用函数，产生2次DMA拷贝+1次CPU拷贝，但是只有2次上下文切换。因为只有一次调用，减少了上下文的切换，但是用户空间对IO数据不可见，适用于静态文件服务器。</p><p>sendfile+DMA gather方式产生2次DMA拷贝，没有CPU拷贝，而且也只有2次上下文切换。虽然极大地提升了性能，但是需要依赖新的硬件设备支持。</p><hr><p>参考链接</p><ul><li><a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA" target="_blank" rel="noopener">阿里二面：什么是mmap？</a></li><li><a href="https://www.jianshu.com/p/497e7640b57c" target="_blank" rel="noopener">零拷贝的原理及Java实现</a></li></ul>]]></content>
    
    <summary type="html">
    
      零拷贝技术
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>零拷贝</title>
    <link href="http://yoursite.com/2021/04/05/zero-copy/"/>
    <id>http://yoursite.com/2021/04/05/zero-copy/</id>
    <published>2021-04-04T16:00:00.000Z</published>
    <updated>2021-04-07T06:55:04.839Z</updated>
    
    <content type="html"><![CDATA[<p>指计算机在网络上发送文件时，不需要将文件内容拷贝到用户空间（User Space）而直接在内核空间（Kernel Space）中传输到网络的方式</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>阅读艾小仙的<a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA" target="_blank" rel="noopener">阿里二面：什么是mmap？</a> ，挺通俗易懂的，把之前学的零拷贝在回顾了下</p><h4 id="传统I-O"><a href="#传统I-O" class="headerlink" title="传统I/O"></a>传统I/O</h4><p>首先要对传统的IO方式有一个概念</p><p>基于传统的IO方式，底层实际上通过调用read()和write()来实现</p><p>通过read()把数据从硬盘读取到内核缓冲区，再复制到用户缓冲区；然后再通过write()写入到socket缓冲区，最后写入网卡设备。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read(file,tmp_buf,len)</span><br><span class="line">write(socket,tmp_buf,len)</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-1.png" alt></p><p>从磁盘文件读取并且通过socket写出的过程发生了4次用户态和内核态的上下文切换和4次拷贝</p><ol><li>用户进程通过read()方法向操作系统发起调用，此时上下文从用户态切换为内核态</li><li>DMA控制器把数据从硬盘中拷贝到读缓冲区</li><li>CPU把读缓冲区数据拷贝到应用缓冲区，上下文从内核态切换为用户态，read()返回</li><li>用户进程通过write()方法发起调用，上下文从用户态切换为内核态</li><li>CPU把用户缓冲区的数据拷贝到socket缓冲区</li><li>DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，write()返回</li></ol><blockquote><p>用户态、内核态指的是什么？上下文切换又是什么？</p><p>简单来说，用户空间指的就是用户进程的运行空间，内核空间就是内核的运行空间。</p><p>如果进程运行在内核空间就是内核态，运行在用户空间就是用户态。</p><p>为了安全起见，他们之间是互相隔离的，而在用户态和内核态之间的上下文切换也是比较耗时的。</p></blockquote><blockquote><p>什么又是DMA拷贝呢？</p><p>因为对于一个IO操作而言，都是通过CPU发出对应的指令来完成，但是相比CPU来说，IO的速度太慢了，CPU有大量的时间处于等待IO的状态。</p><p>因此就产生了DMA（Direct Memory Access）直接内存访问技术，本质上来说他就是一块主板上独立的芯片，通过它来进行内存和IO设备的数据传输，从而减少CPU的等待时间。</p></blockquote><h4 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h4><p>接下来有针对性的来谈谈几种常见的零拷贝技术</p><h5 id="mmap-write"><a href="#mmap-write" class="headerlink" title="mmap+write"></a>mmap+write</h5><p>简单来说就是使用mmap替换了read+write中的read操作，减少了一次CPU的拷贝。</p><p>mmap主要实现方式是将读缓冲区的地址和用户缓冲区的地址进行映射，内核缓冲区和应用缓冲区共享，从而减少了从读缓冲区到用户缓冲区的一次CPU拷贝。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp_buf &#x3D; mmap(file, len);</span><br><span class="line">write(socket, tmp_buf, len);</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-2.png" alt></p><p>整个过程发生了4次用户态和内核态的上下文切换和3次拷贝</p><ol><li>用户进程通过mmap()方法向操作系统发起调用，上下文从用户态转向内核态</li></ol><h5 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h5><p>相比mmap来说，sendfile同样减少了一次CPU拷贝，而且还减少了2次上下文切换。</p><p>sendfile是Linux2.1内核版本后引入的一个系统调用函数，通过使用sendfile数据可以直接在内核空间进行传输，因此避免了用户空间和内核空间的拷贝，同时由于使用sendfile替代了read+write从而节省了一次系统调用，也就是2次上下文切换。</p><p><img src="/images/blog/2021-04-05-3.png" alt></p><p>整个过程发生了2次用户态和内核态的上下文切换和3次拷贝，具体流程如下：</p><ol><li>用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态切换为内核态</li><li>DMA控制器把数据从硬盘中拷贝到读缓冲区</li><li>CPU将读缓冲区中数据拷贝到socket缓冲区</li><li>DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换为用户态，sendfile调用返回</li></ol><p><strong>sendfile方法IO数据对用户空间完全不可见，所以只能适用于完全不需要用户空间处理的情况，比如静态文件服务器。</strong></p><h5 id="sendfile-DMA-Scatter-Gather"><a href="#sendfile-DMA-Scatter-Gather" class="headerlink" title="sendfile+DMA Scatter/Gather"></a>sendfile+DMA Scatter/Gather</h5><p>Linux2.4内核版本之后对sendfile做了进一步优化，通过引入新的硬件支持，这个方式叫做DMA Scatter/Gather 分散/收集功能。</p><p>将读缓冲区中的数据描述信息–内存地址和偏移量记录到socket缓冲区，由 DMA 根据这些将数据从读缓冲区拷贝到网卡，相比之前版本减少了一次CPU拷贝的过程</p><blockquote><p>之前是把读缓冲区的数据拷贝到socket缓存中，实际上，仅仅需要把读缓冲区描述符传到socket缓冲区，再把数据长度传过去，这样DMA控制器直接将页缓存中的数据打包发送到网络中就可以了。</p></blockquote><p>依旧是系统调用sendfile()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sendfile(socket, file, len);</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-4.png" alt></p><ol><li>用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态转向内核态</li><li>DMA控制器利用scatter把数据从硬盘中拷贝到读缓冲区离散存储</li><li>CPU把读缓冲区中的文件描述符和数据长度发送到socket缓冲区</li><li>DMA控制器根据文件描述符和数据长度，使用scatter/gather把数据从内核缓冲区拷贝到网卡</li><li>sendfile()调用返回，上下文从内核态切换回用户态</li></ol><p>DMA gather和sendfile一样数据对用户空间不可见，而且需要硬件支持，同时输入文件描述符只能是文件，但是过程中完全没有CPU拷贝过程，极大提升了性能。</p><blockquote><p>这种模式实现起来需要硬件的支持，但对于基于操作系统的用户来讲，操作系统已经屏蔽了这种差异，它会根据不同的硬件平台来实现这个系统调用</p></blockquote><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>RocketMQ和Kafka都使用到了零拷贝的技术</p><p>对于MQ而言，无非就是生产者发送数据到MQ然后持久化到磁盘，之后消费者从MQ读取数据。</p><p>对于RocketMQ来说这两个步骤使用的是mmap+write，而Kafka则是使用mmap+write持久化数据，发送数据使用sendfile。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>由于CPU和IO速度的差异问题，产生了DMA技术，通过DMA搬运来减少CPU的等待时间。</p><p>传统的IO read+write方式会产生2次DMA拷贝+2次CPU拷贝，同时有4次上下文切换。</p><p>而通过mmap+write方式则产生2次DMA拷贝+1次CPU拷贝，4次上下文切换，通过内存映射减少了一次CPU拷贝，可以减少内存使用，适合大文件的传输。</p><p>sendfile方式是新增的一个系统调用函数，产生2次DMA拷贝+1次CPU拷贝，但是只有2次上下文切换。因为只有一次调用，减少了上下文的切换，但是用户空间对IO数据不可见，适用于静态文件服务器。</p><p>sendfile+DMA gather方式产生2次DMA拷贝，没有CPU拷贝，而且也只有2次上下文切换。虽然极大地提升了性能，但是需要依赖新的硬件设备支持。</p><hr><p>参考链接</p><ul><li><a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA" target="_blank" rel="noopener">阿里二面：什么是mmap？</a></li><li><a href="https://www.jianshu.com/p/497e7640b57c" target="_blank" rel="noopener">零拷贝的原理及Java实现</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;指计算机在网络上发送文件时，不需要将文件内容拷贝到用户空间（User Space）而直接在内核空间（Kernel Space）中传输到网络的方式&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka topic leader 均衡</title>
    <link href="http://yoursite.com/2021/03/10/kafka-leader-reassign/"/>
    <id>http://yoursite.com/2021/03/10/kafka-leader-reassign/</id>
    <published>2021-03-09T16:00:00.000Z</published>
    <updated>2021-03-19T07:54:56.657Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka常见痛点及优化方案</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>在创建一个topic时，partition会在Broker集群上均分，每个partition的所有replicas叫做”assigned replicas”，”assigned replicas”中的第一个replicas叫”preferred replica”。</p><p>刚创建的topic一般”preferred replica”是leader。leader replica负责所有的读写。</p><p>随着时间推移，broker可能会停机，会导致leader迁移，导致机群的负载不均衡。需要对topic的leader进行重新负载均衡，让partition选择”preferred replica”做为leader。</p><p>简单来说：leader 均衡就是让topic 的分区leader 选择的是优先副本</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>先查看 topic 情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic logdata-es</span><br></pre></td></tr></table></figure><p>生成主题列表 json 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;partitions&quot;:</span><br><span class="line">  [</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 0&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 1&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 2&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 3&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 4&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 5&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行均衡</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-preferred-replica-election.sh --zookeeper 127.0.0.1:2181 --path-to-json-file logdata-es-autu.json</span><br></pre></td></tr></table></figure><p>再查看 topic 情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic logdata-es</span><br></pre></td></tr></table></figure><p>Kafka 有个参数可以控制优先副本选举，即<code>auto.leader.rebalance.enable</code>参数，可以使得Kafka集群自动平衡Leader，只需要在server.properties文件中配置如下设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">leader.imbalance.check.interval.seconds&#x3D;300 ,每个300秒检查leader的负载均衡情况</span><br><span class="line">leader.imbalance.per.broker.percentage&#x3D;10，不平衡性超过阈值就自动触发负载均衡</span><br><span class="line">auto.leader.rebalance.enable&#x3D;true ，默认是开启的</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Kafka是允许分区保持一定的不均衡的，单个topic的优先副本均衡，也并不能代表整个集群的优先副本均衡</p><p>对于手动执行优先副本选举，也建议采取分批次的方式进行，避免同时进行多个大数据量topic的优先副本选举。</p><hr><p>参考链接</p><ul><li><a href="https://sukbeta.github.io/kafka-auto-loadblance-leader/" target="_blank" rel="noopener">kafka对topic leader 进行自动负载均衡</a></li><li><a href="https://blog.csdn.net/data2tech/article/details/108730602" target="_blank" rel="noopener">Kafka优先副本选举</a></li><li><a href="https://blog.csdn.net/qq_29493353/article/details/88532089" target="_blank" rel="noopener">Kafka集群Leader均衡(Balancing leadership)</a></li><li><a href="https://cloud.tencent.com/developer/article/1496413" target="_blank" rel="noopener">Kafka集群平滑扩容及Leader均衡【实战笔记】</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 痛点及优化方案
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 分区迁移</title>
    <link href="http://yoursite.com/2021/02/14/kafka-partition-migration/"/>
    <id>http://yoursite.com/2021/02/14/kafka-partition-migration/</id>
    <published>2021-02-13T16:00:00.000Z</published>
    <updated>2021-03-10T14:50:00.136Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka集群扩容后将数据量大Topic迁移到新的Kafka节点上</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>最近因数据量上涨，对Kafka集群进行扩容后，需将Topic量大的迁移到新Kafka节点上，缓解集群压力。</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>Kafka系统提供了一个分区重新分配工具（kafka-reassign-partitions.sh），该工具可用于在Broker之间迁移分区。</p><h5 id="生成待迁移topic的json"><a href="#生成待迁移topic的json" class="headerlink" title="生成待迁移topic的json"></a>生成待迁移topic的json</h5><p>新建文件topics-to-move.json，包含要迁移到Topic 列表。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat topic-to-move.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;topics&quot;: [&#123;&quot;topic&quot;: &quot;ke01&quot;&#125;,&#123;&quot;topic&quot;: &quot;ke02&quot;&#125;],</span><br><span class="line">    &quot;version&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="generate生成迁移计划"><a href="#generate生成迁移计划" class="headerlink" title="generate生成迁移计划"></a>generate生成迁移计划</h5><p>需要指定topics-to-move.json 文件和迁移目标节点的broker id</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist --topics-to-move-json-file topics-to-move.json --broker-list &quot;$brokerlist&quot; --generate &gt; generate.json</span><br></pre></td></tr></table></figure><p>查看generate.json文件结果类似如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Current partition replica assignment</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[61,62]&#125;,&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[62,61]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[140,141]&#125;,&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[141,140]&#125;]&#125;</span><br></pre></td></tr></table></figure><p>将Current partition replica assignment 的内容保存到rollback-cluster-reassignment.json，用于回滚操作。</p><p>将Proposed partition reassignment configuration 的内容保存到expand-cluster-reassignment.json，用于执行迁移操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat generate.json  |grep -A1 &quot;Proposed partition reassignment configuration&quot; |tail -1 &gt; expand-cluster-reassignment.json</span><br></pre></td></tr></table></figure><h5 id="迁移执行generate-prop-json"><a href="#迁移执行generate-prop-json" class="headerlink" title="迁移执行generate_prop.json"></a>迁移执行generate_prop.json</h5><p>限制带宽大小为500Mb/s</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist --reassignment-json-file generate_prop.json --execute --throttle 50000000</span><br></pre></td></tr></table></figure><p>迁移操作会将指定Topic 的数据文件移动到新的节点目录下，这个过程可能需要等待很长时间，视Topic 的数据量而定。</p><p>可以运行以下命令查看执行状态。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist  --reassignment-json-file generate_prop.json --verify</span><br></pre></td></tr></table></figure><p>状态有两种，in progress 表示正在迁移，completed successlly 表示已经成功完成迁移。迁移完成后，原先的节点下将不存在该Topic 的数据文件。</p><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>如果要迁移的Topic 有大量数据（Topic 默认保留1天的数据），可以在迁移之前临时动态地调整retention.ms 来减少数据。</p><hr><p>参考链接</p><ul><li><a href="https://www.jianshu.com/p/626b147821cd" target="_blank" rel="noopener">Kafka扩容节点和分区迁移</a></li><li><a href="https://www.cnblogs.com/smartloli/p/10551165.html" target="_blank" rel="noopener">Kafka数据迁移</a></li><li><a href="https://objcoding.com/2019/10/26/kafka-expansion/" target="_blank" rel="noopener">记一次Kafka集群线上扩容</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 分区迁移
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 分区策略</title>
    <link href="http://yoursite.com/2021/02/14/kafka-partition-strategy/"/>
    <id>http://yoursite.com/2021/02/14/kafka-partition-strategy/</id>
    <published>2021-02-13T16:00:00.000Z</published>
    <updated>2021-02-14T13:19:32.680Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 分区策略</p><hr><h4 id="生产者分区选择配策略"><a href="#生产者分区选择配策略" class="headerlink" title="生产者分区选择配策略"></a>生产者分区选择配策略</h4><p>生产者在将消息发送到某个Topic，需要经过拦截器、序列化器和分区器（Partitioner）的一系列作用之后才能发送到对应的Broker，在发往Broker之前是需要确定它所发往的分区。</p><p>生产端将消息发送给Broker之前，会将producer发送的数据封装成一个 ProducerRecord 对象。是否依赖分区器看partition字段有无指定。</p><p><img src="/images/blog/2021-02-14-1.png" alt></p><p>是否依赖分区器看partition字段有无指定</p><ul><li>如果消息 ProducerRecord 指定了 partition 字段，那么就不需要分区器。</li><li>如果消息 ProducerRecord 没有指定 partition 字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。</li></ul><p>Kafka 中提供的默认分区器是 <a href="https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/DefaultPartitioner.java" target="_blank" rel="noopener">DefaultPartitioner</a> ，它实现了Partitioner接口（用户可以实现这个接口来自定义分区器）</p><p>用户可以通过实现kafka.producer.Partitioner接口实现自己的分区类（重载并实现partition方法），在生产端添加配置<code>partitioner.class</code>即可使用</p><blockquote><ul><li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值。</li><li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值。</li><li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</li><li>既没有 partition 值又指定了自定义的分区类，则按自定义分区类来得到 partition 值</li></ul></blockquote><h4 id="消费者分区分配策略"><a href="#消费者分区分配策略" class="headerlink" title="消费者分区分配策略"></a>消费者分区分配策略</h4><p>消费者以组的名义订阅主题，主题有多个分区，消费者组中有多个消费者实例，<strong>同一时刻，一条消息只能被组中的一个消费者实例消费</strong></p><ul><li>如果分区数大于或者等于组中的消费者实例数，一个消费者会负责多个分区</li><li>如果分区数小于组中的消费者实例数，有些消费者将处于空闲状态并且无法接收消息</li></ul><blockquote><p>如果多个消费者负责同一个分区，那么就意味着两个消费者同时读取分区的消息，由于消费者自己可以控制读取消息的Offset，就有可能C1才读到2，而C1读到1，C1还没处理完，C2已经读到3了，这就相当于多线程读取同一个消息，会造成消息处理的重复，且不能保证消息的顺序。</p></blockquote><p>在 Kafka 中存在着两种分区分配策略，通过 partition.assignment.strategy 来设置。</p><ul><li>RangeAssignor 范围分区策略，也是默认模式。</li><li>RoundRobinAssignor 分配策略，轮询分区模式。</li></ul><h5 id="RangeAssignor"><a href="#RangeAssignor" class="headerlink" title="RangeAssignor"></a>RangeAssignor</h5><p>range （默认分配策略）对应的实现类是 org.apache.kafka.clients.consumer.RangeAssignor</p><ol><li>将分区按数字顺序排行序，消费者按名称的字典序排序</li><li>用分区总数除以消费者总数。如果能够除尽，平均分配；若除不尽，则位于排序前面的消费者将多负责一个分区</li></ol><p>假如现在有 10 个分区，3 个消费者，排序后的分区将会是p0~p9。消费者排序完之后将会是C1-0、C2-0、C3-0。通过 Partitions数 / Consumer数 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C1-0</td><td>消费 0、1、2、3分区</td></tr><tr><td>C2-0</td><td>消费 4、5、6分区</td></tr><tr><td>C3-0</td><td>消费 7、8、9分区</td></tr></tbody></table><blockquote><p>Range 范围分区的弊端: </p><p>如上只是针对 1 个 topic 而言，C1-0 消费者多消费1个分区影响不是很大。如果有 N 多个 topic，那么针对每个 topic，消费者 C1-0 都将多消费 1 个分区，topic越多，C1-0 消费的分区会比其他消费者明显多消费 N 个分区。这就是 Range 范围分区的一个很明显的弊端了.</p></blockquote><h5 id="RoundRobinAssignor"><a href="#RoundRobinAssignor" class="headerlink" title="RoundRobinAssignor"></a>RoundRobinAssignor</h5><p>RoundRobin基于轮询算法，对应的实现类是 org.apache.kafka.clients.consumer.RoundRobinAssignor</p><ol><li>将所有主题的分区组成TopicAndPartition列表</li><li>对TopicAndPartition列表按照hashCode进行排序某个topic</li><li>最后通过轮询算法来分配 partition 给到各个消费者</li></ol><p>轮询分区分为如下两种情况：</p><ul><li>同一个 Consumer Group 内 Consumer  订阅信息相同</li><li>同一个 Consumer Group 内 Consumer  订阅信息不相同</li></ul><h6 id="订阅信息相同"><a href="#订阅信息相同" class="headerlink" title="订阅信息相同"></a>订阅信息相同</h6><p>如果同一消费组内，所有的消费者订阅的消息都是相同的，那么 RoundRobin 策略的分区分配会是均匀的。</p><p>例如同一消费者组中，有 3 个消费者C0、C1和C2，都订阅了 2 个主题 t0 和 t1，并且每个主题都有 3 个分区(p0、p1、p2)，那么所订阅的所以分区可以标识为t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。</p><p>最终分区分配结果如下</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C0</td><td>消费 t0p0、t1p0 分区</td></tr><tr><td>C1</td><td>消费 t0p1、t1p1 分区</td></tr><tr><td>C2</td><td>消费 t0p2、t1p2 分区</td></tr></tbody></table><h5 id="订阅信息不相同"><a href="#订阅信息不相同" class="headerlink" title="订阅信息不相同"></a>订阅信息不相同</h5><p>同一消费者组内，所订阅的消息是不相同的，那么分区分配就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个 topic，那么在分配分区的时候，此消费者将不会分配到这个 topic 的任何分区。</p><p>例如同一消费者组中有3个消费者C0、C1、C2，他们共订阅了 3 个主题t0、t1、t2，这 3 个主题分别有 1、2、3 个分区(即t0有1个分区(p0)，t1有2个分区(p0、p1)，t2有3个分区(p0、p1、p2))，即整个消费者所订阅的所有分区可以标识为 t0p0、t1p0、t1p1、t2p0、t2p1、t2p2。然后消费者 C0 订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2</p><p>最终分区分配结果如下</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C0</td><td>消费 t0p0 分区</td></tr><tr><td>C1</td><td>消费 t1p0 分区</td></tr><tr><td>C2</td><td>消费 t1p1、 t2p0、 t2p1、 t2p2 分区</td></tr></tbody></table><hr><p>参考链接</p><ul><li><a href="https://www.jianshu.com/p/99b4187a994d" target="_blank" rel="noopener">Kafka分区策略</a></li><li><a href="https://mp.weixin.qq.com/s/st-7k7WH5pvLZwA_o9jPpw" target="_blank" rel="noopener">六问 Kafka 为啥那么牛！</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 分区策略
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>滴滴开源 Logi-KafkaManager</title>
    <link href="http://yoursite.com/2021/02/11/didi-Logi-KafkaManager/"/>
    <id>http://yoursite.com/2021/02/11/didi-Logi-KafkaManager/</id>
    <published>2021-02-10T16:00:00.000Z</published>
    <updated>2021-02-10T16:25:22.457Z</updated>
    
    <content type="html"><![CDATA[<p>LogI-KafkaManager脱胎于滴滴内部多年的Kafka运营实践经验，是面向Kafka用户、Kafka运维人员打造的共享多租户Kafka云平台</p><hr><h4 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h4><p>文章介绍：</p><ul><li><a href="https://mp.weixin.qq.com/s/ebUY-9WCt05qDX4jet6Enw" target="_blank" rel="noopener">滴滴Logi-KafkaManager开源之路：一站式Kafka集群指标监控与运维管控平台</a></li><li><a href="https://mp.weixin.qq.com/s/JmVrypgR5mI8GH7BvgEs_g" target="_blank" rel="noopener">滴滴开源Logi-KafkaManager 一站式Kafka监控与管控平台</a></li></ul><p>GitHub地址：<a href="https://github.com/didi/Logi-KafkaManager" target="_blank" rel="noopener">Logi-KafkaManager</a></p>]]></content>
    
    <summary type="html">
    
      一站式Kafka集群指标监控与运维管控平台
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 文件存储机制</title>
    <link href="http://yoursite.com/2021/02/10/Kafka-storage-mechanism/"/>
    <id>http://yoursite.com/2021/02/10/Kafka-storage-mechanism/</id>
    <published>2021-02-09T16:00:00.000Z</published>
    <updated>2021-02-14T08:34:12.584Z</updated>
    
    <content type="html"><![CDATA[<p>从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。</p><hr><h4 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h4><p>在美团上看到一个介绍Kafka 文件存储机制的文章感觉挺好的，适合新手阅读。</p><p>详细见<a href="https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html" target="_blank" rel="noopener">《Kafka文件存储机制那些事》</a></p><blockquote><p>PS：链接中说segment文件命名规则是19位数字字符长度，本人查看已部署的kafka服务确认为20个字符长度</p></blockquote><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>Kafka高效文件存储设计特点</p><ul><li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li><li>通过索引信息可以快速定位message和确定response的最大大小。</li><li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li><li>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 文件存储机制
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Shell 2&gt;&amp;1 用法</title>
    <link href="http://yoursite.com/2021/01/25/Linux-Shell-redirection/"/>
    <id>http://yoursite.com/2021/01/25/Linux-Shell-redirection/</id>
    <published>2021-01-24T16:00:00.000Z</published>
    <updated>2021-01-26T14:10:05.086Z</updated>
    
    <content type="html"><![CDATA[<p>Shell 2&gt;&amp;1 用法</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>在Shell脚本中，默认情况下，总是有三个文件处于打开状态，标准输入(键盘输入)、标准输出（输出到屏幕）、标准错误（也是输出到屏幕），它们分别对应的文件描述符是0，1，2 。</p><p>&gt;  默认为标准输出重定向，与 1&gt; 相同</p><p>2&gt;&amp;1  意思是把 标准错误输出 重定向到 标准输出</p><p>同理 1&gt;&amp;2 意思是将标准输出 重定向到 标准错误输出</p><h4 id="运用"><a href="#运用" class="headerlink" title="运用"></a>运用</h4><p>遇到一个问题需要批量扫描机器的JDK版本是不是为1.8的，遇到无法在’java -version’输出中使用grep和awk的情况</p><p>出现这样的问题，主要就是这些消息默认情况下转到stderr，而不是stdout。所有需要先重定向到stdout，然后才能进行此类操作。</p><p>将stderr重定向到stdout</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">java_check&#x3D;$(java -version 2&gt;&amp;1)</span><br><span class="line"></span><br><span class="line">echo $java_check | grep 1.8.0_265-b01</span><br><span class="line">OpenJDK Runtime Environment Corretto-8.265.01.1 (build 1.8.0_265-b01)</span><br></pre></td></tr></table></figure><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>&amp;&gt;file  意思是把标准输出和标准错误输出都重定向到文件file中</p><p>/dev/null是一个文件，这个文件比较特殊，所有传给它的东西它都丢弃掉</p><hr><p>参考链接</p><ul><li><a href="https://blog.csdn.net/u011630575/article/details/52151995" target="_blank" rel="noopener">Shell重定向 ＆&gt;file、2&gt;&amp;1、1&gt;&amp;2 、/dev/null的区别</a></li><li><a href="https://blog.csdn.net/ITqingliang/article/details/103733038" target="_blank" rel="noopener">不能在’java -version’输出中grep和awk</a></li></ul>]]></content>
    
    <summary type="html">
    
      Shell 2&gt;&amp;1 用法
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 光标快速移动的快捷键</title>
    <link href="http://yoursite.com/2021/01/21/Linux-shortcut-keys/"/>
    <id>http://yoursite.com/2021/01/21/Linux-shortcut-keys/</id>
    <published>2021-01-20T16:00:00.000Z</published>
    <updated>2021-01-21T14:11:14.101Z</updated>
    
    <content type="html"><![CDATA[<p>Linux 快速移动光标的快捷键</p><hr><h4 id="光标快速切换到行尾行首"><a href="#光标快速切换到行尾行首" class="headerlink" title="光标快速切换到行尾行首"></a>光标快速切换到行尾行首</h4><p>ctrl+a 行首<br>ctrl+e 行尾</p><h4 id="删除至行尾"><a href="#删除至行尾" class="headerlink" title="删除至行尾"></a>删除至行尾</h4><p>ctrl+k</p><h4 id="左-右移动一个单词"><a href="#左-右移动一个单词" class="headerlink" title="左|右移动一个单词"></a>左|右移动一个单词</h4><p>Esc b 左移一个单词[back]<br>Esc f 右移一个单词[forward]</p><p><strong>注意：每次按下快捷键，需抬起后再按下快捷键，方可多次移动单词</strong></p><hr><p>参考链接</p><ul><li><a href="https://blog.csdn.net/u010865136/article/details/95628409" target="_blank" rel="noopener">Linux命令行——光标快速移动的快捷键</a></li></ul>]]></content>
    
    <summary type="html">
    
      Linux 命令行执行命令时，快速移动光标可节省不少时间
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux Pmap 命令</title>
    <link href="http://yoursite.com/2021/01/08/pmap/"/>
    <id>http://yoursite.com/2021/01/08/pmap/</id>
    <published>2021-01-07T16:00:00.000Z</published>
    <updated>2021-01-08T13:36:46.714Z</updated>
    
    <content type="html"><![CDATA[<p>pmap 命令用于显示一个或多个进程的内存状态</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>pmap能更详细的查看进程内存映射情况。</p><p>pmap命令输出的内容来自于/proc/{pid}/maps和/proc/{pid}/smaps这两个文件，第一个文件包含了每段的一个大概描述，而后一个文件包含了更详细的信息。</p><h4 id="选项"><a href="#选项" class="headerlink" title="选项"></a>选项</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Usage: pmap [options] pid [pid ...]</span><br><span class="line">Options:</span><br><span class="line"> -x, --extended       show details  显示扩展格式</span><br><span class="line"> -X             show even more details</span><br><span class="line">      WARNING: format changes according to &#x2F;proc&#x2F;PID&#x2F;smaps</span><br><span class="line"> -XX             show everything the kernel provides</span><br><span class="line"> -c, --read-rc        read the default rc</span><br><span class="line"> -C, --read-rc-from&#x3D;&lt;file&gt;  read the rc from file</span><br><span class="line"> -n, --create-rc       create new default rc</span><br><span class="line"> -N, --create-rc-to&#x3D;&lt;file&gt;  create new rc to file</span><br><span class="line">      NOTE: pid arguments are not allowed with -n, -N</span><br><span class="line"> -d, --device        show the device format  显示设备格式</span><br><span class="line"> -q, --quiet         do not display header and footer</span><br><span class="line"> -p, --show-path       show path in the mapping</span><br><span class="line"> -A, --range&#x3D;&lt;low&gt;[,&lt;high&gt;] limit results to the given range</span><br><span class="line"> -h, --help   display this help and exit -V, --version output version information and exit</span><br><span class="line">For more details see pmap(1).</span><br></pre></td></tr></table></figure><h4 id="扩展和设备格式"><a href="#扩展和设备格式" class="headerlink" title="扩展和设备格式"></a>扩展和设备格式</h4><p>Address: 映像起始地址<br>Kbytes: 映像大小<br>RSS: 驻留集大小<br>Dirty: 脏页大小<br>Mode: permissions on map 映像权限: r=read, w=write, x=execute, s=shared, p=private (copy on write)<br>Mapping: 映像支持文件；[anon]为已分配内存，可以理解为匿名块；[stack]为程序堆栈<br>Offset: 文件偏移<br>Device: 设备名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@C44 ~]# pmap -d 1</span><br><span class="line">1:  init [5]          </span><br><span class="line">Address  Kbytes Mode Offset      Device  Mapping</span><br><span class="line">00934000   88 r-x-- 0000000000000000 008:00005 ld-2.3.4.so</span><br><span class="line">0094a000    4 r---- 0000000000015000 008:00005 ld-2.3.4.so</span><br><span class="line">0094b000    4 rw--- 0000000000016000 008:00005 ld-2.3.4.so</span><br><span class="line">0094e000  1188 r-x-- 0000000000000000 008:00005 libc-2.3.4.so</span><br><span class="line">00a77000    8 r---- 0000000000129000 008:00005 libc-2.3.4.so</span><br><span class="line">00a79000    8 rw--- 000000000012b000 008:00005 libc-2.3.4.so</span><br><span class="line">00a7b000    8 rw--- 0000000000a7b000 000:00000  [ anon ]</span><br><span class="line">00a85000   52 r-x-- 0000000000000000 008:00005 libsepol.so.1</span><br><span class="line">00a92000    4 rw--- 000000000000c000 008:00005 libsepol.so.1</span><br><span class="line">00a93000   32 rw--- 0000000000a93000 000:00000  [ anon ]</span><br><span class="line">00d9d000   52 r-x-- 0000000000000000 008:00005 libselinux.so.1</span><br><span class="line">00daa000    4 rw--- 000000000000d000 008:00005 libselinux.so.1</span><br><span class="line">08048000   28 r-x-- 0000000000000000 008:00005 init</span><br><span class="line">0804f000    4 rw--- 0000000000007000 008:00005 init</span><br><span class="line">084e1000   132 rw--- 00000000084e1000 000:00000  [ anon ]</span><br><span class="line">b7f5d000    8 rw--- 00000000b7f5d000 000:00000  [ anon ]</span><br><span class="line">bffee000   72 rw--- 00000000bffee000 000:00000  [ stack ]</span><br><span class="line">ffffe000    4 ----- 0000000000000000 000:00000  [ anon ]</span><br><span class="line">mapped: 1700K  writeable&#x2F;private: 276K  shared: 0K</span><br></pre></td></tr></table></figure><p>最后一行的值</p><p>mapped 表示该进程映射的虚拟地址空间大小，也就是该进程预先分配的虚拟内存大小，即ps出的vsz</p><p>writeable/private  表示进程所占用的私有地址空间大小，也就是该进程实际使用的内存大小</p><p>shared 表示进程和其他进程共享的内存大小</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@info ~]# pmap -x 1013</span><br><span class="line">1013: &#x2F;usr&#x2F;sbin&#x2F;sshd</span><br><span class="line">Address Kbytes RSS Dirty Mode Mapping</span><br><span class="line">00110000 1480 92 0 r-x- libcrypto.so.1.0.0</span><br><span class="line">00282000 80 80 80 rw-- libcrypto.so.1.0.0</span><br><span class="line">00296000 12 8 4 rw-- [ anon ]</span><br><span class="line">00299000 36 0 0 r-x- libkrb5support.so.0.1</span><br><span class="line">002a2000 4 4 4 rw-- libkrb5support.so.0.1</span><br><span class="line">002a3000 16 0 0 r-x- libplc4.so</span><br><span class="line">002a7000 4 4 4 rw-- libplc4.so</span><br><span class="line">002ab000 88 4 0 r-x- libaudit.so.1.0.0</span><br><span class="line">002c1000 4 4 4 r--- libaudit.so.1.0.0</span><br><span class="line">002c2000 4 4 4 rw-- libaudit.so.1.0.0</span><br><span class="line">002c3000 216 4 0 r-x- libgssapi_krb5.so.2.2</span><br><span class="line">002f9000 4 4 4 rw-- libgssapi_krb5.so.2.2</span><br><span class="line">002fa000 808 4 0 r-x- libkrb5.so.3.3</span><br><span class="line">003c4000 24 24 24 rw-- libkrb5.so.3.3</span><br><span class="line">003ca000 152 4 0 r-x- libk5crypto.so.3.1</span><br><span class="line">003f0000 4 4 4 rw-- libk5crypto.so.3.1</span><br><span class="line">003f1000 92 0 0 r-x- libnssutil3.so</span><br><span class="line">00408000 12 12 12 rw-- libnssutil3.so</span><br><span class="line">0040b000 12 0 0 r-x- libplds4.so</span><br><span class="line">0040e000 4 4 4 rw-- libplds4.so</span><br><span class="line"> </span><br><span class="line">--- --- --- --- ---</span><br><span class="line">total kB 8232 - - -</span><br></pre></td></tr></table></figure><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>/proc/pid/smaps各字段含义</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">01785000-017a6000 rw-p 00000000 00:00 0                                  [heap]</span><br><span class="line">Size:                132 kB</span><br><span class="line">Rss:                  12 kB</span><br><span class="line">Pss:                  12 kB</span><br><span class="line">Shared_Clean:          0 kB</span><br><span class="line">Shared_Dirty:          0 kB</span><br><span class="line">Private_Clean:         0 kB</span><br><span class="line">Private_Dirty:        12 kB</span><br><span class="line">Referenced:           12 kB</span><br><span class="line">Anonymous:            12 kB</span><br><span class="line">AnonHugePages:         0 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">KernelPageSize:        4 kB</span><br><span class="line">MMUPageSize:           4 kB</span><br></pre></td></tr></table></figure><p>见<a href="https://blog.csdn.net/u010902721/article/details/46446031" target="_blank" rel="noopener">linux /proc/pid/smaps各字段含义</a></p><hr><p>参考链接</p><ul><li><a href="https://segmentfault.com/a/1190000008125059" target="_blank" rel="noopener">Linux进程的内存使用情况</a></li><li><a href="https://www.jb51.net/article/124947.htm" target="_blank" rel="noopener">Linux性能测试 pmap命令详解</a></li></ul>]]></content>
    
    <summary type="html">
    
      pmap 命令用于显示一个或多个进程的内存状态
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 重置偏移量到某个时间点</title>
    <link href="http://yoursite.com/2020/12/31/Kafka-offset-to-datetime/"/>
    <id>http://yoursite.com/2020/12/31/Kafka-offset-to-datetime/</id>
    <published>2020-12-30T16:00:00.000Z</published>
    <updated>2021-02-14T09:00:52.692Z</updated>
    
    <content type="html"><![CDATA[<hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>有需求排查某个时间的数据是否重复，因此需要将消费者组重置到某个时间点</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>kafka-consumer-groups.sh 使用 –to-datetime 参数可以做到，需要注意这个–to-datetime是utc时间，需要减去8个小时</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group group --reset-offsets --all-topics --to-datetime 2020-12-31T02:00:00.000 --execute</span><br></pre></td></tr></table></figure><p>当然可以根据时区设置时间，以东8时区进行设置，把对应时间改为 2020-12-31T10:00:00.000+08:00</p><p>重置前有个前提是consumer group状态必须是inactive的，即不能是处于正在工作中的状态。</p><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><h5 id="Message-body"><a href="#Message-body" class="headerlink" title="Message body"></a>Message body</h5><p>Kafka从0.10.0.0版本起，在消息内新增加了个timestamp字段</p><p>时间戳的类型有两种：可以设定为producer创建消息的时间(CreateTime)，也可以设定为该消息写入Broker的时间(LogAppendTime)。默认为CreateTime，可通过参数message.timestamp.type 实现Topic级别的类型更改，Broker级别的时间戳类型参数为log.message.timestamp.type</p><p>有关Kafka Message新增时间戳的相关细节，可详见Kafka官方Doc <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-32+-+Add+timestamps+to+Kafka+message" target="_blank" rel="noopener">KIP-32 - Add timestamps to Kafka message</a></p><h5 id="Log-Segment"><a href="#Log-Segment" class="headerlink" title="Log Segment"></a>Log Segment</h5><p>从Kafka 0.10开始，对于日志文件，新增一个<code>.timeindex</code>文件，即每个Segment分别由<code>.log、.index</code>和<code>.timeindex</code>这三个文件组成。</p><p>有关Log Segment 新增.timeindex相关细节，可详见Kafka官方Doc <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-33+-+Add+a+time+based+log+index" target="_blank" rel="noopener">KIP-33 - Add a time based log index</a></p><p>Kafka API提供了一个 offsetsForTimes（Map&lt;TopicPartition, Long&gt; timestampsToSearch）方法，该方法会返回时间戳大于等于待查询时间的第一条消息对应的偏移量。</p><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>Kafka 还支持其他位移重设策略，感兴趣的可以自行阅读<a href="https://www.cnblogs.com/huxi2b/p/7284767.html" target="_blank" rel="noopener">Kafka consumer group位移重设</a></p><hr><p>参考链接</p><ul><li><a href="https://blog.csdn.net/u010003835/article/details/83314766" target="_blank" rel="noopener">Kafka-kafka 重置偏移量 ：通过 kafka-consumer-groups.sh 针对 &gt;= kafka 0.11</a></li><li><a href="https://www.cnblogs.com/tonglin0325/p/7039747.html" target="_blank" rel="noopener">Ubuntu下安装和使用zookeeper和kafka</a></li><li><a href="https://yhyr.github.io/2019/01/23/Kafka-Timestamp/" target="_blank" rel="noopener">Kafka Timestamp</a></li><li><a href="https://juejin.cn/post/6844903919424913415" target="_blank" rel="noopener">Kafka 原理和实战</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 重置偏移量到某个时间点
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 系统 inodes 资源耗尽</title>
    <link href="http://yoursite.com/2020/12/27/Linux-inodes/"/>
    <id>http://yoursite.com/2020/12/27/Linux-inodes/</id>
    <published>2020-12-26T16:00:00.000Z</published>
    <updated>2020-12-27T14:55:33.673Z</updated>
    
    <content type="html"><![CDATA[<p>inodes 资源耗尽处理</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>可以看下阮老师的文章理解下，参见<a href="https://www.ruanyifeng.com/blog/2011/12/inode.html" target="_blank" rel="noopener">理解inode</a></p><h4 id="处理"><a href="#处理" class="headerlink" title="处理"></a>处理</h4><p>马哥Linux运维有介绍相关处理方法，参见<a href="https://mp.weixin.qq.com/s/9rfSsqZdZm8QmNYn3q19gA" target="_blank" rel="noopener">Linux系统inodes资源耗尽问题</a></p>]]></content>
    
    <summary type="html">
    
      Linux 系统 inodes 资源耗尽
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 失效副本</title>
    <link href="http://yoursite.com/2020/12/24/kafka-under-replicated/"/>
    <id>http://yoursite.com/2020/12/24/kafka-under-replicated/</id>
    <published>2020-12-23T16:00:00.000Z</published>
    <updated>2020-12-24T12:55:32.522Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 失效副本</p><hr><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>每个分区的多个副本称之为AR（assigned replicas），包含至多一个leader副本和多个follower副本。与AR对应的另一个重要的概念就是ISR（in-sync replicas），ISR是指与leader副本保持同步状态的副本集合，当然leader副本本身也是这个集合中的一员。而ISR之外，也就是处于同步失败或失效状态的副本，副本对应的分区也就称之为同步失效分区，即under-replicated分区。</p><h4 id="判定"><a href="#判定" class="headerlink" title="判定"></a>判定</h4><p>怎么样判定一个分区是否有副本是处于同步失效状态的呢？从Kafka 0.9.x版本开始通过唯一的一个参数replica.lag.time.max.ms（默认大小为10,000）来控制，当ISR中的一个follower副本滞后leader副本的时间超过参数replica.lag.time.max.ms指定的值时即判定为副本失效，需要将此follower副本剔出除ISR之外。具体实现原理很简单，当follower副本将leader副本的LEO（Log End Offset，每个分区最后一条消息的位置）之前的日志全部同步时，则认为该follower副本已经追赶上leader副本，此时更新该副本的lastCaughtUpTimeMs标识。Kafka的副本管理器（ReplicaManager）启动时会启动一个副本过期检测的定时任务，而这个定时任务会定时检查当前时间与副本的lastCaughtUpTimeMs差值是否大于参数replica.lag.time.max.ms指定的值。千万不要错误的认为follower副本只要拉取leader副本的数据就会更新lastCaughtUpTimeMs，试想当leader副本的消息流入速度大于follower副本的拉取速度时，follower副本一直不断的拉取leader副本的消息也不能与leader副本同步，如果还将此follower副本置于ISR中，那么当leader副本失效，而选取此follower副本为新的leader副本，那么就会有严重的消息丢失。</p><hr><p>参考链接</p><ul><li><a href="https://www.jianshu.com/p/aed1326880f1" target="_blank" rel="noopener">Kafka解析之失效副本</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 失效副本
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka __consumer_offsets 占用磁盘空间过大处理</title>
    <link href="http://yoursite.com/2020/12/16/kafka-consumer-offsets/"/>
    <id>http://yoursite.com/2020/12/16/kafka-consumer-offsets/</id>
    <published>2020-12-15T16:00:00.000Z</published>
    <updated>2021-01-10T12:29:08.294Z</updated>
    
    <content type="html"><![CDATA[<p>__consumer_offsets 占用磁盘空间过大处理</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>生产环境上有一台Kafka机器磁盘告警，通过查看发现kafka的日志储存目录数据盘占用80%的存储，发现是__consumer_offsets的储存文件过大导致的</p><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><p>Kafka 中用于保存消费者消费位移的主题<code>__consumer_offsets</code>与普通topic在清理策略上不同，使用的就是Log Compaction策略。</p><p>Log Compaction是kafka提供的一种整理offset数据的方式。Log Compaction对于有相同key的的不同value值，只保留最后一个版本。如果应用只关心key对应的最新value值，可以开启Kafka的日志清理功能，Kafka会定期将相同key的消息进行合并，只保留最新的value值。</p><h4 id="清理"><a href="#清理" class="headerlink" title="清理"></a>清理</h4><p>查看现有的<code>__consumer_offsets</code>清理策略</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-configs.sh --zookeeper xxxx:2181 --entity-type topics --entity-name __consumer_offsets --describe</span><br></pre></td></tr></table></figure><p>查看第一行输出可以看到 <code>cleanup.policy=compact</code>，则说明cleanup.policy是compact</p><p><code>__consumer_offsets</code>的确与普通topic在清理策略上不同，也就是参数cleanup.policy上，给<code>__consumer_offsets</code>手动添加了清理策略</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-configs.sh --zookeeper xxxx:2181 --entity-type topics --entity-name __consumer_offsets --alter --add-config &#39;cleanup.policy&#x3D;delete&#39;</span><br></pre></td></tr></table></figure><p>添加完后，等了一会磁盘占用就会减少</p><hr><p>参考链接</p><ul><li><a href="https://www.codenong.com/cs107089637/" target="_blank" rel="noopener">KAFKA consumer_offsets 清理</a></li></ul>]]></content>
    
    <summary type="html">
    
      __consumer_offsets 占用磁盘空间过大处理
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 事务日志和 snapshot 清理</title>
    <link href="http://yoursite.com/2020/12/08/zookeeper-log-clean/"/>
    <id>http://yoursite.com/2020/12/08/zookeeper-log-clean/</id>
    <published>2020-12-07T16:00:00.000Z</published>
    <updated>2020-12-08T15:35:29.725Z</updated>
    
    <content type="html"><![CDATA[<p>Zookeeper 运行过程会产生大量的事务日志和 snapshot 镜像文件，讨论下如何清理事务日志和snapshot</p><hr><h4 id="日志文件"><a href="#日志文件" class="headerlink" title="日志文件"></a>日志文件</h4><p>在使用ZK过程中，会有dataDir和dataLogDir两个目录，分别用于snapshot和事务日志的输出（默认情况下只有dataDir目录，snapshot和事务日志都保存在这个目录中）</p><p>ZK在完成若干次事务日志之后（在ZK中，凡是对数据有更新的操作，比如创建节点，删除节点或是对节点数据内容进行更新等，都会记录事务日志），ZK会触发一次快照（snapshot），将当前server上所有节点的状态以快照文件的形式dump到磁盘上去，即snapshot文件。这里的若干次事务日志是可以配置的，默认是100000，具体参看配置参数”snapCount”的介绍</p><h4 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h4><h5 id="配置自动清理"><a href="#配置自动清理" class="headerlink" title="配置自动清理"></a>配置自动清理</h5><p>ZK在3.4.0版本以后提供了自动清理snapshot和事务日志的功能通过配置 <code>autopurge.snapRetainCount</code> 和 <code>autopurge.purgeInterval</code> 这两个参数能够实现定时清理了。</p><p>当前ZK版本为3.4.6，因此可以使用自带的清理功能</p><ul><li>autopurge.purgeInterval: 这个参数指定了清理频率，单位是小时，需要填写一个1或更大的整数，默认是0，表示不开启自己清理功能。</li><li>autopurge.snapRetainCount: 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">autopurge.snapRetainCount&#x3D;50</span><br><span class="line">autopurge.purgeInterval&#x3D;1</span><br></pre></td></tr></table></figure><p>每一个小时清理一次，一次保留50个文件</p><h5 id="自定义清理脚本"><a href="#自定义清理脚本" class="headerlink" title="自定义清理脚本"></a>自定义清理脚本</h5><p>clean_zook_log.sh 脚本内容如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">           </span><br><span class="line">#snapshot file dir</span><br><span class="line">dataDir&#x3D;&#x2F;home&#x2F;tu&#x2F;data&#x2F;zookeeper&#x2F;version-2</span><br><span class="line">#tran log dir</span><br><span class="line">dataLogDir&#x3D;&#x2F;home&#x2F;tu&#x2F;data&#x2F;zookeeper&#x2F;version-2</span><br><span class="line">#zk log dir</span><br><span class="line">logDir&#x3D;&#x2F;home&#x2F;tu&#x2F;zookeeper&#x2F;logs</span><br><span class="line">#Leave 60 files</span><br><span class="line">count&#x3D;50</span><br><span class="line">count&#x3D;$[$count+1]</span><br><span class="line">ls -t $dataLogDir&#x2F;log.* | tail -n +$count | xargs rm -f</span><br><span class="line">ls -t $dataDir&#x2F;snapshot.* | tail -n +$count | xargs rm -f</span><br><span class="line">ls -t $logDir&#x2F;zookeeper.log.* | tail -n +$count | xargs rm -f</span><br></pre></td></tr></table></figure><p>这个脚本保留最新的50个文件，可以将这个脚本添加到crontab中，设置为每30分钟执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">30 * * * * &#x2F;bin&#x2F;bash &#x2F;home&#x2F;tu&#x2F;zookeeper&#x2F;bin&#x2F;clean_zook_log.sh &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h5 id="zkCleanup-sh清理"><a href="#zkCleanup-sh清理" class="headerlink" title="zkCleanup.sh清理"></a>zkCleanup.sh清理</h5><p>ZK自己有自带的清理文件 bin/zkCleanup.sh，可以直接使用这个脚本也是可以执行清理工作的，是使用的zookeeper.jar里的<code>org.apache.zookeeper.server.PurgeTxnLog</code>来做的</p><hr><p>参考链接</p><ul><li><a href="https://www.cnblogs.com/the-tops/p/5783722.html" target="_blank" rel="noopener">ZooKeepr日志清理【转】</a></li><li><a href="https://ningyu1.github.io/site/post/89-zookeeper-cleanlog/" target="_blank" rel="noopener">Zookeeper事务日志和snapshot清理方式</a></li><li><a href="https://www.cnblogs.com/linjiqin/archive/2013/03/16/2963439.html" target="_blank" rel="noopener">zookeeper配置文件详解</a></li><li><a href="https://mp.weixin.qq.com/s/bDwKeELWESerPznCoSdesg" target="_blank" rel="noopener">不懂 Zookeeper？没关系，看这篇就够了</a></li></ul>]]></content>
    
    <summary type="html">
    
      Zookeeper 事务日志和 snapshot 清理
    
    </summary>
    
    
      <category term="Zookeeper" scheme="http://yoursite.com/categories/Zookeeper/"/>
    
    
  </entry>
  
  <entry>
    <title>async-profile 工具</title>
    <link href="http://yoursite.com/2020/05/23/async-profile/"/>
    <id>http://yoursite.com/2020/05/23/async-profile/</id>
    <published>2020-05-22T16:00:00.000Z</published>
    <updated>2020-05-23T12:31:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>超好用的自带火焰图的 Java 性能分析工具</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>火焰图常用来进行性能分析，async-profiler 就是一种自带火焰图的 Java 性能分析工具</p><blockquote><p>最近 Arthas 性能分析工具上线了火焰图分析功能，Arthas 使用 async-profiler 生成 CPU/内存火焰图进行性能分析，弥补了之前内存分析的不足。在 Arthas 上使用还是比较方便的，使用方式可以看官方文档。<a href="https://alibaba.github.io/arthas/profiler.html" target="_blank" rel="noopener">Arthas 火焰图官方文档</a></p></blockquote><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>具体使用请跳转阅读<a href="https://juejin.im/post/5ded9ade6fb9a0164a10bcda#heading-1" target="_blank" rel="noopener">《超好用的自带火焰图的 Java 性能分析工具 Async-profiler 了解一下》</a>，该文章从安装、使用到案例都有介绍，适合入门了解。</p>]]></content>
    
    <summary type="html">
    
      超好用的自带火焰图的 Java 性能分析工具
    
    </summary>
    
    
      <category term="Tools" scheme="http://yoursite.com/categories/Tools/"/>
    
    
  </entry>
  
  <entry>
    <title>perf 工具</title>
    <link href="http://yoursite.com/2020/05/23/perf/"/>
    <id>http://yoursite.com/2020/05/23/perf/</id>
    <published>2020-05-22T16:00:00.000Z</published>
    <updated>2020-12-08T15:24:24.062Z</updated>
    
    <content type="html"><![CDATA[<p>Linux 性能调优工具 perf 使用</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>背景知识啊，介绍啊，跳转阅读下方链接了解即可</p><ul><li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/" target="_blank" rel="noopener">Perf – Linux下的系统性能调优工具，第 1 部分</a></li><li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-perf2/" target="_blank" rel="noopener">Perf – Linux下的系统性能调优工具，第 2 部分</a></li></ul><h4 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h4><p>perf 是一个包含多个子工具的工具集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">$ perf --help</span><br><span class="line"></span><br><span class="line"> usage: perf [--version] [--help] [OPTIONS] COMMAND [ARGS]</span><br><span class="line"></span><br><span class="line"> The most commonly used perf commands are:</span><br><span class="line">   annotate        Read perf.data (created by perf record) and display annotated code</span><br><span class="line">   archive         Create archive with object files with build-ids found in perf.data file</span><br><span class="line">   bench           General framework for benchmark suites</span><br><span class="line">   buildid-cache   Manage build-id cache.</span><br><span class="line">   buildid-list    List the buildids in a perf.data file</span><br><span class="line">   c2c             Shared Data C2C&#x2F;HITM Analyzer.</span><br><span class="line">   config          Get and set variables in a configuration file.</span><br><span class="line">   data            Data file related processing</span><br><span class="line">   diff            Read perf.data files and display the differential profile</span><br><span class="line">   evlist          List the event names in a perf.data file</span><br><span class="line">   ftrace          simple wrapper for kernel&#39;s ftrace functionality</span><br><span class="line">   inject          Filter to augment the events stream with additional information</span><br><span class="line">   kallsyms        Searches running kernel for symbols</span><br><span class="line">   kmem            Tool to trace&#x2F;measure kernel memory properties</span><br><span class="line">   kvm             Tool to trace&#x2F;measure kvm guest os</span><br><span class="line">   list            List all symbolic event types</span><br><span class="line">   lock            Analyze lock events</span><br><span class="line">   mem             Profile memory accesses</span><br><span class="line">   record          Run a command and record its profile into perf.data</span><br><span class="line">   report          Read perf.data (created by perf record) and display the profile</span><br><span class="line">   sched           Tool to trace&#x2F;measure scheduler properties (latencies)</span><br><span class="line">   script          Read perf.data (created by perf record) and display trace output</span><br><span class="line">   stat            Run a command and gather performance counter statistics</span><br><span class="line">   test            Runs sanity tests.</span><br><span class="line">   timechart       Tool to visualize total system behavior during a workload</span><br><span class="line">   top             System profiling tool.</span><br><span class="line">   version         display the version of perf binary</span><br><span class="line">   probe           Define new dynamic tracepoints</span><br><span class="line">   trace           strace inspired tool</span><br><span class="line"></span><br><span class="line"> See &#39;perf help COMMAND&#39; for more information on a specific command.</span><br></pre></td></tr></table></figure><p>其中最常用应该是<code>perf list</code>、<code>perf record</code>、<code>perf report</code>、<code>perf stat</code>、<code>perf top</code>这几个工具</p><h5 id="perf-list"><a href="#perf-list" class="headerlink" title="perf list"></a>perf list</h5><p>perf list 用来查看 perf 所支持的性能事件（即能够触发perf能够采样点的事件），其中有软件的也有硬件的。</p><p><img src="/images/blog/2020-05-23-2.png" alt></p><p>说明:</p><ul><li>Software event: 是内核软件产生的事件，比如进程切换，tick 数等，与硬件无关</li><li>Tracepoint event: 是内核中的静态 tracepoint 所触发的事件，这些 tracepoint 用来判断程序运行期间内核的行为细节，比如 slab 分配器的分配次数等</li><li>Hardware event: 是硬件产生的事件，但这里的<code>perf list</code>上没有看到对应的事件，阅读前辈们文章都有提到这个，感觉是当前版本已经去掉了</li></ul><h5 id="perf-top"><a href="#perf-top" class="headerlink" title="perf top"></a>perf top</h5><p>有些时候，只是发现系统性能无端下降，并不清楚究竟哪个进程吃资源导致的。</p><p>这时就需要用上<code>perf top</code>，其主要用于实时分析各个函数在某个性能事件上的热度，能够快速的定位热点函数，包括应用程序函数、</p><p>直接运行perf top输出示例如下:</p><p><img src="/images/blog/2020-05-23-3.png" alt></p><p>输出格式解释:</p><ul><li>符号引发的性能事件的比例，默认指占用的cpu周期比例</li><li>符号所在的DSO(Dynamic Shared Object)，可以是应用程序、内核、动态链接库、模块</li><li>DSO的类型。[.]表示此符号属于用户态的ELF文件，包括可执行文件与动态链接库)。[k]表述此符号属于内核或模块</li><li>符号名。有些符号不能解析为函数名，只能用地址表示</li></ul><p>使用示例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">perf top                         # 默认配置</span><br><span class="line">perf top -G                      # 得到调用关系图</span><br><span class="line">perf top -e cycles               # 指定性能事件</span><br><span class="line">perf top -p 23015,32476          # 查看这两个进程的cpu cycles使用情况</span><br><span class="line">perf top -s comm,pid,symbol      # 显示调用symbol的进程名和进程号</span><br><span class="line">perf top --comms nginx,top       # 仅显示属于指定进程的符号</span><br><span class="line">perf top --symbols kfree         # 仅显示指定的符号</span><br></pre></td></tr></table></figure><h5 id="perf-stat"><a href="#perf-stat" class="headerlink" title="perf stat"></a>perf stat</h5><p>用于分析指定程序的性能概况，<code>-p</code> 指定进程号，需要按ctrl-c结束</p><p><img src="/images/blog/2020-05-23-4.png" alt></p><p>输出格式解释:</p><ul><li>task-clock：任务真正占用的处理器时间，单位为ms。CPUs utilized = task-clock / time elapsed，CPU的占用率。</li><li>context-switches：上下文的切换次数。</li><li>CPU-migrations：处理器迁移次数。Linux为了维持多个处理器的负载均衡，在特定条件下会将某个任务从一个CPU迁移到另一个CPU。</li><li>page-faults：缺页异常的次数。当应用程序请求的页面尚未建立、请求的页面不在内存中，或者请求的页面虽然在内存中，但物理地址和虚拟地址的映射关系尚未建立时，都会触发一次缺页异常。另外TLB不命中，页面访问权限不匹配等情况也会触发缺页异常。</li></ul><blockquote><p>新版本对一些好像不太支持了</p></blockquote><h5 id="perf-record"><a href="#perf-record" class="headerlink" title="perf record"></a>perf record</h5><p>收集采样信息，并将其记录在数据文件中</p><p>常用参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-a：从所有CPU上收集性能数据</span><br><span class="line">-e：&lt;event&gt;：指明要分析的性能事件</span><br><span class="line">-p：&lt;pid&gt;：仅分析目标进程及其创建的线程</span><br><span class="line">-t：&lt;tid&gt; 仅分析tid线程</span><br><span class="line">-o：将采集的数据输出到指定文件</span><br><span class="line">-g：采集函数的调用关系图</span><br></pre></td></tr></table></figure><blockquote><p>默认情况下，信息会存在<code>perf.data</code>文件里，需使用<code>perf report</code>命令可以解析这个文件，如需到其他文件使用<code>-o</code>参数</p></blockquote><h5 id="perf-report"><a href="#perf-report" class="headerlink" title="perf report"></a>perf report</h5><p>读取<code>perf record</code>创建的数据文件，并给出热点分析结果</p><p>常用参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-i, --input&#x3D;：输入性能数据文件</span><br><span class="line">-T, --threads：显示每一个线程的事件统计信息</span><br><span class="line">--pid&#x3D;：仅显示给的pid的进程的事件统计信息</span><br><span class="line">--tid&#x3D;：仅显示给的tid的线程的事件统计信息</span><br></pre></td></tr></table></figure><hr><p>参考链接</p><ul><li><a href="http://www.cpper.cn/2017/06/04/linux/perf/" target="_blank" rel="noopener">Linux性能调优工具perf的使用</a></li></ul>]]></content>
    
    <summary type="html">
    
      Linux 性能调优工具 perf 使用
    
    </summary>
    
    
      <category term="Tools" scheme="http://yoursite.com/categories/Tools/"/>
    
    
  </entry>
  
  <entry>
    <title>火焰图</title>
    <link href="http://yoursite.com/2020/05/23/flame-graph/"/>
    <id>http://yoursite.com/2020/05/23/flame-graph/</id>
    <published>2020-05-22T16:00:00.000Z</published>
    <updated>2021-01-01T15:17:47.330Z</updated>
    
    <content type="html"><![CDATA[<p>火焰图（flame graph）是性能分析的利器</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>在涉猎运维知识时，多次看到大佬们使用火焰图来进行性能分析，因此跟着涨了下知识。</p><h4 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h4><p>先来体验下火焰图 – <a href="https://queue.acm.org/downloads/2016/Gregg4.svg" target="_blank" rel="noopener">SVG 图片</a>，该图来自阮一峰老师的<a href="https://www.ruanyifeng.com/blog/2017/09/flame-graph.html" target="_blank" rel="noopener">《如何读懂火焰图？》</a>，其用来展示 CPU 的调用栈。</p><p>y 轴表示调用栈，每一层都是一个函数。调用栈越深，火焰就越高，顶部就是正在执行的函数，下方都是它的父函数。</p><p>x 轴表示抽样数，如果一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长。注意，x 轴不代表时间，而是所有的调用栈合并后，按字母顺序排列的。</p><p>火焰图就是看顶层的哪个函数占据的宽度最大。只要有”平顶”（plateaus），就表示该函数可能存在性能问题，也是常说的”大平顶”问题</p><p>颜色没有特殊含义，因为火焰图表示的是 CPU 的繁忙程度，所以一般选择暖色调。</p><h4 id="互动"><a href="#互动" class="headerlink" title="互动"></a>互动</h4><p>火焰图是 SVG 图片，可以与用户互动。</p><p><strong>鼠标悬浮</strong></p><p>火焰的每一层都会标注函数名，鼠标悬浮时会显示完整的函数名、抽样抽中的次数、占据总抽样次数的百分比。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqld&#39;JOIN::exec (272,959 samples, 78.34 percent)</span><br></pre></td></tr></table></figure><p><strong>点击放大</strong></p><p>在某一层点击，火焰图会水平放大，该层会占据所有宽度，显示详细信息。左上角会同时显示”Reset Zoom”，点击该链接，图片就会恢复原样。</p><p><img src="/images/blog/2020-05-23-1.png" alt></p><p><strong>搜索</strong></p><p>按下 Ctrl + F 会显示一个搜索框，用户可以输入关键词或正则表达式，所有符合条件的函数名会高亮显示。</p><h4 id="生成工具"><a href="#生成工具" class="headerlink" title="生成工具"></a>生成工具</h4><p>以perf为例，看一下<code>flamegraph</code>的使用方法</p><p>1、Flame Graph项目位于GitHub上：<a href="https://github.com/brendangregg/FlameGraph" target="_blank" rel="noopener">https://github.com/brendangregg/FlameGraph</a></p><p>2、可以用git将其clone下来：git clone <a href="https://github.com/brendangregg/FlameGraph.git" target="_blank" rel="noopener">https://github.com/brendangregg/FlameGraph.git</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1、第一步</span><br><span class="line"></span><br><span class="line">perf record -e cpu-clock -g -p 28591</span><br><span class="line"></span><br><span class="line">Ctrl+c结束执行后，在当前目录下会生成采样数据perf.data.</span><br><span class="line"></span><br><span class="line">2、第二步</span><br><span class="line"></span><br><span class="line">用perf script工具对perf.data进行解析</span><br><span class="line"></span><br><span class="line">perf script -i perf.data &amp;&gt; perf.unfold</span><br><span class="line"></span><br><span class="line">3、第三步</span><br><span class="line"></span><br><span class="line">将perf.unfold中的符号进行折叠：</span><br><span class="line"></span><br><span class="line">.&#x2F;stackcollapse-perf.pl perf.unfold &amp;&gt; perf.folded</span><br><span class="line"></span><br><span class="line">4、最后生成svg图：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">.&#x2F;flamegraph.pl perf.folded &gt; perf.svg</span><br></pre></td></tr></table></figure><p>现在可以使用自带火焰图的 Java 性能分析工具 <a href="https://github.com/jvm-profiling-tools/async-profiler" target="_blank" rel="noopener">Async-profiler</a><br>，其已经内置了开箱即用的 SVG 文件生成功能。</p><hr><p>参考链接</p><ul><li><a href="https://www.ruanyifeng.com/blog/2017/09/flame-graph.html" target="_blank" rel="noopener">如何读懂火焰图？</a></li><li><a href="https://juejin.im/post/5ded9ade6fb9a0164a10bcda#heading-2" target="_blank" rel="noopener">超好用的自带火焰图的 Java 性能分析工具 Async-profiler 了解一下</a></li><li><a href="https://zhuanlan.zhihu.com/p/85654612" target="_blank" rel="noopener">Linux火焰图性能分析</a></li></ul>]]></content>
    
    <summary type="html">
    
      读懂火焰图
    
    </summary>
    
    
      <category term="Distributed" scheme="http://yoursite.com/categories/Distributed/"/>
    
    
  </entry>
  
  <entry>
    <title>安装 GitLab Runner</title>
    <link href="http://yoursite.com/2020/05/12/gitlab-runner/"/>
    <id>http://yoursite.com/2020/05/12/gitlab-runner/</id>
    <published>2020-05-11T16:00:00.000Z</published>
    <updated>2020-05-12T10:15:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>使用官方的 GitLab 存储库安装 GitLab Runner</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>需要为项目实现基于 Gitlab 的 CI/CD。gitlab-runner 是具体执行 CI/CD 的核心。因此需要搭建一个 GitLab Runner</p><p>文中大部分参考于官方的文档<a href="https://docs.gitlab.com/runner/install/linux-repository.html" target="_blank" rel="noopener">《Install GitLab Runner using the official GitLab repositories》</a></p><h4 id="环境介绍"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍</h4><ul><li>Linux 环境 Debian</li><li>Docker 作为执行器</li></ul><h4 id="安装-Docker"><a href="#安装-Docker" class="headerlink" title="安装 Docker"></a>安装 Docker</h4><p>这边 Runner 需要支持 Docker 系列的执行器，也就是构建需要在容器里执行，那么需要先安装 Docker 环境</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -sSL https:&#x2F;&#x2F;get.docker.com&#x2F; | sh</span><br><span class="line">&#x2F;etc&#x2F;init.d&#x2F;docker status</span><br><span class="line">[ ok ] Docker is running.</span><br></pre></td></tr></table></figure><h4 id="安装-Runner"><a href="#安装-Runner" class="headerlink" title="安装 Runner"></a>安装 Runner</h4><p>GitLab Runner 支持多平台、多方式安装，包括GNU/Linux, macOS, FreeBSD 和Windows平台的安装，以及支持基于docker的自动扩展式安装</p><p>下面使用官方的 GitLab 存储库在 Debian 平台安装GitLab Runner</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 添加GitLab的官方存储库</span><br><span class="line"># For Debian&#x2F;Ubuntu&#x2F;Mint</span><br><span class="line">$ curl -L https:&#x2F;&#x2F;packages.gitlab.com&#x2F;install&#x2F;repositories&#x2F;runner&#x2F;gitlab-runner&#x2F;script.deb.sh | sudo bash</span><br><span class="line"></span><br><span class="line"># 安装特定版本的 GitLab Runner</span><br><span class="line"># for DEB based systems</span><br><span class="line">$ apt-cache madison gitlab-runner</span><br><span class="line">$ apt-get install gitlab-runner&#x3D;11.11.4</span><br><span class="line"></span><br><span class="line"># 确认安装成功</span><br><span class="line">$ gitlab-runner --version</span><br><span class="line">Version:      11.11.4</span><br><span class="line">Git revision: e828d3bc</span><br><span class="line">Git branch:</span><br><span class="line">GO version:   go1.8.7</span><br><span class="line">Built:        2019-07-07T00:29:25+0000</span><br><span class="line">OS&#x2F;Arch:      linux&#x2F;amd64</span><br></pre></td></tr></table></figure><h4 id="注册-Runner"><a href="#注册-Runner" class="headerlink" title="注册 Runner"></a>注册 Runner</h4><p>注册 Runner 是将 Runner 与 GitLab 实例绑定的过程</p><p>注册 Specific Runnersr 到 GitLab 之前，需要在 Settings 中拿到 Gitlab 实例 URL 和注册 token</p><p>Settings-&gt;CI/CD-&gt;Runners-&gt;Specific Runners</p><p><img src="/images/blog/2020-05-12-4.png" alt></p><p>接着执行下方命令会进入一个交互式的配置流程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 运行以下命令注册Runner</span><br><span class="line">$ gitlab-runner register</span><br><span class="line"></span><br><span class="line"># 输入GitLab实例URL</span><br><span class="line">Please enter the gitlab-ci coordinator URL (e.g. https:&#x2F;&#x2F;gitlab.com )</span><br><span class="line">https:&#x2F;&#x2F;git-sa.nie.netease.com&#x2F;</span><br><span class="line"></span><br><span class="line"># 输入token来注册</span><br><span class="line">Please enter the gitlab-ci token for this runner</span><br><span class="line">xxx</span><br><span class="line"></span><br><span class="line"># 输入Runner的描述，稍后可以在GitLab的UI中进行更改</span><br><span class="line">Please enter the gitlab-ci description for this runner</span><br><span class="line">alpha-runner</span><br><span class="line"></span><br><span class="line"># 输入与Runner关联的标签，稍后可以在GitLab的UI中进行更改（在.gitlab-ci.yml中使用tags来指定相关标签的runner运行）</span><br><span class="line">Please enter the gitlab-ci tags for this runner (comma separated):</span><br><span class="line">alpha</span><br><span class="line"></span><br><span class="line"># 输入Runner执行者（需要使用docker来部署服务，因此这里选择Docker作为执行程序）</span><br><span class="line">Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:</span><br><span class="line">docker</span><br><span class="line"></span><br><span class="line"># 如果选择Docker作为执行程序，则会要求定义默认映像，用于在.gitlab-ci.yml中未指定镜像使用默认镜像</span><br><span class="line">Please enter the Docker image (eg. ruby:2.6):</span><br><span class="line">dockerhub.nie.netease.com&#x2F;library&#x2F;debian_ci</span><br></pre></td></tr></table></figure><h4 id="配置-Docker"><a href="#配置-Docker" class="headerlink" title="配置 Docker"></a>配置 Docker</h4><p>注册一个 Docker 类型的 Runner 后，如果要在该 Runner 中使用 Docker 进行构建等任务，则需要增加以下配置，以支持 docker in docker</p><blockquote><p>安装好runner后，即会生成一份runner的配置文件，不同系统平台配置文件路径为：<br>  以root用户安装的，且为 *nix 类系统（如Debian）配置文件路径为/etc/gitlab-runner/config.toml<br>  以非root用户安装的，且为 *nix 类系统（如Debian）配置文件路径为~/.gitlab-runner/config.toml<br>  其他系统 ./config.toml</p></blockquote><p>挂载宿主docker.sock到容器内，挂载镜像registry的认证文件到容器内（如果要拉取私有镜像，则需要在容器内部署认证配置，或者在宿主配置，然后挂入容器内），修改 Docker 为 host 网络</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 修改对应runner的volumes配置</span><br><span class="line">volumes &#x3D; [&quot;&#x2F;cache&quot;, &quot;&#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock&quot;, &quot;&#x2F;root&#x2F;.docker&#x2F;config.json:&#x2F;root&#x2F;.docker&#x2F;config.json&quot;]</span><br><span class="line"># 在volums下添加如下一行</span><br><span class="line">network_mode &#x3D; &quot;host&quot;</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2020-05-12-3.png" alt></p>]]></content>
    
    <summary type="html">
    
      使用官方的 GitLab 存储库安装 GitLab Runner
    
    </summary>
    
    
      <category term="Tools" scheme="http://yoursite.com/categories/Tools/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 知识练习</title>
    <link href="http://yoursite.com/2020/05/12/Linux-Exercise/"/>
    <id>http://yoursite.com/2020/05/12/Linux-Exercise/</id>
    <published>2020-05-11T16:00:00.000Z</published>
    <updated>2020-05-12T02:21:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>Linux 运维知识练习</p><hr><h3 id="Linux-理论部分"><a href="#Linux-理论部分" class="headerlink" title="Linux 理论部分"></a>Linux 理论部分</h3><h4 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h4><h5 id="进程和线程有什么区别"><a href="#进程和线程有什么区别" class="headerlink" title="进程和线程有什么区别"></a>进程和线程有什么区别</h5><p>线程是CPU调度的基本单位，而进程则是资源拥有的基本单位</p><h5 id="进程有哪些状态"><a href="#进程有哪些状态" class="headerlink" title="进程有哪些状态"></a>进程有哪些状态</h5><p><img src="/images/blog/2020-05-12-1.png" alt></p><p>1.创建状态<br>进程由创建而产生。创建进程是一个非常复杂的过程，一般需要通过多个步骤才能完成：如首先由进程申请一个空白的进程控制块(PCB)，并向PCB中填写用于控制和管理进程的信息；然后为该进程分配运行时所必须的资源；最后，把该进程转入就绪状态并插入到就绪队列中。</p><p>2.就绪状态<br>这是指进程已经准备好运行的状态，即进程已分配到除CPU以外所有的必要资源后，只要再获得CPU，便可立即执行。如果系统中有许多处于就绪状态的进程，通常将它们按照一定的策略排成一个队列，该队列称为就绪队列。有执行资格，没有执行权的进程。</p><p>3.运行状态<br>这里指进程已经获取CPU，其进程处于正在执行的状态。对任何一个时刻而言，在单处理机的系统中，只有一个进程处于执行状态而在多处理机系统中，有多个进程处于执行状态。既有执行资格，又有执行权的进程。</p><p>4.阻塞状态<br>这里是指正在执行的进程由于发生某事件（如I/O请求、申请缓冲区失败等）暂时无法继续执行的状态，即进程执行受到阻塞。此时引起进程调度，操作系统把处理机分配给另外一个就绪的进程，而让受阻的进程处于暂停的状态，一般将这个暂停状态称为阻塞状态</p><p>5.终止状态<br>进程的终止也要通过两个步骤：首先，是等待操作系统进行善后处理，最后将其PCB清零，并将PCB空间返还给系统。当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结，它将进入终止状态。进入终止态的进程以后不能在再执行，但是操作系统中任然保留了一个记录，其中保存状态码和一些计时统计数据，供其他进程进行收集。一旦其他进程完成了对其信息的提取之后，操作系统将删除其进程，即将其PCB清零，并将该空白的PCB返回给系统。</p><blockquote><p>为什么要分开就绪和阻塞状态</p><p>答：因为就绪态只需要等待处理机，而阻塞态可能在等待输入输出，即使分配给处理机也是徒劳，所以两状态图不妥。对于调度进程，只需要等待就绪队列里的进程，因为阻塞状态可以转换到就绪队列里去。</p></blockquote><h5 id="什么是僵尸进程"><a href="#什么是僵尸进程" class="headerlink" title="什么是僵尸进程"></a>什么是僵尸进程</h5><p>一个进程使用fork()创建子进程，如果子进程退出，而父进程并没有调用wait()或waitpid()获取子进程的状态信息，那么子进程的某些信息如进程描述符仍然保存在系统中，这种进程称之为僵尸进程</p><blockquote><p>查看僵尸进程，利用命令ps，可以看到有标记为Z(zombie)的进程就是僵尸进程</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 查看进程的状态的</span><br><span class="line">$ ps -aux | grep name</span><br><span class="line">1137   pts&#x2F;0   S   0:00   -bash</span><br><span class="line">1217   pts&#x2F;0   S   0:00   .&#x2F;zombie</span><br><span class="line">1218   pts&#x2F;0   Z   0:00   [zombie]</span><br><span class="line">1578   pts&#x2F;0   R   0:00   ps   -ax</span><br></pre></td></tr></table></figure><h5 id="僵尸进程产生的原因"><a href="#僵尸进程产生的原因" class="headerlink" title="僵尸进程产生的原因"></a>僵尸进程产生的原因</h5><ul><li>子进程结束后向父进程发出SIGCHLD信号，父进程默认忽略了它</li><li>父进程没有调用wait()或waitpid()函数来等待子进程的结束</li><li>网络原因有时会引起僵尸进程</li></ul><h5 id="如果出现大量的僵尸进程会有哪些危害"><a href="#如果出现大量的僵尸进程会有哪些危害" class="headerlink" title="如果出现大量的僵尸进程会有哪些危害"></a>如果出现大量的僵尸进程会有哪些危害</h5><p>僵尸进程会在系统中保留其某些信息如进程描述符、进程id等等。以进程id为例，系统中可用的进程id是有限的，如果由于系统中大量的僵尸进程占用进程id，就会导致因为没有可用的进程id系统不能产生新的进程，这种问题可就大了，这就是僵尸进程来的危害，因此大部分情况下，我们都应当避免僵尸进程的产生。</p><blockquote><p>总而言之，僵尸进程会占用系统资源，如果很多，则会严重影响服务器的性能，最大的危害就是内存泄露</p></blockquote><h5 id="如何杀死僵尸进程"><a href="#如何杀死僵尸进程" class="headerlink" title="如何杀死僵尸进程"></a>如何杀死僵尸进程</h5><p>僵尸进程用kill命令是无法杀掉的，但是我们可以结果掉僵尸进程的父进程（如果其父进程不需要的话）；父进程挂了之后，僵尸进程就成了孤儿进程，孤儿进程不会占用系统资源，会被init程序收养，然后init程序将其回收</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看僵尸进程的父进程</span><br><span class="line">$ ps -A -o stat,ppid,pid,cmd |grep -e &quot;^[Zz]&quot;</span><br><span class="line"></span><br><span class="line"># 杀死僵尸进程对应的父进程</span><br><span class="line">$ kill -9 ppid号</span><br></pre></td></tr></table></figure><blockquote><p>一台服务器上产生了100多少僵死进程，而且每一僵死进程的父进程都不一样，如果用上面的方法，一条一条的杀会挺麻烦的。</p><p>一条命令直接查找僵死进程，然后将父进程杀死</p><p><code>ps -A -o stat,ppid,pid,cmd | grep -e &quot;^[Zz]&quot; | awk &#39;{print $2}&#39; | xargs kill -9</code></p></blockquote><h5 id="描述进程间通信有哪些⽅方法"><a href="#描述进程间通信有哪些⽅方法" class="headerlink" title="描述进程间通信有哪些⽅方法"></a>描述进程间通信有哪些⽅方法</h5><p>进程间通信（IPC，Interprocess communication）是一组编程接口，让程序员能够协调不同的进程，使之能在一个操作系统里同时运行，并相互传递、交换信息。</p><ul><li>管道: 管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系</li><li>有名管道: 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程之间的通信</li><li>消息队列: 消息队列是消息的链表，存放在内核中并由消息队列表示符标示。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限制等缺点</li><li>共享内存: 共享内存就是映射一段能被其它进程所访问的内存，共享内存由一个进程创建，但是多个进程都可以访问。共享内存是最快的IPC，往往与其它通信机制配合使用，来实现进程间的同步和通信</li><li>信号量: 信号量是一个计数器，可以用来控制多个进程对共享资源的访问，它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。主要作为进程间以及同一进程内不同线程之间的同步手段</li><li>socket: 套接字也是进程间的通信机制，与其它通信机制不同的是，它可以用于不同机器间的进程通信</li><li>信号: 信号是一种比较复杂的通信方式，用于通知接受进程某个时间已经发生</li></ul><h5 id="什么是-Unix-信号"><a href="#什么是-Unix-信号" class="headerlink" title="什么是 Unix 信号"></a>什么是 Unix 信号</h5><p>信号是一种中断，是一种处理异步事件的方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 用 kill -l 命令可以察看系统定义的信号列表</span><br><span class="line">$ kill -l</span><br><span class="line"> 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL</span><br><span class="line"> 5) SIGTRAP 6) SIGABRT 7) SIGEMT 8) SIGFPE</span><br><span class="line"> 9) SIGKILL10) SIGBUS11) SIGSEGV12) SIGSYS</span><br><span class="line">13) SIGPIPE14) SIGALRM15) SIGTERM16) SIGURG</span><br><span class="line">17) SIGSTOP18) SIGTSTP19) SIGCONT20) SIGCHLD</span><br><span class="line">21) SIGTTIN22) SIGTTOU23) SIGIO24) SIGXCPU</span><br><span class="line">25) SIGXFSZ26) SIGVTALRM27) SIGPROF28) SIGWINCH</span><br><span class="line">29) SIGINFO30) SIGUSR131) SIGUSR2</span><br></pre></td></tr></table></figure><p>具体含义请转自<a href="https://blog.csdn.net/u012349696/article/details/50687462" target="_blank" rel="noopener">Unix系统中常用的信号含义</a></p><blockquote><p>SIGKILL用来立即结束程序的运行，该信号不能被阻塞、捕获和忽略</p></blockquote><h5 id="当你对⼀个进程发送-一个-HUP-信号，但是没有任何作⽤，分析原因"><a href="#当你对⼀个进程发送-一个-HUP-信号，但是没有任何作⽤，分析原因" class="headerlink" title="当你对⼀个进程发送    一个 HUP 信号，但是没有任何作⽤，分析原因"></a>当你对⼀个进程发送    一个 HUP 信号，但是没有任何作⽤，分析原因</h5><p>先解释下 HUP 信号， 全名叫hangup，表示终端断线</p><blockquote><p>当用户注销（logout）或者网络断开时，终端会收到Linux HUP信号（hangup）信号从而关闭其所有子进程</p></blockquote><p>当<strong>用户退出Linux登录时，前台进程组和后台有对终端输出的进程将会收到SIGHUP信号</strong>。这个信号的默认操作为终止进程，因此前台进程组和后台有终端输出的进程就会中止，不过可以捕获这个信号，比如wget能捕获SIGHUP信号，并忽略它，这样就算退出了Linux登录，wget也能继续下载。</p><p>没有任何作⽤有两种可能</p><ul><li>进程忽略Linux HUP信号</li><li>进程运行在新的会话里从而成为不属于此终端的子进程</li></ul><p>发送 HUP 信号（即意外终止信号）到运行进程 ID 为 1001 的程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kill -9 1001</span><br></pre></td></tr></table></figure><h5 id="请简述nohup命令的原理"><a href="#请简述nohup命令的原理" class="headerlink" title="请简述nohup命令的原理"></a>请简述nohup命令的原理</h5><p>nohup 命令运行指定的命令，忽略所有挂断（SIGHUP）信号，在注销后使用 nohup 命令运行后台中的程序</p><p> nohup 命令会从终端解除进程的关联，进程会丢掉STDOUT，STDERR的链接。标准输出和标准错误缺省会被重定向到 nohup.out 文件中。一般我们可在结尾加上”&amp;”来将命令同时放入后台运行，也可用”&gt;filename 2&gt;&amp;1”来更改缺省的重定向文件名，”&gt;filename 2&gt;&amp;1”意思是把标准错误（2）重定向到标准输出中（1），而标准输出又导入文件filename里面，所以结果是标准错误和标准输出都导入文件filename里面了</p><blockquote><p>使用&amp;后台运行程序：</p><ul><li>结果会输出到终端</li><li>使用Ctrl + C发送SIGINT信号，程序免疫</li><li>关闭session发送SIGHUP信号，程序关闭</li></ul><p>使用nohup运行程序：</p><ul><li>结果默认会输出到nohup.out</li><li>使用Ctrl + C发送SIGINT信号，程序关闭</li><li>关闭session发送SIGHUP信号，程序免疫</li></ul><p>平日线上经常使用nohup和&amp;配合来启动程序：</p><ul><li>同时免疫SIGINT和SIGHUP信号</li></ul></blockquote><h5 id="如何在bash脚本中处理用户的Ctrl-C"><a href="#如何在bash脚本中处理用户的Ctrl-C" class="headerlink" title="如何在bash脚本中处理用户的Ctrl-C"></a>如何在bash脚本中处理用户的Ctrl-C</h5><p>可以使用Bash提供的<code>trap</code>命令捕获中断信号</p><p><code>trap</code>的用法如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trap [-lp] [[arg] signal_spec ...]</span><br></pre></td></tr></table></figure><ul><li><code>-l</code>: 列出所有信号的序号及名称</li><li><code>-p</code>: 列出特定信号对应的处理指令</li><li><code>arg</code>: 是signal_spec指定的信号的处理指令</li><li><code>signal_spec</code>: 是需要捕获的信号</li></ul><p>执行下方脚本，<code>Ctrl+C</code>按键将触发<code>onCtrlC</code>函数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">trap 'onCtrlC; exit' INT</span><br><span class="line">function onCtrlC () &#123;</span><br><span class="line">    echo 'Ctrl+C is captured'</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">while true; do</span><br><span class="line">    echo 'I am working!'</span><br><span class="line">    sleep 1</span><br><span class="line">done</span><br></pre></td></tr></table></figure><blockquote><p>如果用户中断程序的运行，这个 trap 将会被执行，可以确保onCtrlC方法被执行。<strong>onCtrlC</strong> 后面的这个 <strong>exit</strong> 命令，它的存在是必要的。如果没有它，程序会在它中断点（也就是信号接收的时刻）继续执行</p></blockquote><h4 id="bashrc和环境变量"><a href="#bashrc和环境变量" class="headerlink" title="bashrc和环境变量"></a>bashrc和环境变量</h4><h5 id="shell-按照登录类型和交互类型分类，总共有哪⼏类，在各个类别中⾄少举出⼀个例子"><a href="#shell-按照登录类型和交互类型分类，总共有哪⼏类，在各个类别中⾄少举出⼀个例子" class="headerlink" title="shell 按照登录类型和交互类型分类，总共有哪⼏类，在各个类别中⾄少举出⼀个例子"></a>shell 按照登录类型和交互类型分类，总共有哪⼏类，在各个类别中⾄少举出⼀个例子</h5><p><strong>登录shell和非登陆shell</strong></p><ul><li>登录shell: 需要用户名、密码登录后才能进入的shell（或者以–login选项启动的shell，实际上不是真的存在哪个用户来登录）</li><li>非登录shell: 不需要输入用户名和密码即可打开的Shell（直接bash命令就是打开一个新的非登录shell，在Gnome或KDE中打开一个“终端”（terminal）窗口程序也是一个非登录shell）</li></ul><blockquote><p>退出一个登录shell: exit或者logout</p><p>退出一个非登录shell: 只能exit</p></blockquote><blockquote><p>登录shell 时，其bash进程名为”-bash”</p><p>非登陆shell时，bash进程名为”bash”</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@iZbp144crtihiqovt4h5m4Z ~]# su - lihm</span><br><span class="line">上一次登录：四 4月  2 16:06:04 CST 2020pts&#x2F;0 上</span><br><span class="line">[lihm@iZbp144crtihiqovt4h5m4Z ~]$ echo $0</span><br><span class="line">-bash</span><br><span class="line">[lihm@iZbp144crtihiqovt4h5m4Z ~]$ exit</span><br><span class="line">logout</span><br><span class="line">(base) [root@iZbp144crtihiqovt4h5m4Z ~]# su lihm</span><br><span class="line">[lihm@iZbp144crtihiqovt4h5m4Z root]$ echo $0</span><br><span class="line">bash</span><br><span class="line">[lihm@iZbp144crtihiqovt4h5m4Z root]$</span><br></pre></td></tr></table></figure><p><strong>交互式shell和非交互式shell</strong></p><ul><li>交互式模式: 在终端上执行，shell等待你的输入，并且立即执行你提交的命令</li><li>非交互式模式: 以shell script(非交互)方式执行。在这种模式 下，shell不与你进行交互，而是读取存放在文件中的命令,并且执行它们。当它读到文件的结尾EOF，shell也就终止</li></ul><h5 id="上述各个类别的-bash-系统配置文件和个⼈配置⽂件分别是什么，加载顺序是怎样的"><a href="#上述各个类别的-bash-系统配置文件和个⼈配置⽂件分别是什么，加载顺序是怎样的" class="headerlink" title="上述各个类别的 bash 系统配置文件和个⼈配置⽂件分别是什么，加载顺序是怎样的"></a>上述各个类别的 bash 系统配置文件和个⼈配置⽂件分别是什么，加载顺序是怎样的</h5><ul><li><p>交互式登录shell: <code>/etc/profile</code> -&gt; (<code>~/.bash_profile</code> | <code>~/.bash_login</code> | <code>~/.profile</code>) -&gt;（ <code>~/.bashrc</code> -&gt; <code>/etc/bashrc</code>） -&gt; <code>~/.bash_logout</code></p><blockquote><p> (~/.bash_profile | ~/.bash_login | ~/.profile) 中读取第一个存在而且可读的文件并且执行其中的命令，可以在shell启动时使用–noprofile选项来禁止这种行为</p><p> 是以登录shell注销的，Bash会读取并执行文件~/.bash_logout和/etc/bash.bash_logout中的命令，假如文件存在的话</p></blockquote></li><li><p>交互式非登陆shell: <code>~/.bashrc</code>  -&gt; <code>/etc/bashrc</code></p></li></ul><blockquote><p>一般建议将配置直接添加在 <code>~/.bashrc</code> 中，这样不管是登录式 <code>Shell</code> 还是 非登录式 <code>Shell</code> 都可以读到</p></blockquote><h5 id="PS1这个环境变量有什么⽤"><a href="#PS1这个环境变量有什么⽤" class="headerlink" title="$PS1这个环境变量有什么⽤"></a>$PS1这个环境变量有什么⽤</h5><p>是用来定义命令行的提示符，可以按照我们自己的需求来定义自己喜欢的提示符</p><blockquote><p>$： 提示符。如果是 root 用户，则会显示提示符为”#”；如果是普通用户，则会显示提示符为”$”</p></blockquote><h5 id="在什么情况下需要修改-PATH-应该如何合理地修改它"><a href="#在什么情况下需要修改-PATH-应该如何合理地修改它" class="headerlink" title="在什么情况下需要修改$PATH, 应该如何合理地修改它"></a>在什么情况下需要修改$PATH, 应该如何合理地修改它</h5><p>需要修改环境变量加载一些命令时修改$PATH</p><p>如果永久更改就修改配置文件，临时更改对当前会话有效则命令行修改即可</p><h5 id="修改过-bashrc后-如何让改变⽴即生效"><a href="#修改过-bashrc后-如何让改变⽴即生效" class="headerlink" title="修改过~/.bashrc后, 如何让改变⽴即生效"></a>修改过~/.bashrc后, 如何让改变⽴即生效</h5><p>执行<code>source profile</code>就会立即生效</p><h5 id="bashrc与profile有什么异同点-两者的加载顺序如何"><a href="#bashrc与profile有什么异同点-两者的加载顺序如何" class="headerlink" title="bashrc与profile有什么异同点? 两者的加载顺序如何"></a>bashrc与profile有什么异同点? 两者的加载顺序如何</h5><p>bashrc 用于交互式非登陆，profile用于交互式登陆</p><blockquote><p><code>/etc/profile</code>，<code>/etc/bashrc</code> 是系统全局环境变量设定<br><code>~/.profile</code>，<code>~/.bashrc</code>用户家目录下的私有环境变量设定</p></blockquote><p>加载顺序是 profile 再 bashrc</p><h4 id="FHS与proc"><a href="#FHS与proc" class="headerlink" title="FHS与proc"></a>FHS与proc</h4><h5 id="为什么系统命令会分别放到-bin-sbin-usr-bin-usr-sbin这四个⽬目录中-这些⽬录间有什么区别"><a href="#为什么系统命令会分别放到-bin-sbin-usr-bin-usr-sbin这四个⽬目录中-这些⽬录间有什么区别" class="headerlink" title="为什么系统命令会分别放到/bin, /sbin, /usr/bin, /usr/sbin这四个⽬目录中? 这些⽬录间有什么区别"></a>为什么系统命令会分别放到/bin, /sbin, /usr/bin, /usr/sbin这四个⽬目录中? 这些⽬录间有什么区别</h5><p>首先区别下/sbin和/bin:</p><ul><li><p>从命令功能来看，/sbin 下的命令属于基本的系统命令，如shutdown，reboot，用于启动系统，修复系统，/bin下存放一些普通的基本命令，如ls,chmod等，这些命令在Linux系统里的配置文件脚本里经常用到。</p></li><li><p>从用户权限的角度看，/sbin目录下的命令通常只有管理员才可以运行，/bin下的命令管理员和一般的用户都可以使用。</p></li><li><p>从可运行时间角度看，/sbin,/bin能够在挂载其他文件系统前就可以使用。</p><p>而/usr/bin,/usr/sbin与/sbin /bin目录的区别在于:</p></li><li><p>/bin,/sbin目录是在系统启动后挂载到根文件系统中的，所以/sbin,/bin目录必须和根文件系统在同一分区；</p></li><li><p>/usr/bin,/usr/sbin可以和根文件系统不在一个分区</p></li></ul><h5 id="var目录通常用来放哪些内容-var和-tmp有什么区别"><a href="#var目录通常用来放哪些内容-var和-tmp有什么区别" class="headerlink" title="/var目录通常用来放哪些内容? /var和/tmp有什么区别"></a>/var目录通常用来放哪些内容? /var和/tmp有什么区别</h5><p>/var目录主要针对常态性变动文件，包括缓存（cache）、登录文件（logfile）以及某些软件运行所产生的文件，包括程序文件（lock file，run file），或者例如MySQL数据库的文件等</p><ul><li><p>/var/cache: 应用程序本身运行过程中会产生生的一些暂存文件</p></li><li><p>/var/lib: 程序本身执行的过程中需要使用到的数据文件放置的目录。再次目录下各自的软件应该要有各自的目录。举例来说，Mysql的数据库放置到/var/lib/mysql，而rpm的数据库则放到/var/lib/rpm目录下</p></li><li><p>/var/lock: 某些设备或者是文件资源一次只能被一个应用程序所使用 ，如当系统中有一个刻录机两个人都要使用，那么需要在一个人使用的时候上锁，那么第一个人使用完毕后，第二个人才可以继续使用</p></li><li><p>/var/log: 这个是登录文件放置日志的的目录。里面比较重要的文件/var/log/messages，/var/log/harry(记录登陆者信息)等</p></li><li><p>/var/run/: 某些程序启动服务后，会将他们PID放置在这个目录下</p></li></ul><p>/var和/tmp区别是/var系统产生的不可自动销毁的缓存文件、日志记录，/tmp保存在使用完毕后可随时销毁的缓存文件</p><h5 id="boot目录里有哪些内容"><a href="#boot目录里有哪些内容" class="headerlink" title="/boot目录里有哪些内容"></a>/boot目录里有哪些内容</h5><ul><li>系统Kernel的配置文件</li><li>启动管理程序GRUB的目录，里面存放的都是GRUB在启动时所需要的画面、配置及各阶段（stage1, stage1.5, stage 2）的文件</li><li>Initrd文件，是系统启动时的模块供应的主要来源</li><li>System.map文件时系统Kernel中的变量对应表</li><li>vmlinuz是在启动过程中最重要的一个文件，因为这个文件就是实际系统所使用的kernel</li></ul><h5 id="usr-include和-usr-lib有什么区别"><a href="#usr-include和-usr-lib有什么区别" class="headerlink" title="/usr/include和/usr/lib有什么区别"></a>/usr/include和/usr/lib有什么区别</h5><p>/usr/include（头文件存放处），/usr/lib（库函数存放处）</p><h5 id="proc目录下的那些数字是什么东⻄"><a href="#proc目录下的那些数字是什么东⻄" class="headerlink" title="/proc目录下的那些数字是什么东⻄"></a>/proc目录下的那些数字是什么东⻄</h5><p>目录名即为进程的pid</p><h5 id="如何在proc⽂文件系统中查看CPU和内存信息"><a href="#如何在proc⽂文件系统中查看CPU和内存信息" class="headerlink" title="如何在proc⽂文件系统中查看CPU和内存信息"></a>如何在proc⽂文件系统中查看CPU和内存信息</h5><ul><li><p>CPU: cat /proc/cpuinfo</p></li><li><p>内存: cat /proc/meminfo</p></li></ul><h4 id="⽂件系统"><a href="#⽂件系统" class="headerlink" title="⽂件系统"></a>⽂件系统</h4><h5 id="什么是-inode，它包含哪些内容"><a href="#什么是-inode，它包含哪些内容" class="headerlink" title="什么是 inode，它包含哪些内容"></a>什么是 inode，它包含哪些内容</h5><p>文件数据都储存在”block”中，那应该有一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”</p><p>可以用stat命令，查看某个文件的inode信息，输出中除了文件名以外的所有文件信息，都存在inode之中</p><h5 id="软链接和硬链接的区别是什么"><a href="#软链接和硬链接的区别是什么" class="headerlink" title="软链接和硬链接的区别是什么"></a>软链接和硬链接的区别是什么</h5><p><strong>软链接</strong></p><ul><li>软链接是存放另一个文件的路径的形式存在</li><li>软链接可以跨文件系统，硬链接不可以</li><li>软链接可以对一个不存在的文件名进行链接，硬链接必须要有源文件</li><li>软链接可以对目录进行链接</li></ul><p><strong>硬链接</strong></p><ul><li>硬链接，以文件副本的形式存在。但不占用实际空间</li><li>不允许给目录创建硬链接</li><li>硬链接只有在同一个文件系统中才能创建</li><li>删除其中一个硬链接文件并不影响其他有相同 inode 号的文件</li></ul><blockquote><p>不论是硬链接或软链接都不会将原本的档案复制一份，只会占用非常少量的磁碟空间</p></blockquote><h5 id="为什么不能对目录建立硬链接"><a href="#为什么不能对目录建立硬链接" class="headerlink" title="为什么不能对目录建立硬链接?"></a>为什么不能对目录建立硬链接?</h5><p>硬连接的话，相当于镜像的方式，创建一个目录的硬连接之后，操作系统需要把这个目录下所有的文件都要做一次硬连接（复制一份过去），这样操作系统在访问这个链接的时候要不断去遍历，大大增加复杂度，而且很容易进入死循环</p><h5 id="为什么不能跨设备建立硬链接"><a href="#为什么不能跨设备建立硬链接" class="headerlink" title="为什么不能跨设备建立硬链接"></a>为什么不能跨设备建立硬链接</h5><p>首先，不同的文件系统的文件管理方式不同，甚至有些文件系统不是索引文件系统，并不一定两个文件系统的inode有相同的含义。再者，即使有相同inode含义，硬链接的几个文件，具有相同的inode号码。不同文件系统中，也可能有使用该inode号的文件，这将产生矛盾。</p><h5 id="假设-B-是-A-的-软-硬-链接文件"><a href="#假设-B-是-A-的-软-硬-链接文件" class="headerlink" title="假设 B 是 A 的(软/硬)链接文件"></a>假设 B 是 A 的(软/硬)链接文件</h5><p><strong>对于硬链接和软链接, ⽐较当A或者B被删除时, 各有什什么后果？</strong></p><ul><li>硬链接<ul><li>A 被删除，源数据还在</li><li>B 被删除，源数据还在</li></ul></li><li>软连接<ul><li>A 被删除，数据丢失</li><li>B 被删除，源数据还在</li></ul></li></ul><p><strong>当A不存在时, 能否建⽴A的硬链接B? 能否建立A的软链接B？</strong></p><p>不能建立硬链接，能建立软链接</p><h5 id="LVM是什么，有什么作⽤"><a href="#LVM是什么，有什么作⽤" class="headerlink" title="LVM是什么，有什么作⽤"></a>LVM是什么，有什么作⽤</h5><p>可以将LVM视为”动态分区” ，这意味着你可以在Linux系统运行时从命令行创建/调整大小/删除LVM”分区” （LVM称之为”逻辑卷” ）: 不需要重新引导系统，内核就能知道新创建的或调整大小的分区</p><p>如果有多个硬盘，则逻辑卷可以扩展到多个磁盘: 换句话说，它们不受单个磁盘的大小限制，而不受总大小的限制</p><p>LV可以设置”striped” ，以便将I/O分发到并行承载LV的所有磁盘。类似于RAID-0，但是更容易设置</p><p>你可以创建任意LV的(只读)快照，可以在以后将原始LV恢复到快照，或者在不再需要快照时删除快照，这对于服务器备份(例如，(无法停止所有应用程序写入，创建快照并备份快照))很方便，但是也可用于在关键系统升级(克隆root分区，升级，如果出现问题，很容易恢复)之前提供”安全”</p><h5 id="从安全角度考虑，哪些分区应适当限制⼤小"><a href="#从安全角度考虑，哪些分区应适当限制⼤小" class="headerlink" title="从安全角度考虑，哪些分区应适当限制⼤小"></a>从安全角度考虑，哪些分区应适当限制⼤小</h5><p>？？？</p><h5 id="什么是-RAID，介绍至少3种-level-的-RAID"><a href="#什么是-RAID，介绍至少3种-level-的-RAID" class="headerlink" title="什么是 RAID，介绍至少3种 level 的 RAID"></a>什么是 RAID，介绍至少3种 level 的 RAID</h5><p><img src="/images/blog/2020-05-12-2.png" alt></p><p><strong>RAID0</strong></p><p>数据在从内存缓冲区写入磁盘时，根据磁盘数量将数据分成N份，这些数据同时并发写入N块磁盘，使得数据整体写入速度是一块磁盘的N倍，读取的时候也一样，因此RAID0具有极快的数据读写速度。但是RAID0不做数据备份，N块磁盘中只要有一块损坏，数据完整性就被破坏，所有磁盘的数据都会损坏</p><p><strong>RAID1</strong></p><p>数据在写入磁盘时，将一份数据同时写入两块磁盘，这样任何一块磁盘损坏都不会导致数据丢失，插入一块新磁盘就可以通过复制数据的方式自动修复，具有极高的可靠性</p><p><strong>RAID10</strong></p><p>结合RAID0和RAID1两种方案，将所有磁盘平均分成两份，数据同时在两份磁盘写入，相当于RAID1，但是在每一份磁盘里面的N/2块磁盘上，利用RAID0技术并发读写，既提高可靠性又改善性能，不过RAID10的磁盘利用率较低，有一半的磁盘用来写备份数据</p><h4 id="SUID机制与sudo"><a href="#SUID机制与sudo" class="headerlink" title="SUID机制与sudo"></a>SUID机制与sudo</h4><h5 id="简述SUID机制存在的意义"><a href="#简述SUID机制存在的意义" class="headerlink" title="简述SUID机制存在的意义"></a>简述SUID机制存在的意义</h5><p>SUID就是允许用户在执行程序的时候拥有这个程序属主的权限的一个机制</p><blockquote><p><a href="https://www.meiwen.com.cn/subject/qmqldqtx.html" target="_blank" rel="noopener">SUID的应用场景和简单见解</a></p></blockquote><h5 id="sudo的主配置文件路径是什么-应如何更新这个文件"><a href="#sudo的主配置文件路径是什么-应如何更新这个文件" class="headerlink" title="sudo的主配置文件路径是什么? 应如何更新这个文件?"></a>sudo的主配置文件路径是什么? 应如何更新这个文件?</h5><p><code>/etc/sudoers</code>是sudo的主配置文件</p><p>如果想设置sudo设置，有两种方式</p><ul><li>直接在通过<code>sudo visudo /etc/sudoers</code> 修改<code>/etc/sudoers</code>文件</li><li>在<code>/etc/sudoers.d/username</code>目录下添加一个文件，文件名称就用需要设定的用户名</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 建议在&#x2F;etc&#x2F;sudoers.d&#x2F;下面创建文件编辑</span><br><span class="line"># 这里给oracle2用户一些sudo权限，命令会在sudoers.d目录下创建一个文件的</span><br><span class="line">$ visudo  -f &#x2F;etc&#x2F;sudoers.d&#x2F;oracle2</span><br></pre></td></tr></table></figure><blockquote><p>常用实例讲解</p><p>oracle用户可以在任何地点以任何的身份执行所有命令，等同于root</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oracle ALL&#x3D;(ALL)        ALL</span><br></pre></td></tr></table></figure><p>oracle2用户可以在任何地点以root的身份执行命令useradd(无需密码)和usermod（需要密码）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oracle2 ALL&#x3D;(root) NOPASSWD:&#x2F;usr&#x2F;sbin&#x2F;useradd, PASSWD:&#x2F;usr&#x2F;sbin&#x2F;userdel</span><br></pre></td></tr></table></figure><p>oracle3用户只能在192.168.1.120主机远程登录并以root身份执行ifconfig eth0命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Cmnd_Alias NETCMND &#x3D; &#x2F;sbin&#x2F;ifconfig eth0</span><br><span class="line">oracle3 192.168.1.120 &#x3D; (root) NOPASSWD:NETCMND</span><br></pre></td></tr></table></figure><p>oracle4用户可以执行/usr/sbin下的所有命令除了/usr/sbin/userdel</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oracle4 ALL&#x3D;(ALL) &#x2F;usr&#x2F;sbin&#x2F;,!&#x2F;usr&#x2F;sbin&#x2F;userdel</span><br></pre></td></tr></table></figure></blockquote><p>sudo提供人性化的日志功能，在<code>/var/log/secure</code>日志文件中可以查看到，用于记录所有sudo类用户的所有动作</p><h5 id="如果需要在shell脚本中通过sudo调用某个命令或者程序-应如何配置sudo"><a href="#如果需要在shell脚本中通过sudo调用某个命令或者程序-应如何配置sudo" class="headerlink" title="如果需要在shell脚本中通过sudo调用某个命令或者程序,  应如何配置sudo?"></a>如果需要在shell脚本中通过sudo调用某个命令或者程序,  应如何配置sudo?</h5><p>sudo 的 -S 选项允许从stdin读入密码，使用方式<code>echo [password] | sudo -S [command]</code></p><h5 id="怎样将某个⾼权限程序⼀部分的功能开放给sudo"><a href="#怎样将某个⾼权限程序⼀部分的功能开放给sudo" class="headerlink" title="怎样将某个⾼权限程序⼀部分的功能开放给sudo?"></a>怎样将某个⾼权限程序⼀部分的功能开放给sudo?</h5><p><strong>例如能让用户改⼦网掩码, ⽽不让他修改机器ip地址</strong></p><h4 id="cron"><a href="#cron" class="headerlink" title="cron"></a>cron</h4><h5 id="系统配置⽂件的路径是什么"><a href="#系统配置⽂件的路径是什么" class="headerlink" title="系统配置⽂件的路径是什么?"></a>系统配置⽂件的路径是什么?</h5><p>/etc/crontab</p><h5 id="cron时间描述⾥的’-‘是什么意思-‘-‘是什么意思"><a href="#cron时间描述⾥的’-‘是什么意思-‘-‘是什么意思" class="headerlink" title="cron时间描述⾥的’-‘是什么意思, ‘/‘是什么意思?"></a>cron时间描述⾥的’-‘是什么意思, ‘/‘是什么意思?</h5><p>整数间的短线（-）指定一个整数范围。如，1-4意味着整数 1、2、3、4</p><p>正斜线（/）可以用来指定间隔频率。在范围后加上 /<integer>意味着在范围内可以跳过 integer。如，0-59/2可以用来在分钟字段定义每两分钟。间隔频率值还可以和星号一起使用。例如，*/3的值可以用在月份字段中表示每三个月运行一次任务</integer></p><h5 id="reboot会在什么时候执行"><a href="#reboot会在什么时候执行" class="headerlink" title="@reboot会在什么时候执行?"></a>@reboot会在什么时候执行?</h5><p>希望在系统重启后执行某个命令</p><h5 id="cron的最小粒度是分钟-如何⽤cron实现每分钟跑两次-例如-分别在第0秒和第30秒-运⾏的任务"><a href="#cron的最小粒度是分钟-如何⽤cron实现每分钟跑两次-例如-分别在第0秒和第30秒-运⾏的任务" class="headerlink" title="cron的最小粒度是分钟, 如何⽤cron实现每分钟跑两次(例如, 分别在第0秒和第30秒)运⾏的任务?"></a>cron的最小粒度是分钟, 如何⽤cron实现每分钟跑两次(例如, 分别在第0秒和第30秒)运⾏的任务?</h5><p>起两个cron，其中一个cron 利用sleep休息30秒</p><h4 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h4><h5 id="新⽤户创建时-如果选择⾃动创建⽤户home⽬录-此时home⽬录中⾃动⽣成的内容是从哪⼉来的"><a href="#新⽤户创建时-如果选择⾃动创建⽤户home⽬录-此时home⽬录中⾃动⽣成的内容是从哪⼉来的" class="headerlink" title="新⽤户创建时, 如果选择⾃动创建⽤户home⽬录, 此时home⽬录中⾃动⽣成的内容是从哪⼉来的?"></a>新⽤户创建时, 如果选择⾃动创建⽤户home⽬录, 此时home⽬录中⾃动⽣成的内容是从哪⼉来的?</h5><p>把框架目录(默认为/etc/skel)下的文件复制到用户主目录下</p><h5 id="删除⼀个⽤户时-系统会执⾏哪些操作-改变哪些⽂件"><a href="#删除⼀个⽤户时-系统会执⾏哪些操作-改变哪些⽂件" class="headerlink" title="删除⼀个⽤户时, 系统会执⾏哪些操作, 改变哪些⽂件?"></a>删除⼀个⽤户时, 系统会执⾏哪些操作, 改变哪些⽂件?</h5><p>userdel 会查询系统账户文件，例如 /etc/password 和 /etc/group。那么它会删除所有和用户名相关的条目。在删除它之前，用户名必须存在。</p><p>不带选项使用 userdel，只会删除用户，-r 用于彻底删除，用户HOME目录下的信息会被移除，在其他位置上的档案也将一一找出并删除，比如用户的邮件池，在路径/var/mail/用户名下的邮件</p><h5 id="用户的密码存储在哪个⽂件⾥"><a href="#用户的密码存储在哪个⽂件⾥" class="headerlink" title="用户的密码存储在哪个⽂件⾥?"></a>用户的密码存储在哪个⽂件⾥?</h5><p>Linux 账号文件/etc/passwd，密码文件/etc/shadow</p><h5 id="禁⽌用户登录的⽅式有哪些"><a href="#禁⽌用户登录的⽅式有哪些" class="headerlink" title="禁⽌用户登录的⽅式有哪些?"></a>禁⽌用户登录的⽅式有哪些?</h5><p>命令方式</p><ul><li>已经存在的用户: usermod -s /sbin/nologin</li><li>新用户: useradd -s /sbin/nologin</li></ul><blockquote><p>/bin/false是最严格的禁止login选项，一切服务都不能用</p><p>而/sbin/nologin只是不允许login系统，但可以使用其他ftp等服务</p></blockquote><p>直接修改/etc/passwd</p><p>把需禁止用户的/bin/bash修改为/sbin/nologin</p><h5 id="如何踢用户下线"><a href="#如何踢用户下线" class="headerlink" title="如何踢用户下线"></a>如何踢用户下线</h5><p>Linux系统root用户可强制踢制其它登录用户</p><p>首先可用w命令查看登录用户信息 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ w</span><br><span class="line">14:21:31 up 1 day,  4:57,  2 users,  load average: 0.00, 0.00, 0.00</span><br><span class="line">USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT</span><br><span class="line">root     pts&#x2F;1    192.168.1.200    14:18   21.00s  0.01s  0.01s -bash</span><br><span class="line">root     pts&#x2F;2    192.168.1.200    14:21    0.00s  0.01s  0.00s w</span><br></pre></td></tr></table></figure><p>强制踢人命令格式<code>pkill -kill -t tty</code>比如踢掉第一个root: <code>pkill -kill -t pts/1</code></p><ul><li>只有root用户才能踢人，但任何用户都可以踢掉自己 </li><li>如果同时有二个人用root用户登录，任何其中一个可以踢掉另一个 </li><li>pts/0就是自己开的桌面环境现的第一个终端 </li></ul><h4 id="⽂件传输-scp-vs-rsync"><a href="#⽂件传输-scp-vs-rsync" class="headerlink" title="⽂件传输: scp vs rsync"></a>⽂件传输: scp vs rsync</h4><h5 id="对比默认参数下-两种⽅式消耗的系统资源情况"><a href="#对比默认参数下-两种⽅式消耗的系统资源情况" class="headerlink" title="对比默认参数下, 两种⽅式消耗的系统资源情况"></a>对比默认参数下, 两种⽅式消耗的系统资源情况</h5><p>在都是空目录的情况下同步信息，scp和rsync的执行效率相当，在一个量级，但是当已经同步过一次之后，在后续同步内容的过程中会看到同步的效率rsync快了非常多，这是因为scp是复制，而rsync是覆盖。</p><p>scp消耗资源少，不会提高多少系统负荷，在这一点上，rsync就远远不及它。虽然 rsync比scp会快一点，但当小文件众多的情况，rsync会导致硬盘I/O非常高，而scp基本不影响系统使用</p><h5 id="在服务器端存在对应服务的条件下-哪种方式的传输是有加密的"><a href="#在服务器端存在对应服务的条件下-哪种方式的传输是有加密的" class="headerlink" title="在服务器端存在对应服务的条件下, 哪种方式的传输是有加密的?"></a>在服务器端存在对应服务的条件下, 哪种方式的传输是有加密的?</h5><p>rsync默认不是加密传输，而scp是加密传输，使用时可以按需选择</p><p>rsync如果有加密传输文件的需求，可以自定义加密管道管道协议，使用ssh通道或者vpn通道。使用参数：-e来指定相应的管道协议</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 使用-e参数，指定加密的协议以及协议的端口号</span><br><span class="line">$ rsync -avz &#x2F;etc&#x2F;hosts -e &#39;ssh -p 22&#39; root@172.16.1.41:&#x2F;mnt&#x2F;</span><br></pre></td></tr></table></figure><h5 id="请阐述在scp和rsync的具体适⽤场景"><a href="#请阐述在scp和rsync的具体适⽤场景" class="headerlink" title="请阐述在scp和rsync的具体适⽤场景"></a>请阐述在scp和rsync的具体适⽤场景</h5><p>rsync 背后算法原理可以参考<a href="https://coolshell.cn/articles/7425.html" target="_blank" rel="noopener">RSYNC 的核心算法</a></p><ul><li><p>如果是频繁更新的文件并且是小文件，则建议使用rsync</p></li><li><p>如果是很少更新的文件，建议使用scp，简单方便快捷，同时还是加密传输</p></li></ul><p><strong>即在什么时候应该适用scp⽽不是rsync, 在什么时候应该适用rsync⽽不是scp</strong></p><p>只需传输改动部分，无需重新传输整个文件时用rsync</p><p>点对点传输全量文件时用scp</p><ul><li>rsync只对差异文件做更新，可以做增量或全量备份；而scp只能做全量备份。简单说就是rsync只传修改了的部分，如果改动较小就不需要全部重传，所以rsync备份速度较快；默认情况下，rsync通过比较文件的最后修改时间（mtime）和文件的大小（size）来确认哪些文件需要被同步过去</li><li>rsync是分块校验+传输，scp是整个文件传输。rsync比scp有优势的地方在于单个大文件的一小部分存在改动时，只需传输改动部分，无需重新传输整个文件。如果传输一个新的文件，理论上rsync没有优势</li></ul><h3 id="Linux-实践部分"><a href="#Linux-实践部分" class="headerlink" title="Linux 实践部分"></a>Linux 实践部分</h3><h4 id="top"><a href="#top" class="headerlink" title="top"></a>top</h4><h5 id="如何将top的输出通过管道交给另⼀个进程"><a href="#如何将top的输出通过管道交给另⼀个进程" class="headerlink" title="如何将top的输出通过管道交给另⼀个进程?"></a>如何将top的输出通过管道交给另⼀个进程?</h5><p>top -bn 1  显示所有进程信息</p><ul><li>-b: 在批处理模式下启动top，这对于将top输出发送到其他程序或文件很有用。在此模式下，top将不接受输入，并一直运行到您使用`-n’命令行选项设置的迭代次数限制或终止为止</li><li>指定结束前top应生成的最大迭代次数或帧数</li></ul><p>举例，top翻页: top -bn1 | less</p><h5 id="如何让top显示每一个CPU的使⽤情况"><a href="#如何让top显示每一个CPU的使⽤情况" class="headerlink" title="如何让top显示每一个CPU的使⽤情况?"></a>如何让top显示每一个CPU的使⽤情况?</h5><p>如果要查看每个逻辑cpu的使用率，只需要运行top命令，<strong>按下数字键1即可</strong></p><h5 id="如何在top⾥杀进程"><a href="#如何在top⾥杀进程" class="headerlink" title="如何在top⾥杀进程"></a>如何在top⾥杀进程</h5><p>按下k即可，根据后面输入的PID杀死进程</p><h5 id="top的默认刷新时间是多少-如何修改这个默认设置"><a href="#top的默认刷新时间是多少-如何修改这个默认设置" class="headerlink" title="top的默认刷新时间是多少? 如何修改这个默认设置?"></a>top的默认刷新时间是多少? 如何修改这个默认设置?</h5><p>默认是5s，可以在启动时使用-d指定信息刷新的时间间隔，也可以在交互时键入d命令指定间隔时间</p><h5 id="top⾥的load-average是如何计算的"><a href="#top⾥的load-average是如何计算的" class="headerlink" title="top⾥的load average是如何计算的?"></a>top⾥的load average是如何计算的?</h5><p>指单位时间内，系统处于<strong>可运行状态</strong>和<strong>不可中断状态</strong>的平均进程数，也就是<strong>平均活跃进程数</strong></p><blockquote><p>对于单cpu和多cpu情况，系统的average load情况稍有不同。单cpu是最简单的情形，比如过去的平均一分钟里面，判断系统处于运行或者等待状态的进程数则表示系统的平均负载，但是在linux系统下稍有不同，那些处于io等待状态的进程也会被纳入去计算。这样就导致CPU利用率可能和平均负载很不同，在大部分进程都在做IO的时候，即使平均负载很大，也会没有很大的CPU利用率。另外，有些系统对于进程和线程的处理也很不一样，有的对于每一个线程都会进行计算，有的只关注进程，对于超线程技术的线程来说，可能又是别的处理方式。对于多CPU的平均负载的计算，是在单CPU的情况下再除以CPU的个数</p></blockquote><h5 id="假设top显示ffmpeg进程的CPU使⽤率为143-7-请具体解释这个数值是如何计算出来的"><a href="#假设top显示ffmpeg进程的CPU使⽤率为143-7-请具体解释这个数值是如何计算出来的" class="headerlink" title="假设top显示ffmpeg进程的CPU使⽤率为143.7%, 请具体解释这个数值是如何计算出来的"></a>假设top显示ffmpeg进程的CPU使⽤率为143.7%, 请具体解释这个数值是如何计算出来的</h5><p>ffmpeg进程在多核CPU下，每个CPU使用率的累加和</p><h5 id="第四列的NI是什么意思"><a href="#第四列的NI是什么意思" class="headerlink" title="第四列的NI是什么意思?"></a>第四列的NI是什么意思?</h5><p>任务nice值，代表这个进程的优先值</p><blockquote><p>在LINUX系统中，Nice值的范围从-20到+19（不同系统的值范围是不一样的），正值表示低优先级，负值表示高优先级，值为零则表示不会调整该进程的优先级。具有最高优先级的程序，其nice值最低，所以在LINUX系统中，值-20使得一项任务变得非常重要；与之相反，如果任务的nice为+19，则表示它是一个高尚的、无私的任务，允许所有其他任务比自己享有宝贵的CPU时间的更大使用份额，这也就是nice的名称的来意</p></blockquote><h4 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a>ssh</h4><h5 id="ssh的实现原理"><a href="#ssh的实现原理" class="headerlink" title="ssh的实现原理"></a>ssh的实现原理</h5><ol><li><p>远程主机收到用户的登录请求，把自己的公钥发给用户</p></li><li><p>用户使用这个公钥，将登录密码加密后，发送回来</p></li><li><p>远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录</p></li></ol><h5 id="ssh连接时如何指定远程端口-如何设置连接超时间"><a href="#ssh连接时如何指定远程端口-如何设置连接超时间" class="headerlink" title="ssh连接时如何指定远程端口, 如何设置连接超时间?"></a>ssh连接时如何指定远程端口, 如何设置连接超时间?</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># -p 指定端口</span><br><span class="line"># -o ConnectTimeout&#x3D;5 指定超时时间为5s，最大是2m7s左右</span><br><span class="line"># 如果要获得更大的超时时间，可以通过配置 ConnectionAttempts 来实现</span><br><span class="line">$ ssh -p 22 -o ConnectTimeout&#x3D;5 root@192.168.1.240</span><br></pre></td></tr></table></figure><h5 id="ssh私钥⽂件默认的权限是什么"><a href="#ssh私钥⽂件默认的权限是什么" class="headerlink" title="ssh私钥⽂件默认的权限是什么?"></a>ssh私钥⽂件默认的权限是什么?</h5><p>600，属主是当前用户</p><h5 id="如何利⽤ssh来进行端⼝转发"><a href="#如何利⽤ssh来进行端⼝转发" class="headerlink" title="如何利⽤ssh来进行端⼝转发?"></a>如何利⽤ssh来进行端⼝转发?</h5><p><strong>本地端口转发</strong></p><p>假定host1是本地主机，host2是远程主机。由于种种原因，这两台主机之间无法连通。但是，另外还有一台host3，可以同时连通前面两台主机。因此，很自然的想法就是，通过host3，将host1连上host2</p><p>在host1执行下面的命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh -L 2121:host2:21 host3</span><br></pre></td></tr></table></figure><p>命令中的L参数一共接受三个值，分别是”本地端口:目标主机:目标主机端口”，它们之间用冒号分隔。这条命令的意思，就是指定SSH绑定本地端口2121，然后指定host3将所有的数据，转发到目标主机host2的21端口（假定host2运行FTP，默认端口为21）</p><p>这样一来，只要连接host1的2121端口，就等于连上了host2的21端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ftp localhost:2121</span><br></pre></td></tr></table></figure><p>“本地端口转发”使得host1和host3之间仿佛形成一个数据传输的秘密隧道，因此又被称为”SSH隧道”</p><p>下面是一个比较有趣的例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh -L 5900:localhost:5900 host3</span><br></pre></td></tr></table></figure><p>它表示将本机的5900端口绑定host3的5900端口（这里的localhost指的是host3，因为目标主机是相对host3而言的）</p><p>另一个例子是通过host3的端口转发，ssh登录host2</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh -L 9001:host2:22 host3</span><br></pre></td></tr></table></figure><p>这时，只要ssh登录本机的9001端口，就相当于登录host2了，下面的-p参数表示指定登录端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh -p 9001 localhost</span><br></pre></td></tr></table></figure><p><strong>远程端口转发</strong></p><p>还是接着看上面那个例子，host1与host2之间无法连通，必须借助host3转发。但是，特殊情况出现了，host3是一台内网机器，它可以连接外网的host1，但是反过来就不行，外网的host1连不上内网的host3。这时，”本地端口转发”就不能用了，怎么办？</p><p>解决办法是，既然host3可以连host1，那么就从host3上建立与host1的SSH连接，然后在host1上使用这条连接就可以了</p><p>在host3执行下面的命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">　$ ssh -R 2121:host2:21 host1</span><br></pre></td></tr></table></figure><p>R参数也是接受三个值，分别是”远程主机端口:目标主机:目标主机端口”。这条命令的意思，就是让host1监听它自己的2121端口，然后将所有数据经由host3，转发到host2的21端口。由于对于host3来说，host1是远程主机，所以这种情况就被称为”远程端口绑定”</p><p>绑定之后，我们在host1就可以连接host2了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ftp localhost:2121</span><br></pre></td></tr></table></figure><h5 id="passphrase是什么东西-有什么作用"><a href="#passphrase是什么东西-有什么作用" class="headerlink" title="passphrase是什么东西? 有什么作用?"></a>passphrase是什么东西? 有什么作用?</h5><p>passphrase是对私钥设置的口令，passphrase是用来对密钥对的私钥进行加密的，不会在网络上传播</p><h5 id="在⾃己的电脑上操作，通过-ssh-agent-forward-先登录-A，再从-A-登录-B"><a href="#在⾃己的电脑上操作，通过-ssh-agent-forward-先登录-A，再从-A-登录-B" class="headerlink" title="在⾃己的电脑上操作，通过 ssh agent forward 先登录 A，再从 A 登录 B"></a>在⾃己的电脑上操作，通过 ssh agent forward 先登录 A，再从 A 登录 B</h5><p><a href="https://www.jianshu.com/p/12de50582e63" target="_blank" rel="noopener">SSH &amp; SSH agent forward</a></p><h4 id="find"><a href="#find" class="headerlink" title="find"></a>find</h4><h5 id="find能根据哪些条件来查找⽂件"><a href="#find能根据哪些条件来查找⽂件" class="headerlink" title="find能根据哪些条件来查找⽂件"></a>find能根据哪些条件来查找⽂件</h5><ul><li>指搜索层级</li><li>根据文件名和inode查找</li><li>根据属主、属组查找</li><li>根据文件类型查找</li><li>空文件或目录</li><li>组合条件</li><li>根据文件大小来查找</li><li>根据时间戳</li><li>根据权限查找</li></ul><h5 id="find能否根据⽂件内容来搜索，-为什么"><a href="#find能否根据⽂件内容来搜索，-为什么" class="headerlink" title="find能否根据⽂件内容来搜索， 为什么?"></a>find能否根据⽂件内容来搜索， 为什么?</h5><p>不能，但是可以配合grep 命令来</p><p><code>find / | xargs grep function</code>查找系统根目录下面的所有文件的内容中包含有function字符串的文件列表</p><h5 id="find可以如何删除找到的⽂件-请提供三种方法"><a href="#find可以如何删除找到的⽂件-请提供三种方法" class="headerlink" title="find可以如何删除找到的⽂件? 请提供三种方法"></a>find可以如何删除找到的⽂件? 请提供三种方法</h5><p>以删除目录下所有exe文件为例</p><ul><li>find . -name -type f  “*.exe” | xargs rm -rf</li><li>find . -name ‘’*.exe” -type f -print -exec rm -rf {} ;</li><li>find  ./ -iname “*.exe” -ok rm {} ;</li><li>find  ./ -iname “*.exe” -delete</li></ul><h5 id="mtime-ctime-atime的区别"><a href="#mtime-ctime-atime的区别" class="headerlink" title="mtime, ctime, atime的区别"></a>mtime, ctime, atime的区别</h5><ul><li>atime:（access time）显示的是文件中的数据最后被访问的时间，比如系统的进程直接使用或通过一些命令和脚本间接使用。（执行一些可执行文件或脚本）</li><li>mtime:（modify time）显示的是文件内容被修改的最后时间，比如用vi编辑时就会被改变。（也就是Block的内容）</li><li>ctime:（change time）显示的是文件的权限、拥有者、所属的组、链接数发生改变时的时间。当然当内容改变时也会随之改变（即inode内容发生改变和Block内容发生改变时</li></ul><blockquote><p>有一个要注意的就是，在kernel 2.6.30之前，文件系统中默认会及时的更新atime，而在此之后的版本里有变化<br>Linux atime修改策略与 mount 有关，可选的值有 noatime、relatime 和 strictatime</p><ul><li>noatime: atime不会被更新，即使修改了文件内容</li><li>relatime:<ul><li>如果一个文件的 atime 比 ctime 或 mtime 更早，此时你去读取了该文件，atime 才会被更新为当前时间。</li><li>atime 比现在早一天，那么 atime 在文件读取时会被更新</li></ul></li><li>strictatime: atime 在文件每次被读取时，都能够被更新</li></ul><p>所以只有发生以下三种情况之一才会更新atime</p><ul><li>将分区 mount 的挂载的时候指定采用非 relatime 方式，使用方法就是通过<code>mount -o relatime /dir</code>来挂装目录</li><li>atime 小于 ctime 或者小于 mtime 的时候</li><li>本次的 access time 和上次的 atime 超过24个小时</li></ul></blockquote><h5 id="type中有哪些常⻅类型"><a href="#type中有哪些常⻅类型" class="headerlink" title="-type中有哪些常⻅类型?"></a>-type中有哪些常⻅类型?</h5><p>b      block (buffered) special</p><ul><li>c: character (unbuffered) special</li><li>d: directory</li><li>p: named pipe (FIFO)</li><li>f: regular file</li><li>l: symbolic  link;  this  is never true if the -L option or the -follow option is in effect, unless the symbolic link is broken.  If you want to search for symbolic links when -L is in effect, use -xtype.</li><li>s: socket</li><li>D: door (Solaris)</li></ul><h4 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h4><h5 id="了解-c-v-A-B-C-E-n-i-R参数的意义"><a href="#了解-c-v-A-B-C-E-n-i-R参数的意义" class="headerlink" title="了解-c/-v/-A/-B/-C/-E/-n/-i/-R参数的意义"></a>了解-c/-v/-A/-B/-C/-E/-n/-i/-R参数的意义</h5><ul><li>-c: 统计匹配到的次数</li><li>-v: 查找不包含指定内容的行</li><li>-A: 显示匹配行及前面多少行, 如: -A3, 则表示显示匹配行及前3行</li><li>-B: 显示匹配行及后面多少行, 如: -B3, 则表示显示匹配行及后3行</li><li>-C: 显示匹配行前后多少行,   如: -C3, 则表示显示批量行前后3行</li><li>-E: –extended-regexp的缩写，将模式解释为一个扩展的正则表达式</li><li>-n: 显示行号</li><li>-i: 不区分大小写</li><li>-R: 递归地读取每个目录下的所有文件。遵循所有符号链接，不像-r</li><li>-w: 按单词搜索</li><li>-e: 使用正则搜索</li><li>-r: 逐层遍历目录查找</li><li>–color: 匹配到的内容高亮显示</li><li>–include: 指定匹配的文件类型</li><li>–exclude: 过滤不需要匹配的文件类型</li><li>-q: 不显示任何信息</li><li>-o: 只显示匹配PATTERN 部分</li></ul><h5 id="对于-q-o参数-给出具体的使用场景"><a href="#对于-q-o参数-给出具体的使用场景" class="headerlink" title="对于-q/-o参数, 给出具体的使用场景"></a>对于-q/-o参数, 给出具体的使用场景</h5><p>-q 场景用于是否能够匹配，通过$?知道命令的执行结果来确认是否匹配到信息，避免泄漏信息</p><p>-o 场景用于知道匹配到的文件，不需要过多知道匹配到的行信息，避免泄漏 </p><h4 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h4><h5 id="对于ls-l的输出中的第⼀列-给出每个字符的含义"><a href="#对于ls-l的输出中的第⼀列-给出每个字符的含义" class="headerlink" title="对于ls -l的输出中的第⼀列, 给出每个字符的含义"></a>对于ls -l的输出中的第⼀列, 给出每个字符的含义</h5><p>第一个字符如果是d表示目录，空为文件</p><p>从r 读权限，w 写权限，x执行权限</p><h5 id="目录的⼤小是什么意思"><a href="#目录的⼤小是什么意思" class="headerlink" title="目录的⼤小是什么意思?"></a>目录的⼤小是什么意思?</h5><p>用ls命令出来的目录大小，不包括里面的文件大小</p><p>基本上用ls命令查看到的目录大小都是4K（假设块大小为4K）</p><h5 id="ls默认的排序⽅式是什么-有哪些参数能改变这⼀行为"><a href="#ls默认的排序⽅式是什么-有哪些参数能改变这⼀行为" class="headerlink" title="ls默认的排序⽅式是什么? 有哪些参数能改变这⼀行为?"></a>ls默认的排序⽅式是什么? 有哪些参数能改变这⼀行为?</h5><p>默认会以文件名排序</p><p>-S 基于文件大小进行排序；-t 基于文件修改时间进行排序；-r 将排序结果反向输出</p><p>-f 直接列出结果，而不进行排序</p><h5 id="对于-R-i参数-请给出具体的使⽤场景"><a href="#对于-R-i参数-请给出具体的使⽤场景" class="headerlink" title="对于-R/-i参数, 请给出具体的使⽤场景"></a>对于-R/-i参数, 请给出具体的使⽤场景</h5><p>-R 若目录下有文件，则以下之文件亦皆依序列出</p><p>-i 打印每个文件、目录的索引号</p><p>需要查看子目录下的文件时，使用-R，需要知道索引号时使用 -i</p><h4 id="df-du"><a href="#df-du" class="headerlink" title="df/du"></a>df/du</h4><h5 id="如何显示inode占用率"><a href="#如何显示inode占用率" class="headerlink" title="如何显示inode占用率?"></a>如何显示inode占用率?</h5><p>df -ih</p><h5 id="如何显示⽂件系统的类型"><a href="#如何显示⽂件系统的类型" class="headerlink" title="如何显示⽂件系统的类型?"></a>如何显示⽂件系统的类型?</h5><p>df -Th</p><h5 id="什么情况下⽤rm删除了一个⼤文件，df显示的空余⼤小会没有变化"><a href="#什么情况下⽤rm删除了一个⼤文件，df显示的空余⼤小会没有变化" class="headerlink" title="什么情况下⽤rm删除了一个⼤文件，df显示的空余⼤小会没有变化"></a>什么情况下⽤rm删除了一个⼤文件，df显示的空余⼤小会没有变化</h5><p>参考自<a href="https://blog.51cto.com/ixdba/1435781" target="_blank" rel="noopener">运维实战案例之文件已删除但空间不释放问题解析</a>，文中问题是删除access_log文件空间未释放</p><p><strong>解决思路</strong></p><p>一般说来不会出现删除文件后空间不释放的情况，但是也存在例外，比如文件被进程锁定，或者有进程一直在向这个文件写数据等等，要理解这个问题，就需要知道Linux下文件的存储机制和存储结构。</p><p>一个文件在文件系统中的存放分为两个部分：数据部分和指针部分，指针位于文件系统的meta-data中，数据被删除后，这个指针就从meta-data中清除了，而数据部分存储在磁盘中，数据对应的指针从meta-data中清除后，文件数据部分占用的空间就可以被覆盖并写入新的内容，之所以出现删除access_log文件后，空间还没释放，就是因为httpd进程还在一直向这个文件写入内容，导致虽然删除了access_log文件，但文件对应的指针部分由于进程锁定，并未从meta-data中清除，而由于指针并未被删除，那么系统内核就认为文件并未被删除，因此通过df命令查询空间并未释放也就不足为奇了</p><p><strong>问题排查</strong></p><p>既然有了解决问题的思路，那么接下来看看是否有进程一直在向acess.log文件中写数据，这里需要用到Linux下的lsof命令，通过<code>lsof | grep delete</code>命令可以获取一个已经被删除但仍然被应用程序占用的文件列表</p><p>从输出结果可以看到，/tmp/acess.log文件被进程httpd锁定，而httpd进程还一直向这个文件写入日志数据，从第七列可知，这个日志文件大小仅70G，而系统根分区总大小才100G，由此可知，这个文件就是导致系统根分区空间耗尽的罪魁祸首，在最后一列的“deleted”状态，说明这个日志文件已经被删除，但由于进程还在一直向此文件写入数据，空间并未释放</p><p><strong>解决问题</strong></p><p>最简单的方法是关闭或者重启httpd进程，不过这并不是最好的方法，对待这种进程不停对文件写日志的操作，要释放文件占用的磁盘空间，最好的方法是在线清空这个文件，通过以下命令完成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot; &quot; &gt;&#x2F;tmp&#x2F;acess.log</span><br></pre></td></tr></table></figure><p>通过这种方法，磁盘空间不但可以马上释放，也可保障进程继续向文件写入日志，这种方法经常用于在线清理Apache、Tomcat、Nginx等Web服务产生的日志文件</p><h5 id="如何仅显示某个⽬录下⽂件的总⼤小"><a href="#如何仅显示某个⽬录下⽂件的总⼤小" class="headerlink" title="如何仅显示某个⽬录下⽂件的总⼤小"></a>如何仅显示某个⽬录下⽂件的总⼤小</h5><p>du -sh 目录名</p><h5 id="请解释如何产⽣一个⽂件空洞"><a href="#请解释如何产⽣一个⽂件空洞" class="headerlink" title="请解释如何产⽣一个⽂件空洞"></a>请解释如何产⽣一个⽂件空洞</h5><p>![image-20200409135546433](/Users/tu/Library/Application Support/typora-user-images/image-20200409135546433.png)</p><p>在UNIX文件操作中，文件位移量可以大于文件的当前长度</p><blockquote><p>在这种情况下，对该文件的下一次写将延长该文件，并在文件中构成一个空洞。位于文件中但没有写过的字节都被设为 0</p></blockquote><p>如果 offset 比文件的当前长度更大，下一个写操作就会把文件”撑大（extend）”在文件里创造”空洞（hole）”</p><blockquote><p>没有被实际写入文件的所有字节由重复的 0 表示。空洞是否占用硬盘空间是由文件系统（file system）决定的</p></blockquote><h5 id="如果发现了-df-和-du-两个命令的输出磁盘占⽤量不一致，可能原因有哪些"><a href="#如果发现了-df-和-du-两个命令的输出磁盘占⽤量不一致，可能原因有哪些" class="headerlink" title="如果发现了 df 和 du 两个命令的输出磁盘占⽤量不一致，可能原因有哪些"></a>如果发现了 df 和 du 两个命令的输出磁盘占⽤量不一致，可能原因有哪些</h5><p>常见的df和du不一致情况就是文件删除的问题。当一个文件被删除后，在文件系统 目录中已经不可见了，所以du就不会再统计它了。然而如果此时还有运行的进程持有这个已经被删除了的文件的句柄，那么这个文件就不会真正在磁盘中被删除， 分区超级块中的信息也就不会更改。这样df仍旧会统计这个被删除了的文件</p><blockquote><p>硬盘空间消失是因为删除的文件被其他程序引用，导致空间无法回收</p></blockquote><h4 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h4><h5 id="ps-auxww默认是按照什么进⾏排序的"><a href="#ps-auxww默认是按照什么进⾏排序的" class="headerlink" title="ps auxww默认是按照什么进⾏排序的?"></a>ps auxww默认是按照什么进⾏排序的?</h5><p><code>auxww</code>参数解释</p><ul><li><code>a</code>选项显示出所有运行进程的内容， 而不仅仅是您的进程</li><li><code>u</code>选项显示出进程所归属的用户名字以及内存使用，</li><li><code>x</code> 选项显示出后台进程</li><li><code>ww</code> 选项表示把每个进程的整个命令行全部显示完， 而不是由于命令行过长就把它从屏幕上截去</li></ul><p>默认情况下，输出不排序</p><h5 id="如何用ps来查看进程树"><a href="#如何用ps来查看进程树" class="headerlink" title="如何用ps来查看进程树"></a>如何用ps来查看进程树</h5><p>ps -e f</p><p>ps -e -H</p><h5 id="如何⽤ps来查看单个线程的资源使⽤情况"><a href="#如何⽤ps来查看单个线程的资源使⽤情况" class="headerlink" title="如何⽤ps来查看单个线程的资源使⽤情况?"></a>如何⽤ps来查看单个线程的资源使⽤情况?</h5><p>-L用于显示线程</p><p>ps -eLf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ps -eLf</span><br><span class="line">UID PID PPID LWP C NLWP STIME TTY TIME CMD</span><br><span class="line">root 1 0 1 0 1 08:31 ? 00:00:00 init [5]</span><br><span class="line">root 2 1 2 0 1 08:31 ? 00:00:00 [migration&#x2F;0]</span><br><span class="line">root 2233 2228 2233 3 8 08:35 ? 00:04:50 &#x2F;root&#x2F;firefox&#x2F;firefox-bin</span><br><span class="line">root 2233 2228 2271 0 8 08:36 ? 00:00:00 &#x2F;root&#x2F;firefox&#x2F;firefox-bin</span><br><span class="line">root 2233 2228 2272 0 8 08:36 ? 00:00:01 &#x2F;root&#x2F;firefox&#x2F;firefox-bin</span><br><span class="line">root 2233 2228 2277 0 8 08:36 ? 00:00:00 &#x2F;root&#x2F;firefox&#x2F;firefox-bin</span><br><span class="line">root 2233 2228 2278 0 8 08:36 ? 00:00:00 &#x2F;root&#x2F;firefox&#x2F;firefox-bin</span><br><span class="line">root 2233 2228 2279 0 8 08:36 ? 00:00:00 &#x2F;root&#x2F;firefox&#x2F;firefox-bin</span><br></pre></td></tr></table></figure><p>LWP　light weight process ID 可以称其为线程ID<br>NLWP 进程中的线程数number of lwps (threads) in the process</p><h4 id="cut"><a href="#cut" class="headerlink" title="cut"></a>cut</h4><h5 id="cut默认的分隔符是什么-如何设置分隔符"><a href="#cut默认的分隔符是什么-如何设置分隔符" class="headerlink" title="cut默认的分隔符是什么? 如何设置分隔符?"></a>cut默认的分隔符是什么? 如何设置分隔符?</h5><p> -d自定义分隔符，默认为制表符</p><h5 id="对于每⼀行-如何让cut仅显示第3到第5列"><a href="#对于每⼀行-如何让cut仅显示第3到第5列" class="headerlink" title="对于每⼀行, 如何让cut仅显示第3到第5列?"></a>对于每⼀行, 如何让cut仅显示第3到第5列?</h5><p>-f 参数指定 3-5</p><h5 id="对于每⼀行-如何让cut仅显示第10到第15个字符"><a href="#对于每⼀行-如何让cut仅显示第10到第15个字符" class="headerlink" title="对于每⼀行, 如何让cut仅显示第10到第15个字符?"></a>对于每⼀行, 如何让cut仅显示第10到第15个字符?</h5><p>-c 以字符为单位进行分割，-f 指定10-15</p><h5 id="在什么情况下-c和-b的输出有区别"><a href="#在什么情况下-c和-b的输出有区别" class="headerlink" title="在什么情况下, -c和-b的输出有区别?"></a>在什么情况下, -c和-b的输出有区别?</h5><p>-b: 以字节为单位进行分割，-c: 以字符为单位进行分割，多字节字符时就输出有区别了</p><h4 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h4><h5 id="如何对每⾏第3列进⾏排序"><a href="#如何对每⾏第3列进⾏排序" class="headerlink" title="如何对每⾏第3列进⾏排序?"></a>如何对每⾏第3列进⾏排序?</h5><p>-k3，-k指定要排序的key，key由字段组成。key格式为”POS1[,POS2]”，POS1为key起始位置，POS2为key结束位置</p><h5 id="请给出具体例子说明什么情况下使⽤了-n会导致sort的输出和不加-n不一致"><a href="#请给出具体例子说明什么情况下使⽤了-n会导致sort的输出和不加-n不一致" class="headerlink" title="请给出具体例子说明什么情况下使⽤了-n会导致sort的输出和不加-n不一致"></a>请给出具体例子说明什么情况下使⽤了-n会导致sort的输出和不加-n不一致</h5><p>当排序列为数值时，使用-n选项，来告诉sort要以数值来排序，不加-n则是以字典序排序</p><h5 id="请了解-u-r的意义"><a href="#请了解-u-r的意义" class="headerlink" title="请了解-u/-r的意义"></a>请了解-u/-r的意义</h5><p>-r默认是升序排序，使用该选项将得到降序排序的结果，-r不参与排序动作，只是操作排序完成后的结果</p><p>-u只输出重复行的第一行。结合”-f”使用时，重复的小写行被丢弃。 </p><h5 id="默认的分隔符是什么-如何指定分隔符"><a href="#默认的分隔符是什么-如何指定分隔符" class="headerlink" title="默认的分隔符是什么? 如何指定分隔符?"></a>默认的分隔符是什么? 如何指定分隔符?</h5><p>-t&lt;分隔字符&gt;: 指定排序时所用的栏位分隔字符</p><h5 id="请给出-T参数的使⽤场景"><a href="#请给出-T参数的使⽤场景" class="headerlink" title="请给出-T参数的使⽤场景"></a>请给出-T参数的使⽤场景</h5><p>sort命令在进行大文件排序，会自动使用外排序，此时默认会在/tmp目录下新建一个大文件，排序完成后删除，产生的临时文件是隐藏文件，解决办法是使用-T参数指定临时文件目录</p><h4 id="tail-head"><a href="#tail-head" class="headerlink" title="tail/head"></a>tail/head</h4><h5 id="如何取得⼀个⽂件的前几个字符"><a href="#如何取得⼀个⽂件的前几个字符" class="headerlink" title="如何取得⼀个⽂件的前几个字符?"></a>如何取得⼀个⽂件的前几个字符?</h5><p>head -c&lt;字符数&gt; finename</p><h5 id="tail-f是⼲什么的"><a href="#tail-f是⼲什么的" class="headerlink" title="tail -f是⼲什么的?"></a>tail -f是⼲什么的?</h5><p>tail命令用于输入文件中的尾部内容，-f 显示文件最新追加的内容</p><h5 id="如何用tail显示从第25⾏开始-显示⼀个40多⾏-不不知道具体数目-的⽂件的内容"><a href="#如何用tail显示从第25⾏开始-显示⼀个40多⾏-不不知道具体数目-的⽂件的内容" class="headerlink" title="如何用tail显示从第25⾏开始, 显示⼀个40多⾏(不不知道具体数目)的⽂件的内容?"></a>如何用tail显示从第25⾏开始, 显示⼀个40多⾏(不不知道具体数目)的⽂件的内容?</h5><p>tail -n +25</p><h5 id="请提供两种不同的办法来打印⼀个文件的第50⾏内容"><a href="#请提供两种不同的办法来打印⼀个文件的第50⾏内容" class="headerlink" title="请提供两种不同的办法来打印⼀个文件的第50⾏内容"></a>请提供两种不同的办法来打印⼀个文件的第50⾏内容</h5><p>![image-20200409162429804](/Users/tu/Library/Application Support/typora-user-images/image-20200409162429804.png)</p><p>head -n 50，输出最后一行就是第50⾏内容</p><p>tail -n +50，输出第一行就是第50⾏内容</p><h4 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h4><h5 id="直接⽆参数启动这个命令，能得到哪些数据"><a href="#直接⽆参数启动这个命令，能得到哪些数据" class="headerlink" title="直接⽆参数启动这个命令，能得到哪些数据?"></a>直接⽆参数启动这个命令，能得到哪些数据?</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ iostat</span><br><span class="line">Linux 3.10.0-514.26.2.el7.x86_64 (iZbp144crtihiqovt4h5m4Z) 2020年04月09日 _x86_64_(1 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           2.31    0.00    1.23    0.01    0.00   96.44</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read&#x2F;s    kB_wrtn&#x2F;s    kB_read    kB_wrtn</span><br><span class="line">vda               0.43         1.80         3.29   38783769   70867288</span><br></pre></td></tr></table></figure><h5 id="如何持续监控某块硬盘的读写情况"><a href="#如何持续监控某块硬盘的读写情况" class="headerlink" title="如何持续监控某块硬盘的读写情况?"></a>如何持续监控某块硬盘的读写情况?</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ iostat -d vda -x 2</span><br><span class="line">Linux 3.10.0-514.26.2.el7.x86_64 (iZbp144crtihiqovt4h5m4Z) 2020年04月09日 _x86_64_(1 CPU)</span><br><span class="line"></span><br><span class="line">Device:         rrqm&#x2F;s   wrqm&#x2F;s     r&#x2F;s     w&#x2F;s    rkB&#x2F;s    wkB&#x2F;s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">vda               0.00     0.16    0.06    0.37     1.80     3.29    23.76     0.00    6.74    6.57    6.77   0.48   0.02</span><br></pre></td></tr></table></figure><p>-d: 仅显示磁盘统计信息，接硬盘名可以指定某块具体硬盘，这里没有给出硬盘路径就是默认全部</p><p>-x: 输出扩展信息</p><h5 id="iostat的输出中，哪些输出对于诊断磁盘IO问题⽐较关键"><a href="#iostat的输出中，哪些输出对于诊断磁盘IO问题⽐较关键" class="headerlink" title="iostat的输出中，哪些输出对于诊断磁盘IO问题⽐较关键?"></a>iostat的输出中，哪些输出对于诊断磁盘IO问题⽐较关键?</h5><p>%iowait: 如果该值较高，表示磁盘存在I/O瓶颈</p><p>%util: 一秒中有百分之多少的时间用于I/O操作，即被IO消耗的CPU百分比，一般地，如果该参数是100%表示设备已经接近满负荷运行了</p><p>avgqu-sz: 如果avgqu-sz比较大，也表示有当量io在等待</p><h5 id="tps是什么东西-这个值正常情况下会在哪个范围内波动"><a href="#tps是什么东西-这个值正常情况下会在哪个范围内波动" class="headerlink" title="tps是什么东西? 这个值正常情况下会在哪个范围内波动?"></a>tps是什么东西? 这个值正常情况下会在哪个范围内波动?</h5><p>TPS: Transactions Per Second（每秒传输的事物处理个数）</p><p>TPS波动范围= TPS标准差/TPS平均值* 100%. 在5%内算是正常的</p><h4 id="ip"><a href="#ip" class="headerlink" title="ip"></a>ip</h4><h5 id="查看arp表"><a href="#查看arp表" class="headerlink" title="查看arp表"></a>查看arp表</h5><p>ARP表，它记录着主机的IP地址和MAC地址的对应关系</p><p>ARP协议: ARP协议是工作在网络层的协议，它负责将IP地址解析为MAC地址</p><p>ip neigh</p><h5 id="查看有哪些端⼝"><a href="#查看有哪些端⼝" class="headerlink" title="查看有哪些端⼝"></a>查看有哪些端⼝</h5><h5 id="查看ip地址"><a href="#查看ip地址" class="headerlink" title="查看ip地址"></a>查看ip地址</h5><p>Ip a</p><h5 id="查看路由表"><a href="#查看路由表" class="headerlink" title="查看路由表"></a>查看路由表</h5><p>ip route</p><h5 id="使⽤ip命令设置ip地址"><a href="#使⽤ip命令设置ip地址" class="headerlink" title="使⽤ip命令设置ip地址"></a>使⽤ip命令设置ip地址</h5><p>设置IP: ip addr add 192.168.0.123/24 dev eth0</p><p>删除配置的IP: ip add del 192.168.0.123/24 dev eth0</p><h4 id="ss-netstat"><a href="#ss-netstat" class="headerlink" title="ss/netstat"></a>ss/netstat</h4><h5 id="查看当前监听的端⼝，并显示监听端⼝的进程-PID"><a href="#查看当前监听的端⼝，并显示监听端⼝的进程-PID" class="headerlink" title="查看当前监听的端⼝，并显示监听端⼝的进程 PID"></a>查看当前监听的端⼝，并显示监听端⼝的进程 PID</h5><p>netstat -anlp | grep 80</p><h4 id="wget"><a href="#wget" class="headerlink" title="wget"></a>wget</h4><h5 id="如何用wget发⼀个HTTP-POST请求"><a href="#如何用wget发⼀个HTTP-POST请求" class="headerlink" title="如何用wget发⼀个HTTP POST请求"></a>如何用wget发⼀个HTTP POST请求</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget --post-data&#x3D;&quot;user&#x3D;user1&amp;pass&#x3D;pass1&amp;submit&#x3D;Login&quot;  http:&#x2F;&#x2F;domain.com&#x2F;path&#x2F;page_need_login.php</span><br></pre></td></tr></table></figure><h5 id="请简述wget续传-重复下载的逻辑及相关参数"><a href="#请简述wget续传-重复下载的逻辑及相关参数" class="headerlink" title="请简述wget续传/重复下载的逻辑及相关参数"></a>请简述wget续传/重复下载的逻辑及相关参数</h5><p>当文件特别大或者网络特别慢的时候，往往一个文件还没有下载完，连接就已经被切断，此时就需要断点续传。wget的断点续传是自动的，只需要使用-c参数</p><p>重复下载最简单的做法只需要 加上 -O 就可以</p><h5 id="O和-o参数有什么区别"><a href="#O和-o参数有什么区别" class="headerlink" title="-O和-o参数有什么区别?"></a>-O和-o参数有什么区别?</h5><p>使用wget -O下载并以不同的文件名保存(-O：下载文件到对应目录，并且修改文件名称)，-o将所有消息记录到日志文件</p><h4 id="screen"><a href="#screen" class="headerlink" title="screen"></a>screen</h4><h5 id="这个命令是⽤来做什么的"><a href="#这个命令是⽤来做什么的" class="headerlink" title="这个命令是⽤来做什么的?"></a>这个命令是⽤来做什么的?</h5><p>用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换</p><h5 id="如何继续上⼀次的会话"><a href="#如何继续上⼀次的会话" class="headerlink" title="如何继续上⼀次的会话?"></a>如何继续上⼀次的会话?</h5><p>查看所有会话</p><p>screen -ls</p><p>重新连接会话，12865 为会话id</p><p>screen -r 12865</p><h5 id="如何⼿工保存⼀个会话"><a href="#如何⼿工保存⼀个会话" class="headerlink" title="如何⼿工保存⼀个会话?"></a>如何⼿工保存⼀个会话?</h5><p><strong>在每个screen session 下，所有命令都以 ctrl+a(C-a) 开始</strong></p><p>C-a d -&gt; detach，暂时离开当前session，将目前的 screen session (可能含有多个 windows) 丢到后台执行，并会回到还没进 screen 时的状态</p><h4 id="touch"><a href="#touch" class="headerlink" title="touch"></a>touch</h4><h5 id="touch修改文件的atime和mtime"><a href="#touch修改文件的atime和mtime" class="headerlink" title="touch修改文件的atime和mtime"></a>touch修改文件的atime和mtime</h5><p>touch  -a filename: 更新文件的atime和ctime</p><p>touch -m filename: 更新文件的mtime和ctime</p><p>touch -r  参考文件名 目标文件名: 将目标文件的的atime和mtime更改为参考文件的时间并更新ctime</p><blockquote><p>Linux是如何更新访问时间的，这里须得明白下面一点，其更新策略为，当满足以下任意一条件时才更新访问时间</p><ul><li>访问时间早于修改时间或改变时间</li><li>距离上次更新时间间隔大于24h</li></ul></blockquote><h4 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h4><h5 id="Docker和虚拟机的区别"><a href="#Docker和虚拟机的区别" class="headerlink" title="Docker和虚拟机的区别"></a>Docker和虚拟机的区别</h5><p><strong>服务器</strong>好比运输码头: 拥有场地和各种设备（服务器硬件资源）</p><p><strong>服务器虚拟化</strong>好比作码头上的仓库: 拥有独立的空间堆放各种货物或集装箱(仓库之间完全独立，独立的应用系统和操作系统）</p><p><strong>Docker</strong>比作集装箱: 各种货物的打包</p><h5 id="熟悉Dockerfile编写"><a href="#熟悉Dockerfile编写" class="headerlink" title="熟悉Dockerfile编写"></a>熟悉Dockerfile编写</h5><p><a href="https://www.cnblogs.com/zpcoding/p/11450686.html" target="_blank" rel="noopener">docker—Dockerfile编写</a></p><p><a href="https://yeasy.gitbooks.io/docker_practice/image/build.html" target="_blank" rel="noopener">使用 Dockerfile 定制镜像</a></p><h5 id="熟悉docker常⽤用指令和参数-打包-查看-拉取-运行-设置环境变量-挂载⽬录"><a href="#熟悉docker常⽤用指令和参数-打包-查看-拉取-运行-设置环境变量-挂载⽬录" class="headerlink" title="熟悉docker常⽤用指令和参数: 打包/查看/拉取/运行/设置环境变量/挂载⽬录"></a>熟悉docker常⽤用指令和参数: 打包/查看/拉取/运行/设置环境变量/挂载⽬录</h5><ul><li><p>打包: docker image build -t koa-demo:0.0.1 .</p><blockquote><p>有Dockerfile 文件之后，可以使用<code>docker image build</code>命令创建 image 文件</p></blockquote></li><li><p>查看本机image文件: docker image ls</p></li><li><p>删除本机image文件: docker rmi [imageID]</p></li><li><p>拉取: docker image pull library/hello-world </p><blockquote><p><code>library/hello-world</code>是 image 文件在仓库里面的位置，其中<code>library</code>是 image 文件所在的组，<code>hello-world</code>是 image 文件的名字</p></blockquote></li><li><p>运行: docker container run hello-world</p><blockquote><p><code>docker container run</code>命令会从 image 文件，生成一个正在运行的容器实例</p><p>注意，<code>docker container run</code>命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的<code>docker image pull</code>命令并不是必需的步骤</p></blockquote></li><li><p>查看本机正在运行的容器: docker container ls</p></li><li><p>查看本机所有容器，包括终止运行的容器: docker container ls –all</p><blockquote><p><strong>image 文件生成的容器实例，本身也是一个文件，称为容器文件。</strong>也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已</p></blockquote></li><li><p>终止: docker container kill [containID]</p><blockquote><p>对于那些不会自动终止的容器，必须使用<a href="https://docs.docker.com/engine/reference/commandline/container_kill/" target="_blank" rel="noopener"><code>docker container kill</code></a> 命令手动终止</p></blockquote></li><li><p>删除终止运行的容器文件: docker container rm [containerID]</p><blockquote><p>终止运行的容器文件，依然会占据硬盘空间</p></blockquote></li><li><p>设置环境变量: docker run –env VARIABLE=VALUE image:tag</p><blockquote><p>可以使用简写 -e 替换 –env</p></blockquote></li><li><p>挂载目录: docker run -it -v /test:/soft centos</p><blockquote><p>启动一个centos容器，宿主机的/test目录挂载到容器的/soft目录</p></blockquote></li><li><p>查看镜像/容器详细信息: docker inspect NAME|ID</p></li></ul><h5 id="Docker⽹络类型，以及Docker对主机上的iptables的影响"><a href="#Docker⽹络类型，以及Docker对主机上的iptables的影响" class="headerlink" title="Docker⽹络类型，以及Docker对主机上的iptables的影响"></a>Docker⽹络类型，以及Docker对主机上的iptables的影响</h5><p>查看容器的详细信息（可以查看网络类型Networks）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker network ls</span><br><span class="line">NAME                DRIVER              SCOPE</span><br><span class="line">bridge              bridge              <span class="built_in">local</span></span><br><span class="line">host                host                <span class="built_in">local</span></span><br><span class="line">none                null                <span class="built_in">local</span></span><br></pre></td></tr></table></figure><ul><li><p>bridge（桥接式网络）(默认)</p><blockquote><p>启动容器时，首先会在主机上创建一个docker0的虚拟网桥，相当于交换机，同时自动分配一对网卡设备，一半在容器（eth0），一半在宿主机，并且还关联到了docker0，从而进行连接</p><p>Docker0网络是Docker搭建的一个虚拟桥接网络，默认网关地址是172.17.0.1。Docker默认的网络是Docker0网络，也就意味着Docker中所有没有指定网络的容器都会加入到这个桥接网络中，网络中的容器可以互相通信。</p></blockquote></li><li><p>Container(K8S会常用)</p><blockquote><p>与另一个运行得容器共用一个网络Network Namespace</p><p>使用方式: <code>--network=container:容器ID</code></p><p>注意共用时端口不能相同，端口谁先占用就是谁的</p></blockquote></li><li><p>host （主机）</p><blockquote><p>与宿主机共用一个网络</p><p>使用方式: <code>--network=host</code></p><p>使用后不需要做端口映射，性能最高，端口谁先占用就是谁的</p></blockquote></li><li><p>none （空）</p><blockquote><p>不为容器配置任何网络功能，不使用任何网络类型<br>使用方式: <code>--network=none</code> </p></blockquote></li></ul><p><strong>Docker对主机上的iptables的影响</strong></p><p>Docker引擎启动的时候会修改iptables规则</p><p>使用 <code>iptables-save</code> 命令查看 iptable，Docker 对 iptables 的 NAT 表和 FILTER 表都作了较大的改动</p><p><strong>容器对外请求数据</strong></p><p>如果Docker0中的容器请求外部的数据，那么他的数据包将会发送到网关172.17.0.1处。当数据包到达网关后，将会查询主机的路由表，确定数据包将从那个网卡发出。iptables负责对数据包进行snat转换，将原地址转为对应网卡的地址，因此容器对外是不可见的</p><p><strong>外部对容器请求数据</strong></p><p>外部想要访问容器内的数据，首先需要将容器的端口映射到宿主机上。这时候docker会在iptables添加转发规则，把接收到的数据转发给容器</p><blockquote><p>重启iptables会导致docker 的规则丢失，所以建议动态修改iptables</p></blockquote><h5 id="Docker的镜像是如何存储"><a href="#Docker的镜像是如何存储" class="headerlink" title="Docker的镜像是如何存储"></a>Docker的镜像是如何存储</h5><p><a href="https://www.iteblog.com/archives/9778.html" target="_blank" rel="noopener">Docker 入门教程：镜像分层</a></p><h3 id="后端开发"><a href="#后端开发" class="headerlink" title="后端开发"></a>后端开发</h3><h4 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h4><h5 id="PYTHONPATH环境变量"><a href="#PYTHONPATH环境变量" class="headerlink" title="PYTHONPATH环境变量"></a>PYTHONPATH环境变量</h5><p>PYTHONPATH是Python中一个重要的环境变量,用于在导入模块的时候搜索路径</p><p>Linux下设置PYTHONPATH环境变量有三种方法: 一种作用于当前终端，一种作用于当前用户，一种作用于所有用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 作用于当前终端，直接当前终端输入命令</span><br><span class="line"># export PYTHONPATH&#x3D;$PYTHONPATH:&lt;你的要加入的路径&gt;</span><br><span class="line"># 注1：&#39;&#x2F;home&#x2F;hadoop&#x2F;MyBI&#39;是项目MyBI的项目名</span><br><span class="line"># 注2：作用范围当前终端，一旦当前终端关闭或在另一个终端中，则无效。</span><br><span class="line"># 注3：这种方式立即生效。</span><br><span class="line">$ export PYTHONPATH&#x3D;$PYTHONPATH:&#x2F;home&#x2F;hadoop&#x2F;MyBI</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"># 作用于当前用户，修改当前用户目录下的&#39;~&#x2F;.bashrc&#39;文件</span><br><span class="line"># 加入内容：</span><br><span class="line"># export PYTHONPATH&#x3D;$PYTHONPATH:&#x2F;home&#x2F;hadoop&#x2F;MyBI</span><br><span class="line"># 也可以加入多个路径，用分号分隔</span><br><span class="line"># export PYTHONPATH&#x3D;$PYTHONPATH:&lt;你的要加入的路径1&gt;:&lt;你的要加入的路径2&gt;:等等</span><br><span class="line"># 注1：需要执行source ~&#x2F;.bashrc命令后生效（或者注销后重新登陆）</span><br><span class="line">$ vi ~&#x2F;.bashrc</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"># 作用于所有用户（需要root权限修改），修改&#39;&#x2F;etc&#x2F;profile&#39;文件</span><br><span class="line"># 加入内容：</span><br><span class="line"># export PYTHONPATH&#x3D;$PYTHONPATH:&#x2F;home&#x2F;hadoop&#x2F;MyBI</span><br><span class="line"># 注1：需要执行如下命令后生效（或者注销后重新登陆）</span><br><span class="line">$ vi &#x2F;etc&#x2F;profile</span><br><span class="line"> </span><br><span class="line"># 如果修改PATH环境变量，也是像上面的三种方式操作</span><br></pre></td></tr></table></figure><h5 id="查看python的包路径"><a href="#查看python的包路径" class="headerlink" title="查看python的包路径"></a>查看python的包路径</h5><p>利用pip 命令查看<code>pip show beautifulsoup4</code></p><p>利用包的<code>__file__</code>函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ python</span><br><span class="line">Python 3.7.4 (default, Aug 13 2019, 15:17:50)</span><br><span class="line">[Clang 4.0.1 (tags&#x2F;RELEASE_401&#x2F;final)] :: Anaconda, Inc. on darwin</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt; import tornado</span><br><span class="line">&gt;&gt;&gt; print(tornado.__file__)</span><br><span class="line">&#x2F;Users&#x2F;tu&#x2F;.anaconda3&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;tornado&#x2F;__init__.py</span><br></pre></td></tr></table></figure><blockquote><p>Python3查看pip安装的软件包及版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ python3 -m pip list</span><br><span class="line">Package                            Version</span><br><span class="line">---------------------------------- ---------</span><br><span class="line">alabaster                          0.7.12</span><br><span class="line">anaconda-client                    1.7.2</span><br><span class="line">anaconda-navigator                 1.9.12</span><br><span class="line">anaconda-project                   0.8.3</span><br><span class="line">appnope                            0.1.0</span><br></pre></td></tr></table></figure></blockquote><h5 id="python的包结构"><a href="#python的包结构" class="headerlink" title="python的包结构"></a>python的包结构</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">picture&#x2F;                        Top-level package</span><br><span class="line">      __init__.py               Initialize the picture package</span><br><span class="line">      formats&#x2F;                  Subpackage for file format conversions</span><br><span class="line">              __init__.py</span><br><span class="line">              jpgread.py</span><br><span class="line">              jpgwrite.py</span><br><span class="line">              pngread.py</span><br><span class="line">              pngwrite.py</span><br><span class="line">              bmpread.py</span><br><span class="line">              bmpwrite.py</span><br><span class="line">              ...</span><br><span class="line">      filters&#x2F;                  Subpackage for filters</span><br><span class="line">              __init__.py</span><br><span class="line">              boxblur.py</span><br><span class="line">              gaussblur.py</span><br><span class="line">              sharpen.py</span><br><span class="line">              ...</span><br></pre></td></tr></table></figure><p>包（package）是 Python 中对模块的更高一级的抽象，Python 要求每一个「包」目录下，都必须有一个名为 <code>__init__.py</code> 的文件，一个Python 脚本就是一个 Python 模块（Module）。</p><h5 id="python的日志模块"><a href="#python的日志模块" class="headerlink" title="python的日志模块"></a>python的日志模块</h5><p>Python 标准库 logging 用作记录日志，默认分为六种日志级别（括号为级别对应的数值），NOTSET（0）、DEBUG（10）、INFO（20）、WARNING（30）、ERROR（40）、CRITICAL（50）</p><p><a href="https://juejin.im/post/5bc2bd3a5188255c94465d31" target="_blank" rel="noopener">Python日志库logging总结</a></p><h5 id="absolute-import这个模块的用途"><a href="#absolute-import这个模块的用途" class="headerlink" title="absolute_import这个模块的用途"></a>absolute_import这个模块的用途</h5><p>作用是绝对路径导入</p><p>绝对导入和相对导入之间的差异仅在从包导入模块和从包导入其他子模块时才起作用</p><p>例如: 关于这句<code>from __future__ import absolute_import</code>的作用<br>直观地看就是说”加入绝对引入这个新特性”。说到绝对引入，当然就会想到相对引入。那么什么是相对引入呢?比如说，你的包结构是这样的:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pkg&#x2F;</span><br><span class="line">pkg&#x2F;init.py</span><br><span class="line">pkg&#x2F;main.py</span><br><span class="line">pkg&#x2F;string.py</span><br></pre></td></tr></table></figure><p>如果你在main.py中写import string，那么在Python 2.4或之前，Python会先查找当前目录下有没有string.py，若找到了，则引入该模块，然后你在main.py中可以直接用string了。如果你是真的想用同目录下的string.py那就好，但是如果你是想用系统自带的标准string.py呢？那其实没有什么好的简洁的方式可以忽略掉同目录的string.py而引入系统自带的标准string.py。这时候你就需要<code>from __future__ import absolute_import</code>了。这样，你就可以用<code>import string</code>来引入系统的标准string.py，而用<code>from pkg import string</code>来引入当前目录下的string.py了</p><h5 id="熟悉import的⽅式-相对路径和绝对路径"><a href="#熟悉import的⽅式-相对路径和绝对路径" class="headerlink" title="熟悉import的⽅式: 相对路径和绝对路径"></a>熟悉import的⽅式: 相对路径和绝对路径</h5><p>相对路径导入方式只有from…import支持，import语句不支持，且只有使用.或..的才算是相对路径，否则就是绝对路径，就会从sys.path下搜索</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 同级目录 导入 reverse</span><br><span class="line">from . import reverse              </span><br><span class="line"></span><br><span class="line"># 上级目录 导入 frormats</span><br><span class="line">from .. import frormats            </span><br><span class="line"></span><br><span class="line"># 上级目录的filters模块下 导入 equalizer</span><br><span class="line">from ..filters import equalizer</span><br></pre></td></tr></table></figure><h5 id="常见HTTP的状态码"><a href="#常见HTTP的状态码" class="headerlink" title="常见HTTP的状态码"></a>常见HTTP的状态码</h5><p>1xx（临时响应）表示临时响应并需要请求者继续执行操作的状态代码。</p><ul><li>100 （继续）请求者应当继续提出请求。服务器返回此代码表示已收到请求的第一部分，正在等待其余部分</li><li>101 （切换协议）请求者已要求服务器切换协议，服务器已确认并准备切换。</li></ul><p>2xx （成功）表示成功处理了请求的状态代码。</p><ul><li>200 （成功）服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。</li><li>201 （已创建）请求成功并且服务器创建了新的资源。</li><li>202 （已接受）服务器已接受请求，但尚未处理。</li><li>203 （非授权信息）服务器已成功处理了请求，但返回的信息可能来自另一来源。</li><li>204 （无内容）服务器成功处理了请求，但没有返回任何内容。</li><li>205 （重置内容）服务器成功处理了请求，但没有返回任何内容。</li><li>206 （部分内容）服务器成功处理了部分GET 请求。</li></ul><p>3xx （重定向）表示要完成请求，需要进一步操作。通常，这些状态代码用来重定向。</p><ul><li>300 （多种选择）针对请求，服务器可执行多种操作。服务器可根据请求者(user agent) 选择一项操作，或提供操作列表供请求者选择。</li><li>301 （永久移动）请求的网页已永久移动到新位置。服务器返回此响应（对GET 或HEAD请求的响应）时，会自动将请求者转到新位置。</li><li>302 （临时移动）服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</li><li>303 （查看其他位置）请求者应当对不同的位置使用单独的GET 请求来检索响应时，服务器返回此代码。</li><li>304 （未修改）自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容，即取的缓存。</li><li>305 （使用代理）请求者只能使用代理访问请求的网页。如果服务器返回此响应，还表示请求者应使用代理。</li><li>307 （临时重定向）服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</li></ul><p>4xx（请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理。</p><ul><li>400 （错误请求）服务器不理解请求的语法。</li><li>401 （未授权）请求要求身份验证。对于需要登录的网页，服务器可能返回此响应。</li><li>403 （禁止）服务器拒绝请求。</li><li>404 （未找到）服务器找不到请求的网页。</li><li>405 （方法禁用）禁用请求中指定的方法。</li><li>406 （不接受）无法使用请求的内容特性响应请求的网页。</li><li>407 （需要代理授权）此状态代码与401（未授权）类似，但指定请求者应当授权使用代理。</li><li>408 （请求超时）服务器等候请求时发生超时。</li><li>409 （冲突）服务器在完成请求时发生冲突。服务器必须在响应中包含有关冲突的信息。</li><li>410（已删除）如果请求的资源已永久删除，服务器就会返回此响应。</li><li>411 （需要有效长度）服务器不接受不含有效内容长度标头字段的请求。</li><li>412 （未满足前提条件）服务器未满足请求者在请求中设置的其中一个前提条件。</li><li>413 （请求实体过大）服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。</li><li>414 （请求的URI 过长）请求的URI（通常为网址）过长，服务器无法处理。</li><li>415 （不支持的媒体类型）请求的格式不受请求页面的支持。</li><li>416 （请求范围不符合要求）如果页面无法提供请求的范围，则服务器会返回此状态代码。</li><li>417 （未满足期望值）服务器未满足”期望”请求标头字段的要求。</li></ul><p>5xx（服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。</p><ul><li>500 （服务器内部错误）服务器遇到错误，无法完成请求。</li><li>501 （尚未实施）服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码。</li><li>502 （错误网关）服务器作为网关或代理，从上游服务器收到无效响应。</li><li>503 （服务不可用）服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。</li><li>504 （网关超时）服务器作为网关或代理，但是没有及时从上游服务器收到请求。</li><li>505 （HTTP 版本不受支持）服务器不支持请求中所用的HTTP 协议版本。</li></ul><h5 id="REST的设计"><a href="#REST的设计" class="headerlink" title="REST的设计"></a>REST的设计</h5><p><a href="http://www.ruanyifeng.com/blog/2014/05/restful_api.html" target="_blank" rel="noopener">RESTful API 设计指南</a></p><hr>]]></content>
    
    <summary type="html">
    
      Linux 运维知识
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
</feed>
