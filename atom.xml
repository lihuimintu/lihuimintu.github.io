<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>lihuimintu</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-05-03T14:23:45.409Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>图</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pulsar 消息订阅</title>
    <link href="http://yoursite.com/2021/05/03/pulsar-news-subscription/"/>
    <id>http://yoursite.com/2021/05/03/pulsar-news-subscription/</id>
    <published>2021-05-02T16:00:00.000Z</published>
    <updated>2021-05-03T14:23:45.409Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 消息订阅</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>该文摘自Apache Pulsar 官方文档<a href="https://pulsar.apache.org/docs/zh-CN/concepts-messaging/#%E8%AE%A2%E9%98%85" target="_blank" rel="noopener">Apache Pulsar Messaging#订阅</a></p><p>当有有数据进入到Pulsar后，需要将数据消费出来，这里就涉及订阅</p><p>订阅是命名好的配置规则，指导消息如何投递给消费者。</p><h5 id="消息订阅"><a href="#消息订阅" class="headerlink" title="消息订阅"></a>消息订阅</h5><p>Pulsar 中有四种订阅模式: 独占(Exclusive)，共享(Share)，灾备(Failover)和key共享(Key_Shared)</p><p><img src="/images/blog/2021-05-03-1.png" alt></p><h5 id="独占-Exclusive"><a href="#独占-Exclusive" class="headerlink" title="独占(Exclusive)"></a>独占(Exclusive)</h5><p><strong>Exclusive模式为默认订阅模式</strong></p><p>在独占模式下，仅允许单个使用者附加到订阅。如果多个使用者使用相同的订阅来订阅主题，则会发生错误。 即在任何时间，一个消费者组（订阅）中有且只有一个消费者来消费 Topic 中的消息</p><p>在下图中，仅允许消费者A-0消费消息</p><p><img src="/images/blog/2021-05-03-2.png" alt></p><h5 id="灾备-Failover-）"><a href="#灾备-Failover-）" class="headerlink" title="灾备(Failover)）"></a>灾备(Failover)）</h5><p>在灾备模式下，多个消费者（Consumer）可以附加到同一订阅，主消费者会消费非分区主题或者分区主题中的每个分区的消息。当主消费者断开连接时，分区将被重新分配给其中一个故障转移消费者，而新分配的消费者将成为新的主消费者。 发生这种情况时，所有未确认（ack）的消息都将传递给新的主消费者。</p><p>对于分区主题来说，Broker 将按照消费者的优先级和消费者名称的词汇表顺序对消费者进行排序。 然后试图将主题均匀的分配给优先级最高的消费者。</p><p>对于非分区主题来说，Broker 会根据消费者订阅非分区主题的顺序选择消费者。</p><p>在下图中，消费者B-0是主要消费者，如果消费者B-0断开连接，则消费者B-1将是排队接收消息的下一个消费者。</p><p><img src="/images/blog/2021-05-03-3.png" alt></p><h5 id="共享-Share"><a href="#共享-Share" class="headerlink" title="共享(Share)"></a>共享(Share)</h5><p>在共享模式下，多个消费者者可以附加到同一订阅，消息通过round robin（轮询机制）分发给不同的消费者，并且每个消息仅会被分发给一个消费者。</p><p>当消费者断开连接，所有被发送给它，但没有来得及确认（ack）的消息将被重新安排，分发给其它存活的消费者。</p><p>在下图中，Consumer-C-1和Consumer-C-2可以订阅该主题，但是Consumer-C-3和其他消费者也可以订阅该主题。</p><p><img src="/images/blog/2021-05-03-4.png" alt></p><blockquote><p>共享模式的局限性: 使用共享模式时，不保证消息顺序。不能在共享模式下使用累积确认(Cumulative Ack)。</p></blockquote><h5 id="key共享-Key-Shared"><a href="#key共享-Key-Shared" class="headerlink" title="key共享(Key_Shared)"></a>key共享(Key_Shared)</h5><p>key共享模式是共享模式的一种，不同的是它按key对消息做投递，相同的key的消息会被投递到同一个消费者上</p><p><img src="/images/blog/2021-05-03-5.png" alt></p><blockquote><p>Key_Shared模式的局限性: 使用Key_Shared模式时，需要为消息指定密钥或orderingKey。 不能在Key_Shared模式下使用累积确认(Cumulative Ack)。 生产者应禁用批处理或使用基于密钥的批处理生成器。</p></blockquote><p>可以在 broker.config 中禁用 Key_Shared 模式</p><h4 id="多主题订阅"><a href="#多主题订阅" class="headerlink" title="多主题订阅"></a>多主题订阅</h4><p>当consumer订阅pulsar的主题时，默认指定订阅了一个主题，例如：<code>persistent://public/default/my-topic</code></p><p>从Pulsar的1.23.0-incubating的版本开始，Pulsar消费者可以同时订阅多个topic。</p><p>可以用以下两种方式定义topic的列表</p><ul><li>基于正则表达式（regex），例如<code>persistent://public/default/finance-.*</code></li><li>通过明确指定的topic列表</li></ul><blockquote><p>当使用正则匹配订阅多个主题的时候，所有的主题必须是在同一个命名空间里面的</p></blockquote><p>当订阅多个主题的时候，Pulsar客户端将自动调用Pulsar API找到符合匹配规则的主题列表，然后订阅这些主题。 如果此时有暂不存在的主题，那么一旦这些主题被创建，消费者会自动订阅这些主题。</p><p>如下是 Java 订阅多个主题的代码示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import java.util.regex.Pattern;</span><br><span class="line"></span><br><span class="line">import org.apache.pulsar.client.api.Consumer;</span><br><span class="line">import org.apache.pulsar.client.api.PulsarClient;</span><br><span class="line"></span><br><span class="line">PulsarClient pulsarClient &#x3D; &#x2F;&#x2F; Instantiate Pulsar client object</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Subscribe to all topics in a namespace</span><br><span class="line">Pattern allTopicsInNamespace &#x3D; Pattern.compile(&quot;persistent:&#x2F;&#x2F;public&#x2F;default&#x2F;.*&quot;);</span><br><span class="line">Consumer&lt;byte[]&gt; allTopicsConsumer &#x3D; pulsarClient.newConsumer()</span><br><span class="line">                .topicsPattern(allTopicsInNamespace)</span><br><span class="line">                .subscriptionName(&quot;subscription-1&quot;)</span><br><span class="line">                .subscribe();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Subscribe to a subsets of topics in a namespace, based on regex</span><br><span class="line">Pattern someTopicsInNamespace &#x3D; Pattern.compile(&quot;persistent:&#x2F;&#x2F;public&#x2F;default&#x2F;foo.*&quot;);</span><br><span class="line">Consumer&lt;byte[]&gt; someTopicsConsumer &#x3D; pulsarClient.newConsumer()</span><br><span class="line">                .topicsPattern(someTopicsInNamespace)</span><br><span class="line">                .subscriptionName(&quot;subscription-1&quot;)</span><br><span class="line">                .subscribe();</span><br></pre></td></tr></table></figure><p>关于代码示例，请参阅 <a href="https://pulsar.apache.org/docs/zh-CN/client-libraries-java/#multi-topic-subscriptions" target="_blank" rel="noopener">Java</a></p><hr><p>参考链接</p><ul><li><a href="https://pulsar.apache.org/docs/zh-CN/concepts-messaging/#%E8%AE%A2%E9%98%85" target="_blank" rel="noopener">Apache Pulsar Messaging#订阅</a></li></ul>]]></content>
    
    <summary type="html">
    
      Apache Pulsar 消息订阅
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>Pulsar 总览</title>
    <link href="http://yoursite.com/2021/05/02/pulsar-overview/"/>
    <id>http://yoursite.com/2021/05/02/pulsar-overview/</id>
    <published>2021-05-01T16:00:00.000Z</published>
    <updated>2021-05-03T14:23:58.107Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 架构与核心概念</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p><a href="https://pulsar.apache.org" target="_blank" rel="noopener">Apache Pulsar</a> 是 Apache 软件基金会顶级项目，是下一代云原生分布式消息流平台，集消息、存储、轻量化函数式计算为一体，采用计算与存储分离架构设计，支持多租户、持久化存储、多机房跨区域数据复制，具有强一致性、高吞吐、低延时及高可扩展性等流数据存储特性。</p><h4 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h4><p>Apache Pulsar 是 Pub/Sub 模型的消息系统，并且从设计上做了存储和计算的分离</p><h5 id="存储计算分离"><a href="#存储计算分离" class="headerlink" title="存储计算分离"></a>存储计算分离</h5><p>Pulsar 集群由以下三部分组成</p><ul><li>Broker: 无状态服务层，负责接收和传递消息，集群负载均衡等工作，Broker 不会持久化保存元数据，因此可以快速的上、下线</li><li>Apache BookKeeper: 有状态持久层，由一组名为 Bookie 的存储节点组成，持久化地存储消息</li><li>Apache Zookeeper: 进行元数据存储，集群配置和协调</li></ul><p><img src="/images/blog/2021-05-02-2.png" alt></p><p>与传统的消息系统相比，Apache Pulsar 在架构设计上采用了计算与存储分离的模式，Pub/Sub 相关的计算逻辑在 Broker 上完成，数据存储在 Apache BookKeeper 的 Bookie 节点上。</p><h5 id="分片存储"><a href="#分片存储" class="headerlink" title="分片存储"></a>分片存储</h5><p><img src="/images/blog/2021-05-02-1.png" alt></p><hr><p>参考链接</p><ul><li><a href="https://github.com/deviceinsight/kafkactl" target="_blank" rel="noopener">kafkactl</a></li></ul>]]></content>
    
    <summary type="html">
    
      Apache Pulsar 架构与核心概念
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>kafkactl</title>
    <link href="http://yoursite.com/2021/04/26/kafkactl/"/>
    <id>http://yoursite.com/2021/04/26/kafkactl/</id>
    <published>2021-04-25T16:00:00.000Z</published>
    <updated>2021-04-26T15:44:27.056Z</updated>
    
    <content type="html"><![CDATA[<p>与Kafka交互的命令行工具</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>平常使用kafka的命令行感觉不是很方便，每次都要找地址和打很长的命令。</p><p>调研发现kafkactl可以满足需求。简单明了，解压就可以用，不用装JDK</p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>kafkactl 是一个与Apache Kafka交互的命令行工具</p><p>github地址：<a href="https://github.com/deviceinsight/kafkactl" target="_blank" rel="noopener">https://github.com/deviceinsight/kafkactl</a></p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>在releases下载最新的二进制包解压即可用</p><p>在用户的家目录下创建配置文件 <code>.config/kafkactl/config.yml</code></p><p>在配置文件里配置好要kafka集群地址信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">contexts:</span><br><span class="line">  default:</span><br><span class="line">    brokers:</span><br><span class="line">    - localhost:9092</span><br><span class="line">  remote-cluster:</span><br><span class="line">    brokers:</span><br><span class="line">    - remote-cluster001:9092</span><br><span class="line">    - remote-cluster002:9092</span><br><span class="line">    - remote-cluster003:9092</span><br><span class="line">    </span><br><span class="line">current-context: default</span><br></pre></td></tr></table></figure><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>直接输入kafkactl可以查看帮助，感兴趣的可以看下视频学习 <a href="https://asciinema.org/a/vmxrTA0h8CAXPnJnSFk5uHKzr" target="_blank" rel="noopener">https://asciinema.org/a/vmxrTA0h8CAXPnJnSFk5uHKzr</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ kafkactl</span><br><span class="line">A command-line interface the simplifies interaction with Kafka.</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  kafkactl [command]</span><br><span class="line"></span><br><span class="line">Available Commands:</span><br><span class="line">  alter       alter topics, partitions</span><br><span class="line">  attach      run kafkactl pod in kubernetes and attach to it</span><br><span class="line">  completion  </span><br><span class="line">  config      show and edit configurations</span><br><span class="line">  consume     consume messages from a topic</span><br><span class="line">  create      create topics, consumerGroups, acls</span><br><span class="line">  delete      delete topics, acls</span><br><span class="line">  describe    describe topics, consumerGroups</span><br><span class="line">  get         get info about topics, consumerGroups, acls</span><br><span class="line">  help        Help about any command</span><br><span class="line">  produce     produce messages to a topic</span><br><span class="line">  reset       reset consumerGroupsOffset</span><br><span class="line">  version     print the version of kafkactl</span><br><span class="line"></span><br><span class="line">Flags:</span><br><span class="line">  -C, --config-file string   config file. one of: [$HOME&#x2F;.config&#x2F;kafkactl $HOME&#x2F;.kafkactl $SNAP_REAL_HOME&#x2F;.config&#x2F;kafkactl $SNAP_DATA&#x2F;kafkactl &#x2F;etc&#x2F;kafkactl]</span><br><span class="line">  -h, --help                 help for kafkactl</span><br><span class="line">  -V, --verbose              verbose output</span><br><span class="line"></span><br><span class="line">Use &quot;kafkactl [command] --help&quot; for more information about a command.</span><br></pre></td></tr></table></figure><h5 id="选择要访问的集群"><a href="#选择要访问的集群" class="headerlink" title="选择要访问的集群"></a>选择要访问的集群</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kafkactl config get-contexts</span><br><span class="line">ACTIVE     NAME</span><br><span class="line">           remote-cluster</span><br><span class="line">*          default</span><br><span class="line"></span><br><span class="line">$ kafkactl config use-context remote-cluster</span><br><span class="line">$ kafkactl config current-context</span><br><span class="line">remote-cluster</span><br></pre></td></tr></table></figure><h5 id="获取主题和消费者组"><a href="#获取主题和消费者组" class="headerlink" title="获取主题和消费者组"></a>获取主题和消费者组</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafkactl get topics</span><br><span class="line">kafkactl get consumer-groups</span><br></pre></td></tr></table></figure><h5 id="查看主题和消费者组详情"><a href="#查看主题和消费者组详情" class="headerlink" title="查看主题和消费者组详情"></a>查看主题和消费者组详情</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafkactl describe topic xxx</span><br><span class="line">kafkactl describe consumer-group  xxx</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>挺好用的工具，不需要安装jdk，解压就可以使用。</p><p>输出所有消费组的功能挺好的，在集群裁撤时可以一下子查出所有的对应关系</p><hr><p>参考链接</p><ul><li><a href="https://github.com/deviceinsight/kafkactl" target="_blank" rel="noopener">kafkactl</a></li></ul>]]></content>
    
    <summary type="html">
    
      与Kafka交互的命令行工具
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka的一些问题</title>
    <link href="http://yoursite.com/2021/04/15/kafka-difficulty/"/>
    <id>http://yoursite.com/2021/04/15/kafka-difficulty/</id>
    <published>2021-04-14T16:00:00.000Z</published>
    <updated>2021-04-14T19:36:32.545Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的一些问题</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>读自vivo 互联网技术的文章–<a href="https://juejin.cn/post/6844903919424913415#heading-9" target="_blank" rel="noopener">《Kafka 原理和实战》</a> 整理</p><h4 id="问题点"><a href="#问题点" class="headerlink" title="问题点"></a>问题点</h4><h5 id="单分区有序"><a href="#单分区有序" class="headerlink" title="单分区有序"></a>单分区有序</h5><p>只保证单个主题单个分区内的消息有序，但是不能保证单个主题所有分区消息有序。如果应用严格要求消息有序，那么kafka可能不大合适</p><h5 id="消费偏移量维护"><a href="#消费偏移量维护" class="headerlink" title="消费偏移量维护"></a>消费偏移量维护</h5><p>消费偏移量由消费者跟踪和提交，但是消费者并不会经常把这个偏移量写会kafka，因为broker维护这些更新的代价很大，这会导致异常情况下消息可能会被多次消费或者没有消费。</p><p>具体分析如下：消息可能已经被消费了，但是消费者还没有像broker提交偏移量(commit offset)确认该消息已经被消费就挂掉了，接着另一个消费者又开始处理同一个分区，那么它会从上一个已提交偏移量开始，导致有些消息被重复消费。但是反过来，如果消费者在批处理消息之前就先提交偏移量，但是在处理消息的时候挂掉了，那么这部分消息就相当于『丢失』了。通常来说，处理消息和提交偏移量很难构成一个原子性操作，因此无法总是保证所有消息都刚好只被处理一次。</p><h5 id="主题和分区的数目有限"><a href="#主题和分区的数目有限" class="headerlink" title="主题和分区的数目有限"></a>主题和分区的数目有限</h5><p>Kafka集群能够处理的主题数目是有限的，达到1000个主题左右时，性能就开始下降。这些问题基本上都跟Kafka的基本实现决策有关。特别是，随着主题数目增加，broker上的随机IO量急剧增加，因为每个主题分区的写操作实际上都是一个单独的文件追加(append)操作。随着分区数目增加，问题越来越严重。如果Kafka不接管IO调度，问题就很难解决。</p><h5 id="磁盘大小"><a href="#磁盘大小" class="headerlink" title="磁盘大小"></a>磁盘大小</h5><p>单个节点必须有足够的磁盘空间来处理副本，因此非常大的副本可能会迫使你是用非常大的磁盘，磁盘的冗余需要评估和衡量</p><h5 id="手动均衡分区负载"><a href="#手动均衡分区负载" class="headerlink" title="手动均衡分区负载"></a>手动均衡分区负载</h5><p>在集群扩展时必须做Rebalance。这个过程是比较痛苦的，需要良好的计划和执行来保证没有任何故障的情况下分散节点的存储压力</p><h5 id="follow副本-replica-只充当冷备（解决HA问题），无法提供读服务"><a href="#follow副本-replica-只充当冷备（解决HA问题），无法提供读服务" class="headerlink" title="follow副本(replica)只充当冷备（解决HA问题），无法提供读服务"></a>follow副本(replica)只充当冷备（解决HA问题），无法提供读服务</h5><p>kafka因为读服务是有状态的（要维护commited offset），所以follow副本并没有参与到读写服务中。只是作为一个冷备，解决单点问题。</p><h5 id="顺序消费"><a href="#顺序消费" class="headerlink" title="顺序消费"></a>顺序消费</h5><p>只能顺序消费消息，不能随机定位消息，出问题的时候不方便快速定位问题</p><p>这其实是所有以消息系统作为异步RPC的通用问题。假设发送方发了一条消息，但是消费者说我没有收到，那么怎么排查呢？消息队列缺少随机访问消息的机制，如根据消息的key获取消息。</p><p>这导致排查这种问题不大容易。</p><hr><p>参考链接</p><ul><li><a href="https://juejin.cn/post/6844903919424913415#heading-9" target="_blank" rel="noopener">Kafka 原理和实战</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka的一些问题
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>零拷贝</title>
    <link href="http://yoursite.com/2021/04/07/zore-copy/"/>
    <id>http://yoursite.com/2021/04/07/zore-copy/</id>
    <published>2021-04-06T16:00:00.000Z</published>
    <updated>2021-04-07T06:55:04.841Z</updated>
    
    <content type="html"><![CDATA[<p>零拷贝是指计算机在网络上发送文件时，不需要将文件内容拷贝到用户空间（User Space）而直接在内核空间（Kernel Space）中传输到网络的方式</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>阅读艾小仙的<a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA" target="_blank" rel="noopener">阿里二面：什么是mmap？</a> ，挺通俗易懂的，把之前学的零拷贝在回顾了下</p><h4 id="传统I-O"><a href="#传统I-O" class="headerlink" title="传统I/O"></a>传统I/O</h4><p>首先要对传统的IO方式有一个概念</p><p>基于传统的IO方式，底层实际上通过调用read()和write()来实现</p><p>通过read()把数据从硬盘读取到内核缓冲区，再复制到用户缓冲区；然后再通过write()写入到socket缓冲区，最后写入网卡设备。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read(file,tmp_buf,len)</span><br><span class="line">write(socket,tmp_buf,len)</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-1.png" alt></p><p>从磁盘文件读取并且通过socket写出的过程发生了4次用户态和内核态的上下文切换和4次拷贝</p><ol><li>用户进程通过read()方法向操作系统发起调用，此时上下文从用户态切换为内核态</li><li>DMA控制器把数据从硬盘中拷贝到读缓冲区</li><li>CPU把读缓冲区数据拷贝到应用缓冲区，上下文从内核态切换为用户态，read()返回</li><li>用户进程通过write()方法发起调用，上下文从用户态切换为内核态</li><li>CPU把用户缓冲区的数据拷贝到socket缓冲区</li><li>DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，write()返回</li></ol><blockquote><p>用户态、内核态指的是什么？上下文切换又是什么？</p><p>简单来说，用户空间指的就是用户进程的运行空间，内核空间就是内核的运行空间。</p><p>如果进程运行在内核空间就是内核态，运行在用户空间就是用户态。</p><p>为了安全起见，他们之间是互相隔离的，而在用户态和内核态之间的上下文切换也是比较耗时的。</p></blockquote><blockquote><p>什么又是DMA拷贝呢？</p><p>因为对于一个IO操作而言，都是通过CPU发出对应的指令来完成，但是相比CPU来说，IO的速度太慢了，CPU有大量的时间处于等待IO的状态。</p><p>因此就产生了DMA（Direct Memory Access）直接内存访问技术，本质上来说他就是一块主板上独立的芯片，通过它来进行内存和IO设备的数据传输，从而减少CPU的等待时间。</p></blockquote><h4 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h4><p>接下来有针对性的来谈谈几种常见的零拷贝技术</p><h5 id="mmap-write"><a href="#mmap-write" class="headerlink" title="mmap+write"></a>mmap+write</h5><p>简单来说就是使用mmap替换了read+write中的read操作，减少了一次CPU的拷贝。</p><p>mmap主要实现方式是将读缓冲区的地址和用户缓冲区的地址进行映射，内核缓冲区和应用缓冲区共享，从而减少了从读缓冲区到用户缓冲区的一次CPU拷贝。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp_buf &#x3D; mmap(file, len);</span><br><span class="line">write(socket, tmp_buf, len);</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-2.png" alt></p><p>整个过程发生了4次用户态和内核态的上下文切换和3次拷贝</p><ol><li>用户进程通过mmap()方法向操作系统发起调用，上下文从用户态转向内核态</li></ol><h5 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h5><p>相比mmap来说，sendfile同样减少了一次CPU拷贝，而且还减少了2次上下文切换。</p><p>sendfile是Linux2.1内核版本后引入的一个系统调用函数，通过使用sendfile数据可以直接在内核空间进行传输，因此避免了用户空间和内核空间的拷贝，同时由于使用sendfile替代了read+write从而节省了一次系统调用，也就是2次上下文切换。</p><p><img src="/images/blog/2021-04-05-3.png" alt></p><p>整个过程发生了2次用户态和内核态的上下文切换和3次拷贝，具体流程如下：</p><ol><li>用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态切换为内核态</li><li>DMA控制器把数据从硬盘中拷贝到读缓冲区</li><li>CPU将读缓冲区中数据拷贝到socket缓冲区</li><li>DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换为用户态，sendfile调用返回</li></ol><p><strong>sendfile方法IO数据对用户空间完全不可见，所以只能适用于完全不需要用户空间处理的情况，比如静态文件服务器。</strong></p><h5 id="sendfile-DMA-Scatter-Gather"><a href="#sendfile-DMA-Scatter-Gather" class="headerlink" title="sendfile+DMA Scatter/Gather"></a>sendfile+DMA Scatter/Gather</h5><p>Linux2.4内核版本之后对sendfile做了进一步优化，通过引入新的硬件支持，这个方式叫做DMA Scatter/Gather 分散/收集功能。</p><p>将读缓冲区中的数据描述信息–内存地址和偏移量记录到socket缓冲区，由 DMA 根据这些将数据从读缓冲区拷贝到网卡，相比之前版本减少了一次CPU拷贝的过程</p><blockquote><p>之前是把读缓冲区的数据拷贝到socket缓存中，实际上，仅仅需要把读缓冲区描述符传到socket缓冲区，再把数据长度传过去，这样DMA控制器直接将页缓存中的数据打包发送到网络中就可以了。</p></blockquote><p>依旧是系统调用sendfile()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sendfile(socket, file, len);</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-4.png" alt></p><ol><li>用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态转向内核态</li><li>DMA控制器利用scatter把数据从硬盘中拷贝到读缓冲区离散存储</li><li>CPU把读缓冲区中的文件描述符和数据长度发送到socket缓冲区</li><li>DMA控制器根据文件描述符和数据长度，使用scatter/gather把数据从内核缓冲区拷贝到网卡</li><li>sendfile()调用返回，上下文从内核态切换回用户态</li></ol><p>DMA gather和sendfile一样数据对用户空间不可见，而且需要硬件支持，同时输入文件描述符只能是文件，但是过程中完全没有CPU拷贝过程，极大提升了性能。</p><blockquote><p>这种模式实现起来需要硬件的支持，但对于基于操作系统的用户来讲，操作系统已经屏蔽了这种差异，它会根据不同的硬件平台来实现这个系统调用</p></blockquote><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>RocketMQ和Kafka都使用到了零拷贝的技术</p><p>对于MQ而言，无非就是生产者发送数据到MQ然后持久化到磁盘，之后消费者从MQ读取数据。</p><p>对于RocketMQ来说这两个步骤使用的是mmap+write，而Kafka则是使用mmap+write持久化数据，发送数据使用sendfile。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>由于CPU和IO速度的差异问题，产生了DMA技术，通过DMA搬运来减少CPU的等待时间。</p><p>传统的IO read+write方式会产生2次DMA拷贝+2次CPU拷贝，同时有4次上下文切换。</p><p>而通过mmap+write方式则产生2次DMA拷贝+1次CPU拷贝，4次上下文切换，通过内存映射减少了一次CPU拷贝，可以减少内存使用，适合大文件的传输。</p><p>sendfile方式是新增的一个系统调用函数，产生2次DMA拷贝+1次CPU拷贝，但是只有2次上下文切换。因为只有一次调用，减少了上下文的切换，但是用户空间对IO数据不可见，适用于静态文件服务器。</p><p>sendfile+DMA gather方式产生2次DMA拷贝，没有CPU拷贝，而且也只有2次上下文切换。虽然极大地提升了性能，但是需要依赖新的硬件设备支持。</p><hr><p>参考链接</p><ul><li><a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA" target="_blank" rel="noopener">阿里二面：什么是mmap？</a></li><li><a href="https://www.jianshu.com/p/497e7640b57c" target="_blank" rel="noopener">零拷贝的原理及Java实现</a></li></ul>]]></content>
    
    <summary type="html">
    
      零拷贝技术
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka topic leader 均衡</title>
    <link href="http://yoursite.com/2021/03/10/kafka-leader-reassign/"/>
    <id>http://yoursite.com/2021/03/10/kafka-leader-reassign/</id>
    <published>2021-03-09T16:00:00.000Z</published>
    <updated>2021-03-19T07:54:56.657Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka常见痛点及优化方案</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>在创建一个topic时，partition会在Broker集群上均分，每个partition的所有replicas叫做”assigned replicas”，”assigned replicas”中的第一个replicas叫”preferred replica”。</p><p>刚创建的topic一般”preferred replica”是leader。leader replica负责所有的读写。</p><p>随着时间推移，broker可能会停机，会导致leader迁移，导致机群的负载不均衡。需要对topic的leader进行重新负载均衡，让partition选择”preferred replica”做为leader。</p><p>简单来说：leader 均衡就是让topic 的分区leader 选择的是优先副本</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>先查看 topic 情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic logdata-es</span><br></pre></td></tr></table></figure><p>生成主题列表 json 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;partitions&quot;:</span><br><span class="line">  [</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 0&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 1&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 2&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 3&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 4&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 5&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行均衡</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-preferred-replica-election.sh --zookeeper 127.0.0.1:2181 --path-to-json-file logdata-es-autu.json</span><br></pre></td></tr></table></figure><p>再查看 topic 情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic logdata-es</span><br></pre></td></tr></table></figure><p>Kafka 有个参数可以控制优先副本选举，即<code>auto.leader.rebalance.enable</code>参数，可以使得Kafka集群自动平衡Leader，只需要在server.properties文件中配置如下设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">leader.imbalance.check.interval.seconds&#x3D;300 ,每个300秒检查leader的负载均衡情况</span><br><span class="line">leader.imbalance.per.broker.percentage&#x3D;10，不平衡性超过阈值就自动触发负载均衡</span><br><span class="line">auto.leader.rebalance.enable&#x3D;true ，默认是开启的</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Kafka是允许分区保持一定的不均衡的，单个topic的优先副本均衡，也并不能代表整个集群的优先副本均衡</p><p>对于手动执行优先副本选举，也建议采取分批次的方式进行，避免同时进行多个大数据量topic的优先副本选举。</p><hr><p>参考链接</p><ul><li><a href="https://sukbeta.github.io/kafka-auto-loadblance-leader/" target="_blank" rel="noopener">kafka对topic leader 进行自动负载均衡</a></li><li><a href="https://blog.csdn.net/data2tech/article/details/108730602" target="_blank" rel="noopener">Kafka优先副本选举</a></li><li><a href="https://blog.csdn.net/qq_29493353/article/details/88532089" target="_blank" rel="noopener">Kafka集群Leader均衡(Balancing leadership)</a></li><li><a href="https://cloud.tencent.com/developer/article/1496413" target="_blank" rel="noopener">Kafka集群平滑扩容及Leader均衡【实战笔记】</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 痛点及优化方案
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 分区策略</title>
    <link href="http://yoursite.com/2021/02/14/kafka-partition-strategy/"/>
    <id>http://yoursite.com/2021/02/14/kafka-partition-strategy/</id>
    <published>2021-02-13T16:00:00.000Z</published>
    <updated>2021-02-14T13:19:32.680Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 分区策略</p><hr><h4 id="生产者分区选择配策略"><a href="#生产者分区选择配策略" class="headerlink" title="生产者分区选择配策略"></a>生产者分区选择配策略</h4><p>生产者在将消息发送到某个Topic，需要经过拦截器、序列化器和分区器（Partitioner）的一系列作用之后才能发送到对应的Broker，在发往Broker之前是需要确定它所发往的分区。</p><p>生产端将消息发送给Broker之前，会将producer发送的数据封装成一个 ProducerRecord 对象。是否依赖分区器看partition字段有无指定。</p><p><img src="/images/blog/2021-02-14-1.png" alt></p><p>是否依赖分区器看partition字段有无指定</p><ul><li>如果消息 ProducerRecord 指定了 partition 字段，那么就不需要分区器。</li><li>如果消息 ProducerRecord 没有指定 partition 字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。</li></ul><p>Kafka 中提供的默认分区器是 <a href="https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/DefaultPartitioner.java" target="_blank" rel="noopener">DefaultPartitioner</a> ，它实现了Partitioner接口（用户可以实现这个接口来自定义分区器）</p><p>用户可以通过实现kafka.producer.Partitioner接口实现自己的分区类（重载并实现partition方法），在生产端添加配置<code>partitioner.class</code>即可使用</p><blockquote><ul><li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值。</li><li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值。</li><li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</li><li>既没有 partition 值又指定了自定义的分区类，则按自定义分区类来得到 partition 值</li></ul></blockquote><h4 id="消费者分区分配策略"><a href="#消费者分区分配策略" class="headerlink" title="消费者分区分配策略"></a>消费者分区分配策略</h4><p>消费者以组的名义订阅主题，主题有多个分区，消费者组中有多个消费者实例，<strong>同一时刻，一条消息只能被组中的一个消费者实例消费</strong></p><ul><li>如果分区数大于或者等于组中的消费者实例数，一个消费者会负责多个分区</li><li>如果分区数小于组中的消费者实例数，有些消费者将处于空闲状态并且无法接收消息</li></ul><blockquote><p>如果多个消费者负责同一个分区，那么就意味着两个消费者同时读取分区的消息，由于消费者自己可以控制读取消息的Offset，就有可能C1才读到2，而C1读到1，C1还没处理完，C2已经读到3了，这就相当于多线程读取同一个消息，会造成消息处理的重复，且不能保证消息的顺序。</p></blockquote><p>在 Kafka 中存在着两种分区分配策略，通过 partition.assignment.strategy 来设置。</p><ul><li>RangeAssignor 范围分区策略，也是默认模式。</li><li>RoundRobinAssignor 分配策略，轮询分区模式。</li></ul><h5 id="RangeAssignor"><a href="#RangeAssignor" class="headerlink" title="RangeAssignor"></a>RangeAssignor</h5><p>range （默认分配策略）对应的实现类是 org.apache.kafka.clients.consumer.RangeAssignor</p><ol><li>将分区按数字顺序排行序，消费者按名称的字典序排序</li><li>用分区总数除以消费者总数。如果能够除尽，平均分配；若除不尽，则位于排序前面的消费者将多负责一个分区</li></ol><p>假如现在有 10 个分区，3 个消费者，排序后的分区将会是p0~p9。消费者排序完之后将会是C1-0、C2-0、C3-0。通过 Partitions数 / Consumer数 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C1-0</td><td>消费 0、1、2、3分区</td></tr><tr><td>C2-0</td><td>消费 4、5、6分区</td></tr><tr><td>C3-0</td><td>消费 7、8、9分区</td></tr></tbody></table><blockquote><p>Range 范围分区的弊端: </p><p>如上只是针对 1 个 topic 而言，C1-0 消费者多消费1个分区影响不是很大。如果有 N 多个 topic，那么针对每个 topic，消费者 C1-0 都将多消费 1 个分区，topic越多，C1-0 消费的分区会比其他消费者明显多消费 N 个分区。这就是 Range 范围分区的一个很明显的弊端了.</p></blockquote><h5 id="RoundRobinAssignor"><a href="#RoundRobinAssignor" class="headerlink" title="RoundRobinAssignor"></a>RoundRobinAssignor</h5><p>RoundRobin基于轮询算法，对应的实现类是 org.apache.kafka.clients.consumer.RoundRobinAssignor</p><ol><li>将所有主题的分区组成TopicAndPartition列表</li><li>对TopicAndPartition列表按照hashCode进行排序某个topic</li><li>最后通过轮询算法来分配 partition 给到各个消费者</li></ol><p>轮询分区分为如下两种情况：</p><ul><li>同一个 Consumer Group 内 Consumer  订阅信息相同</li><li>同一个 Consumer Group 内 Consumer  订阅信息不相同</li></ul><h6 id="订阅信息相同"><a href="#订阅信息相同" class="headerlink" title="订阅信息相同"></a>订阅信息相同</h6><p>如果同一消费组内，所有的消费者订阅的消息都是相同的，那么 RoundRobin 策略的分区分配会是均匀的。</p><p>例如同一消费者组中，有 3 个消费者C0、C1和C2，都订阅了 2 个主题 t0 和 t1，并且每个主题都有 3 个分区(p0、p1、p2)，那么所订阅的所以分区可以标识为t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。</p><p>最终分区分配结果如下</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C0</td><td>消费 t0p0、t1p0 分区</td></tr><tr><td>C1</td><td>消费 t0p1、t1p1 分区</td></tr><tr><td>C2</td><td>消费 t0p2、t1p2 分区</td></tr></tbody></table><h5 id="订阅信息不相同"><a href="#订阅信息不相同" class="headerlink" title="订阅信息不相同"></a>订阅信息不相同</h5><p>同一消费者组内，所订阅的消息是不相同的，那么分区分配就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个 topic，那么在分配分区的时候，此消费者将不会分配到这个 topic 的任何分区。</p><p>例如同一消费者组中有3个消费者C0、C1、C2，他们共订阅了 3 个主题t0、t1、t2，这 3 个主题分别有 1、2、3 个分区(即t0有1个分区(p0)，t1有2个分区(p0、p1)，t2有3个分区(p0、p1、p2))，即整个消费者所订阅的所有分区可以标识为 t0p0、t1p0、t1p1、t2p0、t2p1、t2p2。然后消费者 C0 订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2</p><p>最终分区分配结果如下</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C0</td><td>消费 t0p0 分区</td></tr><tr><td>C1</td><td>消费 t1p0 分区</td></tr><tr><td>C2</td><td>消费 t1p1、 t2p0、 t2p1、 t2p2 分区</td></tr></tbody></table><hr><p>参考链接</p><ul><li><a href="https://www.jianshu.com/p/99b4187a994d" target="_blank" rel="noopener">Kafka分区策略</a></li><li><a href="https://mp.weixin.qq.com/s/st-7k7WH5pvLZwA_o9jPpw" target="_blank" rel="noopener">六问 Kafka 为啥那么牛！</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 分区策略
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 分区迁移</title>
    <link href="http://yoursite.com/2021/02/14/kafka-partition-migration/"/>
    <id>http://yoursite.com/2021/02/14/kafka-partition-migration/</id>
    <published>2021-02-13T16:00:00.000Z</published>
    <updated>2021-03-10T14:50:00.136Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka集群扩容后将数据量大Topic迁移到新的Kafka节点上</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>最近因数据量上涨，对Kafka集群进行扩容后，需将Topic量大的迁移到新Kafka节点上，缓解集群压力。</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>Kafka系统提供了一个分区重新分配工具（kafka-reassign-partitions.sh），该工具可用于在Broker之间迁移分区。</p><h5 id="生成待迁移topic的json"><a href="#生成待迁移topic的json" class="headerlink" title="生成待迁移topic的json"></a>生成待迁移topic的json</h5><p>新建文件topics-to-move.json，包含要迁移到Topic 列表。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat topic-to-move.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;topics&quot;: [&#123;&quot;topic&quot;: &quot;ke01&quot;&#125;,&#123;&quot;topic&quot;: &quot;ke02&quot;&#125;],</span><br><span class="line">    &quot;version&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="generate生成迁移计划"><a href="#generate生成迁移计划" class="headerlink" title="generate生成迁移计划"></a>generate生成迁移计划</h5><p>需要指定topics-to-move.json 文件和迁移目标节点的broker id</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist --topics-to-move-json-file topics-to-move.json --broker-list &quot;$brokerlist&quot; --generate &gt; generate.json</span><br></pre></td></tr></table></figure><p>查看generate.json文件结果类似如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Current partition replica assignment</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[61,62]&#125;,&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[62,61]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[140,141]&#125;,&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[141,140]&#125;]&#125;</span><br></pre></td></tr></table></figure><p>将Current partition replica assignment 的内容保存到rollback-cluster-reassignment.json，用于回滚操作。</p><p>将Proposed partition reassignment configuration 的内容保存到expand-cluster-reassignment.json，用于执行迁移操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat generate.json  |grep -A1 &quot;Proposed partition reassignment configuration&quot; |tail -1 &gt; expand-cluster-reassignment.json</span><br></pre></td></tr></table></figure><h5 id="迁移执行generate-prop-json"><a href="#迁移执行generate-prop-json" class="headerlink" title="迁移执行generate_prop.json"></a>迁移执行generate_prop.json</h5><p>限制带宽大小为500Mb/s</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist --reassignment-json-file generate_prop.json --execute --throttle 50000000</span><br></pre></td></tr></table></figure><p>迁移操作会将指定Topic 的数据文件移动到新的节点目录下，这个过程可能需要等待很长时间，视Topic 的数据量而定。</p><p>可以运行以下命令查看执行状态。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist  --reassignment-json-file generate_prop.json --verify</span><br></pre></td></tr></table></figure><p>状态有两种，in progress 表示正在迁移，completed successlly 表示已经成功完成迁移。迁移完成后，原先的节点下将不存在该Topic 的数据文件。</p><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>如果要迁移的Topic 有大量数据（Topic 默认保留1天的数据），可以在迁移之前临时动态地调整retention.ms 来减少数据。</p><hr><p>参考链接</p><ul><li><a href="https://www.jianshu.com/p/626b147821cd" target="_blank" rel="noopener">Kafka扩容节点和分区迁移</a></li><li><a href="https://www.cnblogs.com/smartloli/p/10551165.html" target="_blank" rel="noopener">Kafka数据迁移</a></li><li><a href="https://objcoding.com/2019/10/26/kafka-expansion/" target="_blank" rel="noopener">记一次Kafka集群线上扩容</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 分区迁移
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>滴滴开源 Logi-KafkaManager</title>
    <link href="http://yoursite.com/2021/02/11/didi-Logi-KafkaManager/"/>
    <id>http://yoursite.com/2021/02/11/didi-Logi-KafkaManager/</id>
    <published>2021-02-10T16:00:00.000Z</published>
    <updated>2021-02-10T16:25:22.457Z</updated>
    
    <content type="html"><![CDATA[<p>LogI-KafkaManager脱胎于滴滴内部多年的Kafka运营实践经验，是面向Kafka用户、Kafka运维人员打造的共享多租户Kafka云平台</p><hr><h4 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h4><p>文章介绍：</p><ul><li><a href="https://mp.weixin.qq.com/s/ebUY-9WCt05qDX4jet6Enw" target="_blank" rel="noopener">滴滴Logi-KafkaManager开源之路：一站式Kafka集群指标监控与运维管控平台</a></li><li><a href="https://mp.weixin.qq.com/s/JmVrypgR5mI8GH7BvgEs_g" target="_blank" rel="noopener">滴滴开源Logi-KafkaManager 一站式Kafka监控与管控平台</a></li></ul><p>GitHub地址：<a href="https://github.com/didi/Logi-KafkaManager" target="_blank" rel="noopener">Logi-KafkaManager</a></p>]]></content>
    
    <summary type="html">
    
      一站式Kafka集群指标监控与运维管控平台
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 文件存储机制</title>
    <link href="http://yoursite.com/2021/02/10/Kafka-storage-mechanism/"/>
    <id>http://yoursite.com/2021/02/10/Kafka-storage-mechanism/</id>
    <published>2021-02-09T16:00:00.000Z</published>
    <updated>2021-02-14T08:34:12.584Z</updated>
    
    <content type="html"><![CDATA[<p>从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。</p><hr><h4 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h4><p>在美团上看到一个介绍Kafka 文件存储机制的文章感觉挺好的，适合新手阅读。</p><p>详细见<a href="https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html" target="_blank" rel="noopener">《Kafka文件存储机制那些事》</a></p><blockquote><p>PS：链接中说segment文件命名规则是19位数字字符长度，本人查看已部署的kafka服务确认为20个字符长度</p></blockquote><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>Kafka高效文件存储设计特点</p><ul><li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li><li>通过索引信息可以快速定位message和确定response的最大大小。</li><li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li><li>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 文件存储机制
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Shell 2&gt;&amp;1 用法</title>
    <link href="http://yoursite.com/2021/01/25/Linux-Shell-redirection/"/>
    <id>http://yoursite.com/2021/01/25/Linux-Shell-redirection/</id>
    <published>2021-01-24T16:00:00.000Z</published>
    <updated>2021-01-26T14:10:05.086Z</updated>
    
    <content type="html"><![CDATA[<p>Shell 2&gt;&amp;1 用法</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>在Shell脚本中，默认情况下，总是有三个文件处于打开状态，标准输入(键盘输入)、标准输出（输出到屏幕）、标准错误（也是输出到屏幕），它们分别对应的文件描述符是0，1，2 。</p><p>&gt;  默认为标准输出重定向，与 1&gt; 相同</p><p>2&gt;&amp;1  意思是把 标准错误输出 重定向到 标准输出</p><p>同理 1&gt;&amp;2 意思是将标准输出 重定向到 标准错误输出</p><h4 id="运用"><a href="#运用" class="headerlink" title="运用"></a>运用</h4><p>遇到一个问题需要批量扫描机器的JDK版本是不是为1.8的，遇到无法在’java -version’输出中使用grep和awk的情况</p><p>出现这样的问题，主要就是这些消息默认情况下转到stderr，而不是stdout。所有需要先重定向到stdout，然后才能进行此类操作。</p><p>将stderr重定向到stdout</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">java_check&#x3D;$(java -version 2&gt;&amp;1)</span><br><span class="line"></span><br><span class="line">echo $java_check | grep 1.8.0_265-b01</span><br><span class="line">OpenJDK Runtime Environment Corretto-8.265.01.1 (build 1.8.0_265-b01)</span><br></pre></td></tr></table></figure><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>&amp;&gt;file  意思是把标准输出和标准错误输出都重定向到文件file中</p><p>/dev/null是一个文件，这个文件比较特殊，所有传给它的东西它都丢弃掉</p><hr><p>参考链接</p><ul><li><a href="https://blog.csdn.net/u011630575/article/details/52151995" target="_blank" rel="noopener">Shell重定向 ＆&gt;file、2&gt;&amp;1、1&gt;&amp;2 、/dev/null的区别</a></li><li><a href="https://blog.csdn.net/ITqingliang/article/details/103733038" target="_blank" rel="noopener">不能在’java -version’输出中grep和awk</a></li></ul>]]></content>
    
    <summary type="html">
    
      Shell 2&gt;&amp;1 用法
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 光标快速移动的快捷键</title>
    <link href="http://yoursite.com/2021/01/21/Linux-shortcut-keys/"/>
    <id>http://yoursite.com/2021/01/21/Linux-shortcut-keys/</id>
    <published>2021-01-20T16:00:00.000Z</published>
    <updated>2021-01-21T14:11:14.101Z</updated>
    
    <content type="html"><![CDATA[<p>Linux 快速移动光标的快捷键</p><hr><h4 id="光标快速切换到行尾行首"><a href="#光标快速切换到行尾行首" class="headerlink" title="光标快速切换到行尾行首"></a>光标快速切换到行尾行首</h4><p>ctrl+a 行首<br>ctrl+e 行尾</p><h4 id="删除至行尾"><a href="#删除至行尾" class="headerlink" title="删除至行尾"></a>删除至行尾</h4><p>ctrl+k</p><h4 id="左-右移动一个单词"><a href="#左-右移动一个单词" class="headerlink" title="左|右移动一个单词"></a>左|右移动一个单词</h4><p>Esc b 左移一个单词[back]<br>Esc f 右移一个单词[forward]</p><p><strong>注意：每次按下快捷键，需抬起后再按下快捷键，方可多次移动单词</strong></p><hr><p>参考链接</p><ul><li><a href="https://blog.csdn.net/u010865136/article/details/95628409" target="_blank" rel="noopener">Linux命令行——光标快速移动的快捷键</a></li></ul>]]></content>
    
    <summary type="html">
    
      Linux 命令行执行命令时，快速移动光标可节省不少时间
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux Pmap 命令</title>
    <link href="http://yoursite.com/2021/01/08/pmap/"/>
    <id>http://yoursite.com/2021/01/08/pmap/</id>
    <published>2021-01-07T16:00:00.000Z</published>
    <updated>2021-01-08T13:36:46.714Z</updated>
    
    <content type="html"><![CDATA[<p>pmap 命令用于显示一个或多个进程的内存状态</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>pmap能更详细的查看进程内存映射情况。</p><p>pmap命令输出的内容来自于/proc/{pid}/maps和/proc/{pid}/smaps这两个文件，第一个文件包含了每段的一个大概描述，而后一个文件包含了更详细的信息。</p><h4 id="选项"><a href="#选项" class="headerlink" title="选项"></a>选项</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Usage: pmap [options] pid [pid ...]</span><br><span class="line">Options:</span><br><span class="line"> -x, --extended       show details  显示扩展格式</span><br><span class="line"> -X             show even more details</span><br><span class="line">      WARNING: format changes according to &#x2F;proc&#x2F;PID&#x2F;smaps</span><br><span class="line"> -XX             show everything the kernel provides</span><br><span class="line"> -c, --read-rc        read the default rc</span><br><span class="line"> -C, --read-rc-from&#x3D;&lt;file&gt;  read the rc from file</span><br><span class="line"> -n, --create-rc       create new default rc</span><br><span class="line"> -N, --create-rc-to&#x3D;&lt;file&gt;  create new rc to file</span><br><span class="line">      NOTE: pid arguments are not allowed with -n, -N</span><br><span class="line"> -d, --device        show the device format  显示设备格式</span><br><span class="line"> -q, --quiet         do not display header and footer</span><br><span class="line"> -p, --show-path       show path in the mapping</span><br><span class="line"> -A, --range&#x3D;&lt;low&gt;[,&lt;high&gt;] limit results to the given range</span><br><span class="line"> -h, --help   display this help and exit -V, --version output version information and exit</span><br><span class="line">For more details see pmap(1).</span><br></pre></td></tr></table></figure><h4 id="扩展和设备格式"><a href="#扩展和设备格式" class="headerlink" title="扩展和设备格式"></a>扩展和设备格式</h4><p>Address: 映像起始地址<br>Kbytes: 映像大小<br>RSS: 驻留集大小<br>Dirty: 脏页大小<br>Mode: permissions on map 映像权限: r=read, w=write, x=execute, s=shared, p=private (copy on write)<br>Mapping: 映像支持文件；[anon]为已分配内存，可以理解为匿名块；[stack]为程序堆栈<br>Offset: 文件偏移<br>Device: 设备名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@C44 ~]# pmap -d 1</span><br><span class="line">1:  init [5]          </span><br><span class="line">Address  Kbytes Mode Offset      Device  Mapping</span><br><span class="line">00934000   88 r-x-- 0000000000000000 008:00005 ld-2.3.4.so</span><br><span class="line">0094a000    4 r---- 0000000000015000 008:00005 ld-2.3.4.so</span><br><span class="line">0094b000    4 rw--- 0000000000016000 008:00005 ld-2.3.4.so</span><br><span class="line">0094e000  1188 r-x-- 0000000000000000 008:00005 libc-2.3.4.so</span><br><span class="line">00a77000    8 r---- 0000000000129000 008:00005 libc-2.3.4.so</span><br><span class="line">00a79000    8 rw--- 000000000012b000 008:00005 libc-2.3.4.so</span><br><span class="line">00a7b000    8 rw--- 0000000000a7b000 000:00000  [ anon ]</span><br><span class="line">00a85000   52 r-x-- 0000000000000000 008:00005 libsepol.so.1</span><br><span class="line">00a92000    4 rw--- 000000000000c000 008:00005 libsepol.so.1</span><br><span class="line">00a93000   32 rw--- 0000000000a93000 000:00000  [ anon ]</span><br><span class="line">00d9d000   52 r-x-- 0000000000000000 008:00005 libselinux.so.1</span><br><span class="line">00daa000    4 rw--- 000000000000d000 008:00005 libselinux.so.1</span><br><span class="line">08048000   28 r-x-- 0000000000000000 008:00005 init</span><br><span class="line">0804f000    4 rw--- 0000000000007000 008:00005 init</span><br><span class="line">084e1000   132 rw--- 00000000084e1000 000:00000  [ anon ]</span><br><span class="line">b7f5d000    8 rw--- 00000000b7f5d000 000:00000  [ anon ]</span><br><span class="line">bffee000   72 rw--- 00000000bffee000 000:00000  [ stack ]</span><br><span class="line">ffffe000    4 ----- 0000000000000000 000:00000  [ anon ]</span><br><span class="line">mapped: 1700K  writeable&#x2F;private: 276K  shared: 0K</span><br></pre></td></tr></table></figure><p>最后一行的值</p><p>mapped 表示该进程映射的虚拟地址空间大小，也就是该进程预先分配的虚拟内存大小，即ps出的vsz</p><p>writeable/private  表示进程所占用的私有地址空间大小，也就是该进程实际使用的内存大小</p><p>shared 表示进程和其他进程共享的内存大小</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@info ~]# pmap -x 1013</span><br><span class="line">1013: &#x2F;usr&#x2F;sbin&#x2F;sshd</span><br><span class="line">Address Kbytes RSS Dirty Mode Mapping</span><br><span class="line">00110000 1480 92 0 r-x- libcrypto.so.1.0.0</span><br><span class="line">00282000 80 80 80 rw-- libcrypto.so.1.0.0</span><br><span class="line">00296000 12 8 4 rw-- [ anon ]</span><br><span class="line">00299000 36 0 0 r-x- libkrb5support.so.0.1</span><br><span class="line">002a2000 4 4 4 rw-- libkrb5support.so.0.1</span><br><span class="line">002a3000 16 0 0 r-x- libplc4.so</span><br><span class="line">002a7000 4 4 4 rw-- libplc4.so</span><br><span class="line">002ab000 88 4 0 r-x- libaudit.so.1.0.0</span><br><span class="line">002c1000 4 4 4 r--- libaudit.so.1.0.0</span><br><span class="line">002c2000 4 4 4 rw-- libaudit.so.1.0.0</span><br><span class="line">002c3000 216 4 0 r-x- libgssapi_krb5.so.2.2</span><br><span class="line">002f9000 4 4 4 rw-- libgssapi_krb5.so.2.2</span><br><span class="line">002fa000 808 4 0 r-x- libkrb5.so.3.3</span><br><span class="line">003c4000 24 24 24 rw-- libkrb5.so.3.3</span><br><span class="line">003ca000 152 4 0 r-x- libk5crypto.so.3.1</span><br><span class="line">003f0000 4 4 4 rw-- libk5crypto.so.3.1</span><br><span class="line">003f1000 92 0 0 r-x- libnssutil3.so</span><br><span class="line">00408000 12 12 12 rw-- libnssutil3.so</span><br><span class="line">0040b000 12 0 0 r-x- libplds4.so</span><br><span class="line">0040e000 4 4 4 rw-- libplds4.so</span><br><span class="line"> </span><br><span class="line">--- --- --- --- ---</span><br><span class="line">total kB 8232 - - -</span><br></pre></td></tr></table></figure><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>/proc/pid/smaps各字段含义</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">01785000-017a6000 rw-p 00000000 00:00 0                                  [heap]</span><br><span class="line">Size:                132 kB</span><br><span class="line">Rss:                  12 kB</span><br><span class="line">Pss:                  12 kB</span><br><span class="line">Shared_Clean:          0 kB</span><br><span class="line">Shared_Dirty:          0 kB</span><br><span class="line">Private_Clean:         0 kB</span><br><span class="line">Private_Dirty:        12 kB</span><br><span class="line">Referenced:           12 kB</span><br><span class="line">Anonymous:            12 kB</span><br><span class="line">AnonHugePages:         0 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">KernelPageSize:        4 kB</span><br><span class="line">MMUPageSize:           4 kB</span><br></pre></td></tr></table></figure><p>见<a href="https://blog.csdn.net/u010902721/article/details/46446031" target="_blank" rel="noopener">linux /proc/pid/smaps各字段含义</a></p><hr><p>参考链接</p><ul><li><a href="https://segmentfault.com/a/1190000008125059" target="_blank" rel="noopener">Linux进程的内存使用情况</a></li><li><a href="https://www.jb51.net/article/124947.htm" target="_blank" rel="noopener">Linux性能测试 pmap命令详解</a></li></ul>]]></content>
    
    <summary type="html">
    
      pmap 命令用于显示一个或多个进程的内存状态
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 重置偏移量到某个时间点</title>
    <link href="http://yoursite.com/2020/12/31/Kafka-offset-to-datetime/"/>
    <id>http://yoursite.com/2020/12/31/Kafka-offset-to-datetime/</id>
    <published>2020-12-30T16:00:00.000Z</published>
    <updated>2021-02-14T09:00:52.692Z</updated>
    
    <content type="html"><![CDATA[<hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>有需求排查某个时间的数据是否重复，因此需要将消费者组重置到某个时间点</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>kafka-consumer-groups.sh 使用 –to-datetime 参数可以做到，需要注意这个–to-datetime是utc时间，需要减去8个小时</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group group --reset-offsets --all-topics --to-datetime 2020-12-31T02:00:00.000 --execute</span><br></pre></td></tr></table></figure><p>当然可以根据时区设置时间，以东8时区进行设置，把对应时间改为 2020-12-31T10:00:00.000+08:00</p><p>重置前有个前提是consumer group状态必须是inactive的，即不能是处于正在工作中的状态。</p><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><h5 id="Message-body"><a href="#Message-body" class="headerlink" title="Message body"></a>Message body</h5><p>Kafka从0.10.0.0版本起，在消息内新增加了个timestamp字段</p><p>时间戳的类型有两种：可以设定为producer创建消息的时间(CreateTime)，也可以设定为该消息写入Broker的时间(LogAppendTime)。默认为CreateTime，可通过参数message.timestamp.type 实现Topic级别的类型更改，Broker级别的时间戳类型参数为log.message.timestamp.type</p><p>有关Kafka Message新增时间戳的相关细节，可详见Kafka官方Doc <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-32+-+Add+timestamps+to+Kafka+message" target="_blank" rel="noopener">KIP-32 - Add timestamps to Kafka message</a></p><h5 id="Log-Segment"><a href="#Log-Segment" class="headerlink" title="Log Segment"></a>Log Segment</h5><p>从Kafka 0.10开始，对于日志文件，新增一个<code>.timeindex</code>文件，即每个Segment分别由<code>.log、.index</code>和<code>.timeindex</code>这三个文件组成。</p><p>有关Log Segment 新增.timeindex相关细节，可详见Kafka官方Doc <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-33+-+Add+a+time+based+log+index" target="_blank" rel="noopener">KIP-33 - Add a time based log index</a></p><p>Kafka API提供了一个 offsetsForTimes（Map&lt;TopicPartition, Long&gt; timestampsToSearch）方法，该方法会返回时间戳大于等于待查询时间的第一条消息对应的偏移量。</p><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>Kafka 还支持其他位移重设策略，感兴趣的可以自行阅读<a href="https://www.cnblogs.com/huxi2b/p/7284767.html" target="_blank" rel="noopener">Kafka consumer group位移重设</a></p><hr><p>参考链接</p><ul><li><a href="https://blog.csdn.net/u010003835/article/details/83314766" target="_blank" rel="noopener">Kafka-kafka 重置偏移量 ：通过 kafka-consumer-groups.sh 针对 &gt;= kafka 0.11</a></li><li><a href="https://www.cnblogs.com/tonglin0325/p/7039747.html" target="_blank" rel="noopener">Ubuntu下安装和使用zookeeper和kafka</a></li><li><a href="https://yhyr.github.io/2019/01/23/Kafka-Timestamp/" target="_blank" rel="noopener">Kafka Timestamp</a></li><li><a href="https://juejin.cn/post/6844903919424913415" target="_blank" rel="noopener">Kafka 原理和实战</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 重置偏移量到某个时间点
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 系统 inodes 资源耗尽</title>
    <link href="http://yoursite.com/2020/12/27/Linux-inodes/"/>
    <id>http://yoursite.com/2020/12/27/Linux-inodes/</id>
    <published>2020-12-26T16:00:00.000Z</published>
    <updated>2020-12-27T14:55:33.673Z</updated>
    
    <content type="html"><![CDATA[<p>inodes 资源耗尽处理</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>可以看下阮老师的文章理解下，参见<a href="https://www.ruanyifeng.com/blog/2011/12/inode.html" target="_blank" rel="noopener">理解inode</a></p><h4 id="处理"><a href="#处理" class="headerlink" title="处理"></a>处理</h4><p>马哥Linux运维有介绍相关处理方法，参见<a href="https://mp.weixin.qq.com/s/9rfSsqZdZm8QmNYn3q19gA" target="_blank" rel="noopener">Linux系统inodes资源耗尽问题</a></p>]]></content>
    
    <summary type="html">
    
      Linux 系统 inodes 资源耗尽
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 失效副本</title>
    <link href="http://yoursite.com/2020/12/24/kafka-under-replicated/"/>
    <id>http://yoursite.com/2020/12/24/kafka-under-replicated/</id>
    <published>2020-12-23T16:00:00.000Z</published>
    <updated>2020-12-24T12:55:32.522Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 失效副本</p><hr><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>每个分区的多个副本称之为AR（assigned replicas），包含至多一个leader副本和多个follower副本。与AR对应的另一个重要的概念就是ISR（in-sync replicas），ISR是指与leader副本保持同步状态的副本集合，当然leader副本本身也是这个集合中的一员。而ISR之外，也就是处于同步失败或失效状态的副本，副本对应的分区也就称之为同步失效分区，即under-replicated分区。</p><h4 id="判定"><a href="#判定" class="headerlink" title="判定"></a>判定</h4><p>怎么样判定一个分区是否有副本是处于同步失效状态的呢？从Kafka 0.9.x版本开始通过唯一的一个参数replica.lag.time.max.ms（默认大小为10,000）来控制，当ISR中的一个follower副本滞后leader副本的时间超过参数replica.lag.time.max.ms指定的值时即判定为副本失效，需要将此follower副本剔出除ISR之外。具体实现原理很简单，当follower副本将leader副本的LEO（Log End Offset，每个分区最后一条消息的位置）之前的日志全部同步时，则认为该follower副本已经追赶上leader副本，此时更新该副本的lastCaughtUpTimeMs标识。Kafka的副本管理器（ReplicaManager）启动时会启动一个副本过期检测的定时任务，而这个定时任务会定时检查当前时间与副本的lastCaughtUpTimeMs差值是否大于参数replica.lag.time.max.ms指定的值。千万不要错误的认为follower副本只要拉取leader副本的数据就会更新lastCaughtUpTimeMs，试想当leader副本的消息流入速度大于follower副本的拉取速度时，follower副本一直不断的拉取leader副本的消息也不能与leader副本同步，如果还将此follower副本置于ISR中，那么当leader副本失效，而选取此follower副本为新的leader副本，那么就会有严重的消息丢失。</p><hr><p>参考链接</p><ul><li><a href="https://www.jianshu.com/p/aed1326880f1" target="_blank" rel="noopener">Kafka解析之失效副本</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 失效副本
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka __consumer_offsets 占用磁盘空间过大处理</title>
    <link href="http://yoursite.com/2020/12/16/kafka-consumer-offsets/"/>
    <id>http://yoursite.com/2020/12/16/kafka-consumer-offsets/</id>
    <published>2020-12-15T16:00:00.000Z</published>
    <updated>2021-01-10T12:29:08.294Z</updated>
    
    <content type="html"><![CDATA[<p>__consumer_offsets 占用磁盘空间过大处理</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>生产环境上有一台Kafka机器磁盘告警，通过查看发现kafka的日志储存目录数据盘占用80%的存储，发现是__consumer_offsets的储存文件过大导致的</p><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><p>Kafka 中用于保存消费者消费位移的主题<code>__consumer_offsets</code>与普通topic在清理策略上不同，使用的就是Log Compaction策略。</p><p>Log Compaction是kafka提供的一种整理offset数据的方式。Log Compaction对于有相同key的的不同value值，只保留最后一个版本。如果应用只关心key对应的最新value值，可以开启Kafka的日志清理功能，Kafka会定期将相同key的消息进行合并，只保留最新的value值。</p><h4 id="清理"><a href="#清理" class="headerlink" title="清理"></a>清理</h4><p>查看现有的<code>__consumer_offsets</code>清理策略</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-configs.sh --zookeeper xxxx:2181 --entity-type topics --entity-name __consumer_offsets --describe</span><br></pre></td></tr></table></figure><p>查看第一行输出可以看到 <code>cleanup.policy=compact</code>，则说明cleanup.policy是compact</p><p><code>__consumer_offsets</code>的确与普通topic在清理策略上不同，也就是参数cleanup.policy上，给<code>__consumer_offsets</code>手动添加了清理策略</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-configs.sh --zookeeper xxxx:2181 --entity-type topics --entity-name __consumer_offsets --alter --add-config &#39;cleanup.policy&#x3D;delete&#39;</span><br></pre></td></tr></table></figure><p>添加完后，等了一会磁盘占用就会减少</p><hr><p>参考链接</p><ul><li><a href="https://www.codenong.com/cs107089637/" target="_blank" rel="noopener">KAFKA consumer_offsets 清理</a></li></ul>]]></content>
    
    <summary type="html">
    
      __consumer_offsets 占用磁盘空间过大处理
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 事务日志和 snapshot 清理</title>
    <link href="http://yoursite.com/2020/12/08/zookeeper-log-clean/"/>
    <id>http://yoursite.com/2020/12/08/zookeeper-log-clean/</id>
    <published>2020-12-07T16:00:00.000Z</published>
    <updated>2020-12-08T15:35:29.725Z</updated>
    
    <content type="html"><![CDATA[<p>Zookeeper 运行过程会产生大量的事务日志和 snapshot 镜像文件，讨论下如何清理事务日志和snapshot</p><hr><h4 id="日志文件"><a href="#日志文件" class="headerlink" title="日志文件"></a>日志文件</h4><p>在使用ZK过程中，会有dataDir和dataLogDir两个目录，分别用于snapshot和事务日志的输出（默认情况下只有dataDir目录，snapshot和事务日志都保存在这个目录中）</p><p>ZK在完成若干次事务日志之后（在ZK中，凡是对数据有更新的操作，比如创建节点，删除节点或是对节点数据内容进行更新等，都会记录事务日志），ZK会触发一次快照（snapshot），将当前server上所有节点的状态以快照文件的形式dump到磁盘上去，即snapshot文件。这里的若干次事务日志是可以配置的，默认是100000，具体参看配置参数”snapCount”的介绍</p><h4 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h4><h5 id="配置自动清理"><a href="#配置自动清理" class="headerlink" title="配置自动清理"></a>配置自动清理</h5><p>ZK在3.4.0版本以后提供了自动清理snapshot和事务日志的功能通过配置 <code>autopurge.snapRetainCount</code> 和 <code>autopurge.purgeInterval</code> 这两个参数能够实现定时清理了。</p><p>当前ZK版本为3.4.6，因此可以使用自带的清理功能</p><ul><li>autopurge.purgeInterval: 这个参数指定了清理频率，单位是小时，需要填写一个1或更大的整数，默认是0，表示不开启自己清理功能。</li><li>autopurge.snapRetainCount: 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">autopurge.snapRetainCount&#x3D;50</span><br><span class="line">autopurge.purgeInterval&#x3D;1</span><br></pre></td></tr></table></figure><p>每一个小时清理一次，一次保留50个文件</p><h5 id="自定义清理脚本"><a href="#自定义清理脚本" class="headerlink" title="自定义清理脚本"></a>自定义清理脚本</h5><p>clean_zook_log.sh 脚本内容如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">           </span><br><span class="line">#snapshot file dir</span><br><span class="line">dataDir&#x3D;&#x2F;home&#x2F;tu&#x2F;data&#x2F;zookeeper&#x2F;version-2</span><br><span class="line">#tran log dir</span><br><span class="line">dataLogDir&#x3D;&#x2F;home&#x2F;tu&#x2F;data&#x2F;zookeeper&#x2F;version-2</span><br><span class="line">#zk log dir</span><br><span class="line">logDir&#x3D;&#x2F;home&#x2F;tu&#x2F;zookeeper&#x2F;logs</span><br><span class="line">#Leave 60 files</span><br><span class="line">count&#x3D;50</span><br><span class="line">count&#x3D;$[$count+1]</span><br><span class="line">ls -t $dataLogDir&#x2F;log.* | tail -n +$count | xargs rm -f</span><br><span class="line">ls -t $dataDir&#x2F;snapshot.* | tail -n +$count | xargs rm -f</span><br><span class="line">ls -t $logDir&#x2F;zookeeper.log.* | tail -n +$count | xargs rm -f</span><br></pre></td></tr></table></figure><p>这个脚本保留最新的50个文件，可以将这个脚本添加到crontab中，设置为每30分钟执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">30 * * * * &#x2F;bin&#x2F;bash &#x2F;home&#x2F;tu&#x2F;zookeeper&#x2F;bin&#x2F;clean_zook_log.sh &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h5 id="zkCleanup-sh清理"><a href="#zkCleanup-sh清理" class="headerlink" title="zkCleanup.sh清理"></a>zkCleanup.sh清理</h5><p>ZK自己有自带的清理文件 bin/zkCleanup.sh，可以直接使用这个脚本也是可以执行清理工作的，是使用的zookeeper.jar里的<code>org.apache.zookeeper.server.PurgeTxnLog</code>来做的</p><hr><p>参考链接</p><ul><li><a href="https://www.cnblogs.com/the-tops/p/5783722.html" target="_blank" rel="noopener">ZooKeepr日志清理【转】</a></li><li><a href="https://ningyu1.github.io/site/post/89-zookeeper-cleanlog/" target="_blank" rel="noopener">Zookeeper事务日志和snapshot清理方式</a></li><li><a href="https://www.cnblogs.com/linjiqin/archive/2013/03/16/2963439.html" target="_blank" rel="noopener">zookeeper配置文件详解</a></li><li><a href="https://mp.weixin.qq.com/s/bDwKeELWESerPznCoSdesg" target="_blank" rel="noopener">不懂 Zookeeper？没关系，看这篇就够了</a></li></ul>]]></content>
    
    <summary type="html">
    
      Zookeeper 事务日志和 snapshot 清理
    
    </summary>
    
    
      <category term="Zookeeper" scheme="http://yoursite.com/categories/Zookeeper/"/>
    
    
  </entry>
  
  <entry>
    <title>async-profile 工具</title>
    <link href="http://yoursite.com/2020/05/23/async-profile/"/>
    <id>http://yoursite.com/2020/05/23/async-profile/</id>
    <published>2020-05-22T16:00:00.000Z</published>
    <updated>2020-05-23T12:31:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>超好用的自带火焰图的 Java 性能分析工具</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>火焰图常用来进行性能分析，async-profiler 就是一种自带火焰图的 Java 性能分析工具</p><blockquote><p>最近 Arthas 性能分析工具上线了火焰图分析功能，Arthas 使用 async-profiler 生成 CPU/内存火焰图进行性能分析，弥补了之前内存分析的不足。在 Arthas 上使用还是比较方便的，使用方式可以看官方文档。<a href="https://alibaba.github.io/arthas/profiler.html" target="_blank" rel="noopener">Arthas 火焰图官方文档</a></p></blockquote><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>具体使用请跳转阅读<a href="https://juejin.im/post/5ded9ade6fb9a0164a10bcda#heading-1" target="_blank" rel="noopener">《超好用的自带火焰图的 Java 性能分析工具 Async-profiler 了解一下》</a>，该文章从安装、使用到案例都有介绍，适合入门了解。</p>]]></content>
    
    <summary type="html">
    
      超好用的自带火焰图的 Java 性能分析工具
    
    </summary>
    
    
      <category term="Tools" scheme="http://yoursite.com/categories/Tools/"/>
    
    
  </entry>
  
  <entry>
    <title>火焰图</title>
    <link href="http://yoursite.com/2020/05/23/flame-graph/"/>
    <id>http://yoursite.com/2020/05/23/flame-graph/</id>
    <published>2020-05-22T16:00:00.000Z</published>
    <updated>2021-01-01T15:17:47.330Z</updated>
    
    <content type="html"><![CDATA[<p>火焰图（flame graph）是性能分析的利器</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>在涉猎运维知识时，多次看到大佬们使用火焰图来进行性能分析，因此跟着涨了下知识。</p><h4 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h4><p>先来体验下火焰图 – <a href="https://queue.acm.org/downloads/2016/Gregg4.svg" target="_blank" rel="noopener">SVG 图片</a>，该图来自阮一峰老师的<a href="https://www.ruanyifeng.com/blog/2017/09/flame-graph.html" target="_blank" rel="noopener">《如何读懂火焰图？》</a>，其用来展示 CPU 的调用栈。</p><p>y 轴表示调用栈，每一层都是一个函数。调用栈越深，火焰就越高，顶部就是正在执行的函数，下方都是它的父函数。</p><p>x 轴表示抽样数，如果一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长。注意，x 轴不代表时间，而是所有的调用栈合并后，按字母顺序排列的。</p><p>火焰图就是看顶层的哪个函数占据的宽度最大。只要有”平顶”（plateaus），就表示该函数可能存在性能问题，也是常说的”大平顶”问题</p><p>颜色没有特殊含义，因为火焰图表示的是 CPU 的繁忙程度，所以一般选择暖色调。</p><h4 id="互动"><a href="#互动" class="headerlink" title="互动"></a>互动</h4><p>火焰图是 SVG 图片，可以与用户互动。</p><p><strong>鼠标悬浮</strong></p><p>火焰的每一层都会标注函数名，鼠标悬浮时会显示完整的函数名、抽样抽中的次数、占据总抽样次数的百分比。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqld&#39;JOIN::exec (272,959 samples, 78.34 percent)</span><br></pre></td></tr></table></figure><p><strong>点击放大</strong></p><p>在某一层点击，火焰图会水平放大，该层会占据所有宽度，显示详细信息。左上角会同时显示”Reset Zoom”，点击该链接，图片就会恢复原样。</p><p><img src="/images/blog/2020-05-23-1.png" alt></p><p><strong>搜索</strong></p><p>按下 Ctrl + F 会显示一个搜索框，用户可以输入关键词或正则表达式，所有符合条件的函数名会高亮显示。</p><h4 id="生成工具"><a href="#生成工具" class="headerlink" title="生成工具"></a>生成工具</h4><p>以perf为例，看一下<code>flamegraph</code>的使用方法</p><p>1、Flame Graph项目位于GitHub上：<a href="https://github.com/brendangregg/FlameGraph" target="_blank" rel="noopener">https://github.com/brendangregg/FlameGraph</a></p><p>2、可以用git将其clone下来：git clone <a href="https://github.com/brendangregg/FlameGraph.git" target="_blank" rel="noopener">https://github.com/brendangregg/FlameGraph.git</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1、第一步</span><br><span class="line"></span><br><span class="line">perf record -e cpu-clock -g -p 28591</span><br><span class="line"></span><br><span class="line">Ctrl+c结束执行后，在当前目录下会生成采样数据perf.data.</span><br><span class="line"></span><br><span class="line">2、第二步</span><br><span class="line"></span><br><span class="line">用perf script工具对perf.data进行解析</span><br><span class="line"></span><br><span class="line">perf script -i perf.data &amp;&gt; perf.unfold</span><br><span class="line"></span><br><span class="line">3、第三步</span><br><span class="line"></span><br><span class="line">将perf.unfold中的符号进行折叠：</span><br><span class="line"></span><br><span class="line">.&#x2F;stackcollapse-perf.pl perf.unfold &amp;&gt; perf.folded</span><br><span class="line"></span><br><span class="line">4、最后生成svg图：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">.&#x2F;flamegraph.pl perf.folded &gt; perf.svg</span><br></pre></td></tr></table></figure><p>现在可以使用自带火焰图的 Java 性能分析工具 <a href="https://github.com/jvm-profiling-tools/async-profiler" target="_blank" rel="noopener">Async-profiler</a><br>，其已经内置了开箱即用的 SVG 文件生成功能。</p><hr><p>参考链接</p><ul><li><a href="https://www.ruanyifeng.com/blog/2017/09/flame-graph.html" target="_blank" rel="noopener">如何读懂火焰图？</a></li><li><a href="https://juejin.im/post/5ded9ade6fb9a0164a10bcda#heading-2" target="_blank" rel="noopener">超好用的自带火焰图的 Java 性能分析工具 Async-profiler 了解一下</a></li><li><a href="https://zhuanlan.zhihu.com/p/85654612" target="_blank" rel="noopener">Linux火焰图性能分析</a></li></ul>]]></content>
    
    <summary type="html">
    
      读懂火焰图
    
    </summary>
    
    
      <category term="Distributed" scheme="http://yoursite.com/categories/Distributed/"/>
    
    
  </entry>
  
</feed>
