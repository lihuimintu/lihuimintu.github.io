<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>lihuimintu</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-08-11T15:47:47.067Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>图</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka Pagecache 原理</title>
    <link href="http://yoursite.com/2021/08/11/kafka-pagecache/"/>
    <id>http://yoursite.com/2021/08/11/kafka-pagecache/</id>
    <published>2021-08-10T16:00:00.000Z</published>
    <updated>2021-08-11T15:47:47.067Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 重度依赖底层操作系统提供的 PageCache 功能</p><hr><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>Kafka 重度依赖底层操作系统提供的 PageCache 功能。</p><p>Kafka为什么不自己管理缓存，而非要用page cache？原因有如下三点</p><ul><li>JVM中一切皆对象，数据的对象存储会带来所谓object overhead，浪费空间；</li><li>如果由JVM来管理缓存，会受到GC的影响，并且过大的堆也会拖累GC的效率，降低吞吐量；</li><li>一旦程序崩溃，自己管理的缓存数据会全部丢失。</li></ul><p>Kafka三大件（broker、producer、consumer）与page cache的关系可以用下面的简图来表示。</p><p><img src="/images/blog/2021-08-11-2.png" alt></p><p>当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。</p><p>来看美团详细版的图</p><p><img src="/images/blog/2021-08-11-1.png" alt></p><p>对于Produce请求：Server端的I/O线程统一将请求中的数据写入到操作系统的PageCache后立即返回，当消息条数到达一定阈值后，Kafka应用本身或操作系统内核会触发强制刷盘操作（如左侧流程图所示）。</p><p>对于Consume请求：主要利用了操作系统的ZeroCopy机制，当Kafka Broker接收到读数据请求时，会向操作系统发送sendfile系统调用，操作系统接收后，首先试图从PageCache中获取数据（如中间流程图所示）；如果数据不存在，会触发缺页异常中断将数据从磁盘读入到临时缓冲区中（如右侧流程图所示），随后将数据拷贝到网卡缓冲区中等待后续的TCP传输（数据拷贝利用DMA操作减少拷贝次数和上下文切换）。</p><p>由此我们可以得出重要的结论：如果Kafka producer的生产速率与consumer的消费速率相差不大，那么就能几乎只靠对broker page cache的读写完成整个生产-消费过程，磁盘访问非常少。并且Kafka持久化消息到各个topic的partition文件时，是只追加的顺序写，充分利用了磁盘顺序访问快的特性，效率高。</p><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p>对于单纯运行Kafka的集群而言，首先要注意的就是为Kafka设置合适（不那么大）的JVM堆大小。从上面的分析可知，Kafka的性能与堆内存关系并不大，而对page cache需求巨大。根据经验值，为Kafka分配5~8GB的堆内存就已经足足够用了，将剩下的系统内存都作为page cache空间，可以最大化I/O效率。</p><p>另一个需要特别注意的问题是lagging consumer，即那些消费速率慢、明显落后的consumer。它们要读取的数据有较大概率不在broker page cache中，因此会增加很多不必要的读盘操作。比这更坏的是，lagging consumer读取的“冷”数据仍然会进入page cache，污染了多数正常consumer要读取的“热”数据，连带着正常consumer的性能变差。</p><p>在Linux操作系统中，写操作是异步的，即写操作返回的时候数据并没有真正写到磁盘上，而是先写到了系统cache里，随后由pdflush内核线程将系统中的脏页写到磁盘上</p><ul><li>/proc/sys/vm/dirty_writeback_centisecs：flush检查的周期。单位为0.01秒，默认值500，即5秒。每次检查都会按照以下三个参数控制的逻辑来处理。</li><li>/proc/sys/vm/dirty_expire_centisecs：如果page cache中的页被标记为dirty的时间超过了这个值，就会被直接刷到磁盘。单位为0.01秒。默认值3000，即半分钟。</li><li>/proc/sys/vm/dirty_background_ratio：如果dirty page的总大小占空闲内存量的比例超过了该值，就会在后台调度pdflush内核线程异步写磁盘，不会阻塞当前的write()操作。默认值为10%。</li><li>/proc/sys/vm/dirty_ratio：如果dirty page的总大小占总内存量的比例超过了该值，就会阻塞所有进程的write()操作，并且强制每个进程将自己的文件写入磁盘。默认值为20%。</li></ul><hr><p>参考链接</p><ul><li><a href="https://zhuanlan.zhihu.com/p/353304786" target="_blank" rel="noopener">2021-2-27：Linux 下如何优化 Java MMAP 写入</a></li><li><a href="https://cloud.tencent.com/developer/article/1488144" target="_blank" rel="noopener">聊聊page cache与Kafka之间的事儿</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka Pagecache 原理
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 显示Leader不可用的分区</title>
    <link href="http://yoursite.com/2021/07/20/kafka-partitions/"/>
    <id>http://yoursite.com/2021/07/20/kafka-partitions/</id>
    <published>2021-07-19T16:00:00.000Z</published>
    <updated>2021-08-11T08:54:16.738Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 项目的 CLI 工具</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>当集群Broker出现问题的时候，Topic的分区会出现两种情况</p><ul><li>不同步的分区</li><li>Leader不可用</li></ul><p>Kafka 有相关命令能支持这两类分区问题的过滤，执行<code>bin/kafka-topics.sh</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--unavailable-partitions                 if set when describing topics, only    </span><br><span class="line">                                           show partitions whose leader is not  </span><br><span class="line">                                           available                            </span><br><span class="line">--under-replicated-partitions            if set when describing topics, only    </span><br><span class="line">                                           show under replicated partitions</span><br></pre></td></tr></table></figure><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><p>通过监控面板，可以知道有分区不同步</p><p><img src="/images/blog/2021-07-20-1.png" alt></p><p>这时，需要知道是哪些分区不同步</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --bootstrap-server xxx:9092 --under-replicated-partitions</span><br></pre></td></tr></table></figure><p>同理对应想知道哪些分区leader不可用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --bootstrap-server xxx:9092 --unavailable-partitions</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Kafka 显示Leader不可用的分区
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>pulsarctl</title>
    <link href="http://yoursite.com/2021/07/11/pulsarctl/"/>
    <id>http://yoursite.com/2021/07/11/pulsarctl/</id>
    <published>2021-07-10T16:00:00.000Z</published>
    <updated>2021-07-11T10:28:01.316Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 项目的 CLI 工具</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>pulsarctl 是一个 CLI 工具，采用 Go 语言开发，基于 Pulsar REST API，用于控制和管理 Pulsar 集群、租户、命名空间、主题、模式、源、接收器、函数等。</p><p>Github地址：<a href="https://github.com/streamnative/pulsarctl" target="_blank" rel="noopener">https://github.com/streamnative/pulsarctl</a></p><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>pulsarctl 支持 Mac、Linux、Windows，具体部署见官方文档。</p><p>使用帮助信息<code>pulsarctl -h</code></p><h5 id="context"><a href="#context" class="headerlink" title="context"></a>context</h5><p>在多集群中，context是一个非常有趣和有用的功能。可以帮助用户缓存多个集群的信息，可以在多个集群之间切换。</p><p>见<a href="https://github.com/streamnative/pulsarctl/blob/master/docs/en/how-to-use-context.md" target="_blank" rel="noopener">How to use pulsarctl context</a></p><h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><p>pulsarctl还是挺好用的，开箱即用，不需要专门部署JDK来执行pulsar-admin</p><p>另外在执行相同命令下，pulsarctl比pulsar-admin快很多</p><p><img src="/images/blog/2021-07-11-1.png" alt></p>]]></content>
    
    <summary type="html">
    
      pulsarctl
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>Pulsar 端口信息</title>
    <link href="http://yoursite.com/2021/05/17/pulsar-port/"/>
    <id>http://yoursite.com/2021/05/17/pulsar-port/</id>
    <published>2021-05-16T16:00:00.000Z</published>
    <updated>2021-05-17T13:12:06.402Z</updated>
    
    <content type="html"><![CDATA[<p>默认情况下，Pulsar 集群会使用如下的端口信息。</p><hr><h4 id="端口信息"><a href="#端口信息" class="headerlink" title="端口信息"></a>端口信息</h4><p>默认情况下，Pulsar 集群会使用如下的端口信息。</p><table><thead><tr><th>组件</th><th>端口</th><th>描述</th></tr></thead><tbody><tr><td>Broker</td><td>6650</td><td>Broker 二进制协议通信端口（不开启加密）</td></tr><tr><td>Broker</td><td>6651</td><td>Broker 二进制协议通信端口（开启加密）</td></tr><tr><td>Broker</td><td>8080</td><td>Broker admin 和 restful 服务的端口号（不开启加密）</td></tr><tr><td>Broker</td><td>8443</td><td>Broker admin 和 restful 服务的端口号（开启加密）</td></tr><tr><td>Bookie</td><td>8000</td><td>Bookie admin 和 restful 服务的端口号 (plain text, aka HTTP)</td></tr><tr><td>Bookie</td><td>3181</td><td>Bookie 协议通讯端口 (plain text or TLS encrypted)</td></tr><tr><td>Table Services</td><td>4181</td><td>Bookie table service API 端口(gRPC)</td></tr><tr><td>Zookeeper</td><td>2181</td><td>zk client之间的通讯端口</td></tr><tr><td>Zookeeper</td><td>2888</td><td>zk followers 节点之间的通讯端口</td></tr><tr><td>Zookeeper</td><td>3888</td><td>zk leader 节点之间的通讯端口</td></tr></tbody></table><p>根据实际的部署环境，用户可以自定义相关的端口信息。</p>]]></content>
    
    <summary type="html">
    
      Pulsar 端口信息
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>Pulsar 消息保留（Retention）</title>
    <link href="http://yoursite.com/2021/05/05/pulsar-retention/"/>
    <id>http://yoursite.com/2021/05/05/pulsar-retention/</id>
    <published>2021-05-04T16:00:00.000Z</published>
    <updated>2021-05-06T14:12:27.676Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 消息保留（Retention）</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>全文全摘自<a href="https://mp.weixin.qq.com/s/fU7HjmuaEzJllOTSNtTg3g" target="_blank" rel="noopener">博文推荐 | 一文带你看懂 Pulsar 的消息保留和过期策略</a></p><p>有些话，第一次看时没看明白，后面在看了几次之后按自己的理解复制了一遍</p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>默认情况下，Pulsar Broker 会对消息做如下处理：</p><ul><li>当消息被 Consumer 确认之后，会立即执行删除操作。</li><li>对于未被确认的消息会存储到 backlog 中。</li></ul><p>有时默认行为并不能满足生产需求，因此Pulsar提供了如下配置策略来覆盖这些行为：</p><ul><li>Retention策略: 用户可以将 Consumer 已经确认的消息保留下来。</li><li>TTL 策略: 对于未确认的消息，用户可以通过设置 TTL 来使未确认的消息到达已经确认的状态。</li></ul><p>上述两种策略的设置都是在 NameSpace 的级别进行设置。</p><h4 id="Retention-策略"><a href="#Retention-策略" class="headerlink" title="Retention 策略"></a>Retention 策略</h4><p>Retention 策略的设置提供了两种方式</p><ul><li>消息的大小，默认值：<code>defaultRetentionSizeInMB=0</code></li><li>消息被保存的时间，默认值：<code>defaultRetentionTimeInMinutes=0</code></li></ul><p>可以在 broker.conf 中对这两项内容进行配置，也支持通过命令行的配置</p><h4 id="Backlog"><a href="#Backlog" class="headerlink" title="Backlog"></a>Backlog</h4><p>backlog 是未被确认消息的集合，有个前提是backlog是针对持久化的topic（有<a href="https://pulsar.apache.org/docs/zh-CN/concepts-messaging/#%E9%9D%9E%E6%8C%81%E4%B9%85topic" target="_blank" rel="noopener">非持久化的topic</a>）</p><p>Pulsar Broker 会将所有未确认或者未处理的消息都存放到 backlog 中。</p><p>同样的，可以在 NameSpace 级别对 backlog 的大小进行配置。</p><p>需要注意的是，对 backlog 进行配置时，需要明确以下两点：</p><ul><li>在当前的 NameSpace 下，每一个 Topic 允许的backlog大小是多少</li><li>如果超过设定的 backlog 的阈值，将会执行哪些操作</li></ul><p>当超过设定的 backlog 的阈值，Pulsar 提供了以下三种策略供用户选择：</p><table><thead><tr><th>Policy</th><th>Action</th></tr></thead><tbody><tr><td>producer_request_hold</td><td>Broker会继续提供服务，但是对于之后未确认的消息不做持久化操作</td></tr><tr><td>producer_exception</td><td>Broker会抛出异常，断开与produce的连接</td></tr><tr><td>consumer_backlog_eviction</td><td>Broker会删除backlog中之前的积压的消息</td></tr></tbody></table><h4 id="Time-To-Live-（TTL）"><a href="#Time-To-Live-（TTL）" class="headerlink" title="Time To Live （TTL）"></a>Time To Live （TTL）</h4><p>默认情况下，Pulsar 会持久化所有未被确认的消息。如果未被确认的消息有很多，这种策略会造成大量的消息被积压，导致磁盘空间增大。</p><p>可以通过设置 TTL 使得未被确认的消息进入到被确认的状态，当超过设定的 TTL 时间之后，配合相应的 Retention 策略将消息丢弃。</p><p>TTL 的一个典型使用场景是，当 Consumer 由于某些原因出现故障，不能正常消费消息，这时 Producer 还在不断的往 Topic 中生产消息，会造成 Topic 中有大量的未确认的消息出现，这时你可以通过设置 TTL 将这些未确认的消息变为已确认的状态。</p><h4 id="TTL、Backlog-与-Retention-的区别和联系"><a href="#TTL、Backlog-与-Retention-的区别和联系" class="headerlink" title="TTL、Backlog 与 Retention 的区别和联系"></a>TTL、Backlog 与 Retention 的区别和联系</h4><p>可以发现，TTL 只去处理一件事情，将未被确认的消息变为被确认的状态，TTL 本身不会去涉及相应的删除操作</p><p>具体如下图所示</p><p><img src="/images/blog/2021-05-06-1.png" alt></p><ol><li>在 T1 阶段，m1-m5 这 5 条消息被确认，m6-m10 这 5 条消息未被确认</li><li>在 T2 阶段，对 m6、m7、m8 这三条消息设置 TTL 策略 </li><li>在 T3 阶段，到达 TTL 设定的阈值，m6、m7、m8 这三条消息被确认</li></ol><p>通过上图可以看到，对于 backlog 中未被确认的消息，当设置 TTL 之后，会将未确认消息的状态变为确认的状态。</p><p>TTL 在这里所起到的作用就是将消息的 Cursor 从 m5 移动到 m8，m6、m7、m8 这三条消息变为已确认状态。</p><p>Pulsar 是一个 multiple-subscription 的消息系统，对于 Topic 中的一条消息，只有当所有订阅者都对这条消息 ack 或者消费了，它才能被删除。</p><p>默认情况下，Pulsar Broker 会将所有未确认的消息持久化到 backlog 中</p><p>TTL 的功能是，你可以将这些未被确认的消息变为被确认的状态</p><p>Retention 是当消息处于被确认的状态时，可以对已确认的消息进行的相应的保留策略</p><hr><p>参考链接</p><ul><li><a href="https://mp.weixin.qq.com/s/fU7HjmuaEzJllOTSNtTg3g" target="_blank" rel="noopener">博文推荐 | 一文带你看懂 Pulsar 的消息保留和过期策略</a></li></ul>]]></content>
    
    <summary type="html">
    
      Pulsar 消息保留（Retention）
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>Pulsar 消息确认（ACK）</title>
    <link href="http://yoursite.com/2021/05/05/pulsar-ack/"/>
    <id>http://yoursite.com/2021/05/05/pulsar-ack/</id>
    <published>2021-05-04T16:00:00.000Z</published>
    <updated>2021-05-05T07:20:32.858Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 消息确认（ACK）</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>由于分布式系统的特性，当使用分布式消息系统时，可能会发生故障。比如在消费者从消息系统中的主题消费消息的过程中，消费消息的消费者和服务于主题分区的消息代理（Broker）都可能发生错误。消息确认（ACK）的目的就是保证当发生这样的故障后，消费者能够从上一次停止的地方恢复消费，保证既不会丢失消息，也不会重复处理已经确认（ACK）的消息。</p><p>在Apache Kafka中，恢复点通常称为Offset，更新恢复点的过程称为消息确认或提交Offset。</p><p>在Apache Pulsar中，每个订阅中都使用一个专门的数据结构–游标（Cursor）来跟踪订阅中的每条消息的确认（ACK）状态。每当消费者在主题分区上确认消息时，游标都会更新。更新游标可确保消费者不会再次收到消息。</p><h4 id="消息确认"><a href="#消息确认" class="headerlink" title="消息确认"></a>消息确认</h4><p>Pulsar 提供两种消息确认方法：</p><ul><li>单条确认（Individual Ack）: 单独确认一条消息。 被确认后的消息将不会被重新传递</li><li>累积确认（Cumulative Ack）: 通过累积确认，消费者只需要确认它收到的最后一条消息</li></ul><p>下图说明了单条确认和累积确认的差异（灰色框中的消息被确认并且不会被重新传递）。对于累计确认，M12 之前的消息被标记为 Acked。对于单独进行 ACK，仅确认消息 M7 和 M12， 在消费者失败的情况下，除了 M7 和 M12 之外，其他所有消息将被重新传送。</p><p><img src="/images/blog/2021-05-05-1.png" alt></p><p>Apache Pulsar可以支持消息的单条确认，也就是选择性确认。消费者可以单独确认一条消息。 被确认后的消息将不会被重新传递。</p><p>累积确认，消费者只需要确认它收到的最后一条消息。主题分区中的所有消息（包括）提供消息ID将被标记为已确认，并且不会再次传递给消费者。累积确认与Apache Kafka中的Offset更新类似。</p><h4 id="消费模式支持"><a href="#消费模式支持" class="headerlink" title="消费模式支持"></a>消费模式支持</h4><p>独占订阅或灾备订阅的消费者能够对消息进行单条确认和累积确认；共享订阅的消费者只允许对消息进行单条确认。</p><p>管理Ack的专门的数据结构–游标（Cursor），由Broker来管理，利用BookKeeper的Ledger提供存储</p><hr><p>参考链接</p><ul><li><a href="https://mp.weixin.qq.com/s/XJ3vj9xeDpdqZr-um8wBug" target="_blank" rel="noopener">Pulsar VS. Kafka（1）: 统一的消息消费模型（Queue + Stream）</a></li></ul>]]></content>
    
    <summary type="html">
    
      Pulsar 消息确认（ACK）
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>Pulsar 术语</title>
    <link href="http://yoursite.com/2021/05/04/pulsar-terminology/"/>
    <id>http://yoursite.com/2021/05/04/pulsar-terminology/</id>
    <published>2021-05-03T16:00:00.000Z</published>
    <updated>2021-05-05T07:11:46.231Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 相关的一些术语</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>该文摘自Apache Pulsar 官方文档<a href="https://pulsar.apache.org/docs/zh-CN/reference-terminology/" target="_blank" rel="noopener">Apache Pulsar Terminology</a></p><p>下面是 Apache Pulsar 相关的一些术语</p><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><h5 id="Pulsar"><a href="#Pulsar" class="headerlink" title="Pulsar"></a>Pulsar</h5><p>Pulsar 是一个分布式消息系统，最初由 Yahoo 创建，现在是 Apache 软件基金会的一个孵化器项目。</p><h5 id="消息（Message）"><a href="#消息（Message）" class="headerlink" title="消息（Message）"></a>消息（Message）</h5><p>消息是Pulsar的基本单位。它是生产者发布到主题的内容，然后是消费者从主题中消费的内容。</p><h5 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h5><p>Topic 接收 producer 发布的消息后，将消息传递给 consumer，由 consumer 消费这些消息。</p><h5 id="分区-Topic（Partitioned-Topic）"><a href="#分区-Topic（Partitioned-Topic）" class="headerlink" title="分区 Topic（Partitioned Topic）"></a>分区 Topic（Partitioned Topic）</h5><p>由多个 Pulsar broker 处理分区 topic，提高吞吐量。</p><h5 id="命名空间（Namespace）"><a href="#命名空间（Namespace）" class="headerlink" title="命名空间（Namespace）"></a>命名空间（Namespace）</h5><p>相关 topic 间的分组机制。</p><h5 id="命名空间-Bundle（Namespace-Bundle）"><a href="#命名空间-Bundle（Namespace-Bundle）" class="headerlink" title="命名空间 Bundle（Namespace Bundle）"></a>命名空间 Bundle（Namespace Bundle）</h5><p>同一个命名空间下的虚拟 topic 组。 命名空间 bundle 是 32 位的哈希值，取值范围从 0x00000000 到 0xffffffff。</p><h5 id="租户（Tenant）"><a href="#租户（Tenant）" class="headerlink" title="租户（Tenant）"></a>租户（Tenant）</h5><p>用于分配容量和执行身份验证/授权方案的管理单元。</p><h5 id="订阅（Subscription）"><a href="#订阅（Subscription）" class="headerlink" title="订阅（Subscription）"></a>订阅（Subscription）</h5><p>由一组消费者建立关于Topic的租约。 Pulsar具有四种订阅模式（独占，共享，故障转移和key_shared）。</p><h5 id="发布-订阅（Pub-Sub）"><a href="#发布-订阅（Pub-Sub）" class="headerlink" title="发布 - 订阅（Pub-Sub）"></a>发布 - 订阅（Pub-Sub）</h5><p>一种消息传递模式，即 producer 进程发布消息到 topic，consumer 进程消费（处理）这些消息。</p><h5 id="生产者（Producer）"><a href="#生产者（Producer）" class="headerlink" title="生产者（Producer）"></a>生产者（Producer）</h5><p>发送消息到 Pulsar topic 的进程。</p><h5 id="消费者（Consumer）"><a href="#消费者（Consumer）" class="headerlink" title="消费者（Consumer）"></a>消费者（Consumer）</h5><p>订阅 Pulsar topic 并处理消息（由 producer 发布到该 topic）的进程。</p><h5 id="Reader"><a href="#Reader" class="headerlink" title="Reader"></a>Reader</h5><p>消息处理程序，与 Pulsar consumer 非常相似。二者之间有两个主要区别:</p><ul><li>Reader可以指定读在主题上从何处开始处理消息（消费者总是以最新的可用未确认消息开始）</li><li>Reader 不保留数据，也不确认消息。</li></ul><blockquote><p>由于Pulsar主题分区实际上是存储在Apache BookKeeper中，它还提供了一个读取API（Reader），类似于消费者API（但Reader没有游标管理），以便用户完全控制如何使用Topic中的消息。</p></blockquote><h5 id="游标（Cursor）"><a href="#游标（Cursor）" class="headerlink" title="游标（Cursor）"></a>游标（Cursor）</h5><p>Consumer 订阅分区的位置。</p><h5 id="Ack（Acknowledgement）"><a href="#Ack（Acknowledgement）" class="headerlink" title="Ack（Acknowledgement）"></a>Ack（Acknowledgement）</h5><p>Consumer 发送 ack 到 Pulsar broker，表明消息处理成功。 Pulsar 通过 Ack 确认是否可以将消息从系统中删除。如果没有收到 Ack，则一直保留消息到处理完成。</p><h5 id="Nack（Negative-Acknowledgment）"><a href="#Nack（Negative-Acknowledgment）" class="headerlink" title="Nack（Negative Acknowledgment）"></a>Nack（Negative Acknowledgment）</h5><p>当应用程序无法处理特定消息时，应用程序向 Pulsar 发送 Nack，表示可以在一段时间后重新消费此消息。 （默认情况下，延迟1分钟后会重播失败的消息）</p><p>请注意，对独占、灾备、key共享的订阅类型的否定确认可能会导致失败的消息以非原始顺序到达使用者。</p><h5 id="未确认（Unacknowledged）"><a href="#未确认（Unacknowledged）" class="headerlink" title="未确认（Unacknowledged）"></a>未确认（Unacknowledged）</h5><p>已传递给使用者以进行处理但尚未确认为已由使用者处理的消息。</p><h5 id="保留政策（Retention-Policy）"><a href="#保留政策（Retention-Policy）" class="headerlink" title="保留政策（Retention Policy）"></a>保留政策（Retention Policy）</h5><p>在命名空间级别，通过设置消息大小和消息保留时间，为消息（已被 Ack）设置保留策略。</p><h5 id="多租户（Multi-Tenancy）"><a href="#多租户（Multi-Tenancy）" class="headerlink" title="多租户（Multi-Tenancy）"></a>多租户（Multi-Tenancy）</h5><p>能够隔离名称空间，指定配额以及按租户配置身份验证和授权的功能。</p><h4 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h4><h5 id="单机版（Standalone）"><a href="#单机版（Standalone）" class="headerlink" title="单机版（Standalone）"></a>单机版（Standalone）</h5><p>轻量级的Pulsar代理，其中所有组件都在单个Java虚拟机（JVM）进程中运行。独立群集可以在单台计算机上运行，​​并且对于开发目的很有用。</p><h5 id="集群（Cluster）"><a href="#集群（Cluster）" class="headerlink" title="集群（Cluster）"></a>集群（Cluster）</h5><p>一组Pulsar代理和BookKeeper服务器（又称bookies）。集群可以驻留在不同的地理区域中，并且可以在称为地理复制的过程中将消息彼此复制。</p><h5 id="实例（Instance）"><a href="#实例（Instance）" class="headerlink" title="实例（Instance）"></a>实例（Instance）</h5><p>一组Pulsar集群，这多个集群一起作为一个单元起作用。</p><h5 id="地理复制（Geo-Replication）"><a href="#地理复制（Geo-Replication）" class="headerlink" title="地理复制（Geo-Replication）"></a>地理复制（Geo-Replication）</h5><p>在Pulsar群集之间（可能在不同的数据中心或地理区域中）复制消息。</p><h5 id="Configuration-Store"><a href="#Configuration-Store" class="headerlink" title="Configuration Store"></a>Configuration Store</h5><p>Pulsar的配置存储（以前称为配置存储）是ZooKeeper仲裁，用于特定于配置的任务。多集群的Pulsar安装仅需要跨所有集群的一个配置存储。</p><h5 id="Topic-Lookup"><a href="#Topic-Lookup" class="headerlink" title="Topic Lookup"></a>Topic Lookup</h5><p>由Pulsar代理提供的一项服务，使连接客户端可以自动确定哪个Pulsar集群负责某个主题（从而确定该主题的消息通信需要路由到何处）。</p><h5 id="服务发现（Service-Discovery）"><a href="#服务发现（Service-Discovery）" class="headerlink" title="服务发现（Service Discovery）"></a>服务发现（Service Discovery）</h5><p>Pulsar提供的一种机制，使连接客户端可以仅使用单个URL与集群中的所有代理进行交互。</p><h5 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h5><p>Pulsar群集的无状态组件，该组件运行其他两个组件</p><ul><li>公开用于管理和主题查找的REST接口的HTTP服务器</li><li>处理所有消息传输的调度程序</li></ul><p>Pulsar集群由多个broker组成</p><h5 id="Dispatcher"><a href="#Dispatcher" class="headerlink" title="Dispatcher"></a>Dispatcher</h5><p>用于进出Pulsar代理的所有数据传输的异步TCP服务器。脉冲星调度程序对所有通信使用自定义二进制协议。</p><h4 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h4><h5 id="BookKeeper"><a href="#BookKeeper" class="headerlink" title="BookKeeper"></a>BookKeeper</h5><p>Apache BookKeeper是一种可扩展的，低延迟的持久日志存储服务，Pulsar用于存储数据。</p><h5 id="Bookie"><a href="#Bookie" class="headerlink" title="Bookie"></a>Bookie</h5><p>Bookie是单个BookKeeper服务器的名称。它实际上是Pulsar的存储服务器。</p><h5 id="Ledger"><a href="#Ledger" class="headerlink" title="Ledger"></a>Ledger</h5><p>BookKeeper中的仅追加数据结构，用于将消息持久存储在Pulsar主题中。</p><h4 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h4><p>Pulsar函数是轻量级函数，可以使用来自Pulsar主题的消息，应用自定义处理逻辑，并在需要时将结果发布到主题。</p><hr><p>参考链接</p><ul><li><a href="https://pulsar.apache.org/docs/zh-CN/reference-terminology/" target="_blank" rel="noopener">Apache Pulsar Terminology</a></li></ul>]]></content>
    
    <summary type="html">
    
      Apache Pulsar 相关的一些术语
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>Pulsar 消息订阅</title>
    <link href="http://yoursite.com/2021/05/03/pulsar-news-subscription/"/>
    <id>http://yoursite.com/2021/05/03/pulsar-news-subscription/</id>
    <published>2021-05-02T16:00:00.000Z</published>
    <updated>2021-05-04T14:53:15.587Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 消息订阅</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>该文摘自Apache Pulsar 官方文档<a href="https://pulsar.apache.org/docs/zh-CN/concepts-messaging/#%E8%AE%A2%E9%98%85" target="_blank" rel="noopener">Apache Pulsar Messaging#订阅</a></p><p>当有有数据进入到Pulsar后，需要将数据消费出来，这里就涉及订阅</p><p>订阅是命名好的配置规则，指导消息如何投递给消费者。</p><h4 id="消息订阅"><a href="#消息订阅" class="headerlink" title="消息订阅"></a>消息订阅</h4><p>Pulsar 中有四种订阅模式: 独占(Exclusive)，共享(Share)，灾备(Failover)和key共享(Key_Shared)</p><p><img src="/images/blog/2021-05-03-1.png" alt></p><h5 id="独占-Exclusive"><a href="#独占-Exclusive" class="headerlink" title="独占(Exclusive)"></a>独占(Exclusive)</h5><p><strong>Exclusive模式为默认订阅模式</strong></p><p>在独占模式下，仅允许单个使用者附加到订阅。如果多个使用者使用相同的订阅来订阅主题，则会发生错误。</p><p>在下图中，仅允许消费者A-0消费消息</p><p><img src="/images/blog/2021-05-03-2.png" alt></p><h5 id="灾备-Failover"><a href="#灾备-Failover" class="headerlink" title="灾备(Failover)"></a>灾备(Failover)</h5><p>在灾备模式下，多个消费者（Consumer）可以附加到同一订阅，主消费者会消费非分区主题或者分区主题中的每个分区的消息。当主消费者断开连接时，分区将被重新分配给其中一个故障转移消费者，而新分配的消费者将成为新的主消费者。 发生这种情况时，所有未确认（ack）的消息都将传递给新的主消费者。</p><p>对于分区主题来说，Broker 将按照消费者的优先级和消费者名称的词汇表顺序对消费者进行排序。 然后试图将主题均匀的分配给优先级最高的消费者。</p><p>对于非分区主题来说，Broker 会根据消费者订阅非分区主题的顺序选择消费者。</p><p>在下图中，消费者B-0是主要消费者，如果消费者B-0断开连接，则消费者B-1将是排队接收消息的下一个消费者。</p><p><img src="/images/blog/2021-05-03-3.png" alt></p><h5 id="共享-Share"><a href="#共享-Share" class="headerlink" title="共享(Share)"></a>共享(Share)</h5><p>在共享模式下，多个消费者者可以附加到同一订阅，消息通过round robin（轮询机制）分发给不同的消费者，并且每个消息仅会被分发给一个消费者。</p><p>当消费者断开连接，所有被发送给它，但没有来得及确认（ack）的消息将被重新安排，分发给其它存活的消费者。</p><p>在下图中，Consumer-C-1和Consumer-C-2可以订阅该主题，但是Consumer-C-3和其他消费者也可以订阅该主题。</p><p><img src="/images/blog/2021-05-03-4.png" alt></p><blockquote><p>共享模式的局限性: 使用共享模式时，不保证消息顺序。不能在共享模式下使用累积确认(Cumulative Ack)。</p></blockquote><h5 id="key共享-Key-Shared"><a href="#key共享-Key-Shared" class="headerlink" title="key共享(Key_Shared)"></a>key共享(Key_Shared)</h5><p>key共享模式是共享模式的一种，不同的是它按key对消息做投递，相同的key的消息会被投递到同一个消费者上</p><p><img src="/images/blog/2021-05-03-5.png" alt></p><blockquote><p>Key_Shared模式的局限性: 使用Key_Shared模式时，需要为消息指定密钥或orderingKey。 不能在Key_Shared模式下使用累积确认(Cumulative Ack)。 生产者应禁用批处理或使用基于密钥的批处理生成器。</p></blockquote><p>可以在 broker.config 中禁用 Key_Shared 模式</p><h4 id="多主题订阅"><a href="#多主题订阅" class="headerlink" title="多主题订阅"></a>多主题订阅</h4><p>当consumer订阅pulsar的主题时，默认指定订阅了一个主题，例如：<code>persistent://public/default/my-topic</code></p><p>从Pulsar的1.23.0-incubating的版本开始，Pulsar消费者可以同时订阅多个topic。</p><p>可以用以下两种方式定义topic的列表</p><ul><li>基于正则表达式（regex），例如<code>persistent://public/default/finance-.*</code></li><li>通过明确指定的topic列表</li></ul><blockquote><p>当使用正则匹配订阅多个主题的时候，所有的主题必须是在同一个命名空间里面的</p></blockquote><p>当订阅多个主题的时候，Pulsar客户端将自动调用Pulsar API找到符合匹配规则的主题列表，然后订阅这些主题。 如果此时有暂不存在的主题，那么一旦这些主题被创建，消费者会自动订阅这些主题。</p><p>如下是 Java 订阅多个主题的代码示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import java.util.regex.Pattern;</span><br><span class="line"></span><br><span class="line">import org.apache.pulsar.client.api.Consumer;</span><br><span class="line">import org.apache.pulsar.client.api.PulsarClient;</span><br><span class="line"></span><br><span class="line">PulsarClient pulsarClient &#x3D; &#x2F;&#x2F; Instantiate Pulsar client object</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Subscribe to all topics in a namespace</span><br><span class="line">Pattern allTopicsInNamespace &#x3D; Pattern.compile(&quot;persistent:&#x2F;&#x2F;public&#x2F;default&#x2F;.*&quot;);</span><br><span class="line">Consumer&lt;byte[]&gt; allTopicsConsumer &#x3D; pulsarClient.newConsumer()</span><br><span class="line">                .topicsPattern(allTopicsInNamespace)</span><br><span class="line">                .subscriptionName(&quot;subscription-1&quot;)</span><br><span class="line">                .subscribe();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Subscribe to a subsets of topics in a namespace, based on regex</span><br><span class="line">Pattern someTopicsInNamespace &#x3D; Pattern.compile(&quot;persistent:&#x2F;&#x2F;public&#x2F;default&#x2F;foo.*&quot;);</span><br><span class="line">Consumer&lt;byte[]&gt; someTopicsConsumer &#x3D; pulsarClient.newConsumer()</span><br><span class="line">                .topicsPattern(someTopicsInNamespace)</span><br><span class="line">                .subscriptionName(&quot;subscription-1&quot;)</span><br><span class="line">                .subscribe();</span><br></pre></td></tr></table></figure><p>关于代码示例，请参阅 <a href="https://pulsar.apache.org/docs/zh-CN/client-libraries-java/#multi-topic-subscriptions" target="_blank" rel="noopener">Java</a></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Pulsar中的订阅实际上与Apache Kafka中的Consumer Group的概念类似。</p><p>独占(Exclusive): 在任何时间，一个消费者组（订阅）中有且只有一个消费者来消费 Topic 中的消息。<br>灾备(Failover): 多个消费者（Consumer）可以附加到同一订阅。 但是，一个订阅中的所有消费者，只会有一个消费者被选为该订阅的主消费者。 其他消费者将被指定为故障转移消费者。 当主消费者断开连接时，分区将被重新分配给其中一个故障转移消费者，而新分配的消费者将成为新的主消费者。 发生这种情况时，所有未确认（ack）的消息都将传递给新的主消费者。<br>共享(Share): 使用共享订阅，在同一个订阅背后，用户按照应用的需求挂载任意多的消费者。 订阅中的所有消息以循环分发形式发送给订阅背后的多个消费者，并且一个消息仅传递给一个消费者。当消费者断开连接时，所有传递给它但是未被确认（ack）的消息将被重新分配和组织，以便发送给该订阅上剩余的剩余消费者。</p><p>独占订阅或灾备订阅的消费者能够对消息进行单条确认和累积确认；共享订阅的消费者只允许对消息进行单条确认。</p><hr><p>参考链接</p><ul><li><a href="https://pulsar.apache.org/docs/zh-CN/concepts-messaging/#%E8%AE%A2%E9%98%85" target="_blank" rel="noopener">Apache Pulsar Messaging#订阅</a></li><li><a href="https://mp.weixin.qq.com/s/XJ3vj9xeDpdqZr-um8wBug" target="_blank" rel="noopener">Pulsar VS. Kafka（1）: 统一的消息消费模型（Queue + Stream）</a></li></ul>]]></content>
    
    <summary type="html">
    
      Apache Pulsar 消息订阅
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>Pulsar 总览</title>
    <link href="http://yoursite.com/2021/05/02/pulsar-overview/"/>
    <id>http://yoursite.com/2021/05/02/pulsar-overview/</id>
    <published>2021-05-01T16:00:00.000Z</published>
    <updated>2021-05-04T14:53:15.595Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Pulsar 架构与核心概念</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p><a href="https://pulsar.apache.org" target="_blank" rel="noopener">Apache Pulsar</a> 是 Apache 软件基金会顶级项目，是下一代云原生分布式消息流平台，集消息、存储、轻量化函数式计算为一体，采用计算与存储分离架构设计，支持多租户、持久化存储、多机房跨区域数据复制，具有强一致性、高吞吐、低延时及高可扩展性等流数据存储特性。</p><h4 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h4><p>Apache Pulsar 是 Pub/Sub 模型的消息系统，并且从设计上做了存储和计算的分离</p><h5 id="存储计算分离"><a href="#存储计算分离" class="headerlink" title="存储计算分离"></a>存储计算分离</h5><p>Pulsar 集群由以下三部分组成</p><ul><li>Broker: 无状态服务层，负责接收和传递消息，集群负载均衡等工作，Broker 不会持久化保存元数据，因此可以快速的上、下线</li><li>Apache BookKeeper: 有状态持久层，由一组名为 Bookie 的存储节点组成，持久化地存储消息</li><li>Apache Zookeeper: 进行元数据存储，集群配置和协调</li></ul><p><img src="/images/blog/2021-05-02-2.png" alt></p><p>与传统的消息系统相比，Apache Pulsar 在架构设计上采用了计算与存储分离的模式，Pub/Sub 相关的计算逻辑在 Broker 上完成，数据存储在 Apache BookKeeper 的 Bookie 节点上。</p><h5 id="分片存储"><a href="#分片存储" class="headerlink" title="分片存储"></a>分片存储</h5><p><img src="/images/blog/2021-05-02-1.png" alt></p><h4 id="消息的存储与过期"><a href="#消息的存储与过期" class="headerlink" title="消息的存储与过期"></a>消息的存储与过期</h4><h4 id="消息去重"><a href="#消息去重" class="headerlink" title="消息去重"></a>消息去重</h4><h4 id="消息存储"><a href="#消息存储" class="headerlink" title="消息存储"></a>消息存储</h4><hr><p>参考链接</p><ul><li><a href="https://zhuanlan.zhihu.com/p/88618994" target="_blank" rel="noopener">新一代MQ apache pulsar的架构与核心概念</a></li></ul>]]></content>
    
    <summary type="html">
    
      Apache Pulsar 架构与核心概念
    
    </summary>
    
    
      <category term="Pulsar" scheme="http://yoursite.com/categories/Pulsar/"/>
    
    
  </entry>
  
  <entry>
    <title>kafkactl</title>
    <link href="http://yoursite.com/2021/04/26/kafkactl/"/>
    <id>http://yoursite.com/2021/04/26/kafkactl/</id>
    <published>2021-04-25T16:00:00.000Z</published>
    <updated>2021-04-26T15:44:27.056Z</updated>
    
    <content type="html"><![CDATA[<p>与Kafka交互的命令行工具</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>平常使用kafka的命令行感觉不是很方便，每次都要找地址和打很长的命令。</p><p>调研发现kafkactl可以满足需求。简单明了，解压就可以用，不用装JDK</p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>kafkactl 是一个与Apache Kafka交互的命令行工具</p><p>github地址：<a href="https://github.com/deviceinsight/kafkactl" target="_blank" rel="noopener">https://github.com/deviceinsight/kafkactl</a></p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>在releases下载最新的二进制包解压即可用</p><p>在用户的家目录下创建配置文件 <code>.config/kafkactl/config.yml</code></p><p>在配置文件里配置好要kafka集群地址信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">contexts:</span><br><span class="line">  default:</span><br><span class="line">    brokers:</span><br><span class="line">    - localhost:9092</span><br><span class="line">  remote-cluster:</span><br><span class="line">    brokers:</span><br><span class="line">    - remote-cluster001:9092</span><br><span class="line">    - remote-cluster002:9092</span><br><span class="line">    - remote-cluster003:9092</span><br><span class="line">    </span><br><span class="line">current-context: default</span><br></pre></td></tr></table></figure><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>直接输入kafkactl可以查看帮助，感兴趣的可以看下视频学习 <a href="https://asciinema.org/a/vmxrTA0h8CAXPnJnSFk5uHKzr" target="_blank" rel="noopener">https://asciinema.org/a/vmxrTA0h8CAXPnJnSFk5uHKzr</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ kafkactl</span><br><span class="line">A command-line interface the simplifies interaction with Kafka.</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  kafkactl [command]</span><br><span class="line"></span><br><span class="line">Available Commands:</span><br><span class="line">  alter       alter topics, partitions</span><br><span class="line">  attach      run kafkactl pod in kubernetes and attach to it</span><br><span class="line">  completion  </span><br><span class="line">  config      show and edit configurations</span><br><span class="line">  consume     consume messages from a topic</span><br><span class="line">  create      create topics, consumerGroups, acls</span><br><span class="line">  delete      delete topics, acls</span><br><span class="line">  describe    describe topics, consumerGroups</span><br><span class="line">  get         get info about topics, consumerGroups, acls</span><br><span class="line">  help        Help about any command</span><br><span class="line">  produce     produce messages to a topic</span><br><span class="line">  reset       reset consumerGroupsOffset</span><br><span class="line">  version     print the version of kafkactl</span><br><span class="line"></span><br><span class="line">Flags:</span><br><span class="line">  -C, --config-file string   config file. one of: [$HOME&#x2F;.config&#x2F;kafkactl $HOME&#x2F;.kafkactl $SNAP_REAL_HOME&#x2F;.config&#x2F;kafkactl $SNAP_DATA&#x2F;kafkactl &#x2F;etc&#x2F;kafkactl]</span><br><span class="line">  -h, --help                 help for kafkactl</span><br><span class="line">  -V, --verbose              verbose output</span><br><span class="line"></span><br><span class="line">Use &quot;kafkactl [command] --help&quot; for more information about a command.</span><br></pre></td></tr></table></figure><h5 id="选择要访问的集群"><a href="#选择要访问的集群" class="headerlink" title="选择要访问的集群"></a>选择要访问的集群</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kafkactl config get-contexts</span><br><span class="line">ACTIVE     NAME</span><br><span class="line">           remote-cluster</span><br><span class="line">*          default</span><br><span class="line"></span><br><span class="line">$ kafkactl config use-context remote-cluster</span><br><span class="line">$ kafkactl config current-context</span><br><span class="line">remote-cluster</span><br></pre></td></tr></table></figure><h5 id="获取主题和消费者组"><a href="#获取主题和消费者组" class="headerlink" title="获取主题和消费者组"></a>获取主题和消费者组</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafkactl get topics</span><br><span class="line">kafkactl get consumer-groups</span><br></pre></td></tr></table></figure><h5 id="查看主题和消费者组详情"><a href="#查看主题和消费者组详情" class="headerlink" title="查看主题和消费者组详情"></a>查看主题和消费者组详情</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafkactl describe topic xxx</span><br><span class="line">kafkactl describe consumer-group  xxx</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>挺好用的工具，不需要安装jdk，解压就可以使用。</p><p>输出所有消费组的功能挺好的，在集群裁撤时可以一下子查出所有的对应关系</p><hr><p>参考链接</p><ul><li><a href="https://github.com/deviceinsight/kafkactl" target="_blank" rel="noopener">kafkactl</a></li></ul>]]></content>
    
    <summary type="html">
    
      与Kafka交互的命令行工具
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka的一些问题</title>
    <link href="http://yoursite.com/2021/04/15/kafka-difficulty/"/>
    <id>http://yoursite.com/2021/04/15/kafka-difficulty/</id>
    <published>2021-04-14T16:00:00.000Z</published>
    <updated>2021-04-14T19:36:32.545Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的一些问题</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>读自vivo 互联网技术的文章–<a href="https://juejin.cn/post/6844903919424913415#heading-9" target="_blank" rel="noopener">《Kafka 原理和实战》</a> 整理</p><h4 id="问题点"><a href="#问题点" class="headerlink" title="问题点"></a>问题点</h4><h5 id="单分区有序"><a href="#单分区有序" class="headerlink" title="单分区有序"></a>单分区有序</h5><p>只保证单个主题单个分区内的消息有序，但是不能保证单个主题所有分区消息有序。如果应用严格要求消息有序，那么kafka可能不大合适</p><h5 id="消费偏移量维护"><a href="#消费偏移量维护" class="headerlink" title="消费偏移量维护"></a>消费偏移量维护</h5><p>消费偏移量由消费者跟踪和提交，但是消费者并不会经常把这个偏移量写会kafka，因为broker维护这些更新的代价很大，这会导致异常情况下消息可能会被多次消费或者没有消费。</p><p>具体分析如下：消息可能已经被消费了，但是消费者还没有像broker提交偏移量(commit offset)确认该消息已经被消费就挂掉了，接着另一个消费者又开始处理同一个分区，那么它会从上一个已提交偏移量开始，导致有些消息被重复消费。但是反过来，如果消费者在批处理消息之前就先提交偏移量，但是在处理消息的时候挂掉了，那么这部分消息就相当于『丢失』了。通常来说，处理消息和提交偏移量很难构成一个原子性操作，因此无法总是保证所有消息都刚好只被处理一次。</p><h5 id="主题和分区的数目有限"><a href="#主题和分区的数目有限" class="headerlink" title="主题和分区的数目有限"></a>主题和分区的数目有限</h5><p>Kafka集群能够处理的主题数目是有限的，达到1000个主题左右时，性能就开始下降。这些问题基本上都跟Kafka的基本实现决策有关。特别是，随着主题数目增加，broker上的随机IO量急剧增加，因为每个主题分区的写操作实际上都是一个单独的文件追加(append)操作。随着分区数目增加，问题越来越严重。如果Kafka不接管IO调度，问题就很难解决。</p><h5 id="磁盘大小"><a href="#磁盘大小" class="headerlink" title="磁盘大小"></a>磁盘大小</h5><p>单个节点必须有足够的磁盘空间来处理副本，因此非常大的副本可能会迫使你是用非常大的磁盘，磁盘的冗余需要评估和衡量</p><h5 id="手动均衡分区负载"><a href="#手动均衡分区负载" class="headerlink" title="手动均衡分区负载"></a>手动均衡分区负载</h5><p>在集群扩展时必须做Rebalance。这个过程是比较痛苦的，需要良好的计划和执行来保证没有任何故障的情况下分散节点的存储压力</p><h5 id="follow副本-replica-只充当冷备（解决HA问题），无法提供读服务"><a href="#follow副本-replica-只充当冷备（解决HA问题），无法提供读服务" class="headerlink" title="follow副本(replica)只充当冷备（解决HA问题），无法提供读服务"></a>follow副本(replica)只充当冷备（解决HA问题），无法提供读服务</h5><p>kafka因为读服务是有状态的（要维护commited offset），所以follow副本并没有参与到读写服务中。只是作为一个冷备，解决单点问题。</p><h5 id="顺序消费"><a href="#顺序消费" class="headerlink" title="顺序消费"></a>顺序消费</h5><p>只能顺序消费消息，不能随机定位消息，出问题的时候不方便快速定位问题</p><p>这其实是所有以消息系统作为异步RPC的通用问题。假设发送方发了一条消息，但是消费者说我没有收到，那么怎么排查呢？消息队列缺少随机访问消息的机制，如根据消息的key获取消息。</p><p>这导致排查这种问题不大容易。</p><hr><p>参考链接</p><ul><li><a href="https://juejin.cn/post/6844903919424913415#heading-9" target="_blank" rel="noopener">Kafka 原理和实战</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka的一些问题
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>零拷贝</title>
    <link href="http://yoursite.com/2021/04/07/zore-copy/"/>
    <id>http://yoursite.com/2021/04/07/zore-copy/</id>
    <published>2021-04-06T16:00:00.000Z</published>
    <updated>2021-04-07T06:55:04.841Z</updated>
    
    <content type="html"><![CDATA[<p>零拷贝是指计算机在网络上发送文件时，不需要将文件内容拷贝到用户空间（User Space）而直接在内核空间（Kernel Space）中传输到网络的方式</p><hr><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>阅读艾小仙的<a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA" target="_blank" rel="noopener">阿里二面：什么是mmap？</a> ，挺通俗易懂的，把之前学的零拷贝在回顾了下</p><h4 id="传统I-O"><a href="#传统I-O" class="headerlink" title="传统I/O"></a>传统I/O</h4><p>首先要对传统的IO方式有一个概念</p><p>基于传统的IO方式，底层实际上通过调用read()和write()来实现</p><p>通过read()把数据从硬盘读取到内核缓冲区，再复制到用户缓冲区；然后再通过write()写入到socket缓冲区，最后写入网卡设备。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read(file,tmp_buf,len)</span><br><span class="line">write(socket,tmp_buf,len)</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-1.png" alt></p><p>从磁盘文件读取并且通过socket写出的过程发生了4次用户态和内核态的上下文切换和4次拷贝</p><ol><li>用户进程通过read()方法向操作系统发起调用，此时上下文从用户态切换为内核态</li><li>DMA控制器把数据从硬盘中拷贝到读缓冲区</li><li>CPU把读缓冲区数据拷贝到应用缓冲区，上下文从内核态切换为用户态，read()返回</li><li>用户进程通过write()方法发起调用，上下文从用户态切换为内核态</li><li>CPU把用户缓冲区的数据拷贝到socket缓冲区</li><li>DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，write()返回</li></ol><blockquote><p>用户态、内核态指的是什么？上下文切换又是什么？</p><p>简单来说，用户空间指的就是用户进程的运行空间，内核空间就是内核的运行空间。</p><p>如果进程运行在内核空间就是内核态，运行在用户空间就是用户态。</p><p>为了安全起见，他们之间是互相隔离的，而在用户态和内核态之间的上下文切换也是比较耗时的。</p></blockquote><blockquote><p>什么又是DMA拷贝呢？</p><p>因为对于一个IO操作而言，都是通过CPU发出对应的指令来完成，但是相比CPU来说，IO的速度太慢了，CPU有大量的时间处于等待IO的状态。</p><p>因此就产生了DMA（Direct Memory Access）直接内存访问技术，本质上来说他就是一块主板上独立的芯片，通过它来进行内存和IO设备的数据传输，从而减少CPU的等待时间。</p></blockquote><h4 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h4><p>接下来有针对性的来谈谈几种常见的零拷贝技术</p><h5 id="mmap-write"><a href="#mmap-write" class="headerlink" title="mmap+write"></a>mmap+write</h5><p>简单来说就是使用mmap替换了read+write中的read操作，减少了一次CPU的拷贝。</p><p>mmap主要实现方式是将读缓冲区的地址和用户缓冲区的地址进行映射，内核缓冲区和应用缓冲区共享，从而减少了从读缓冲区到用户缓冲区的一次CPU拷贝。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp_buf &#x3D; mmap(file, len);</span><br><span class="line">write(socket, tmp_buf, len);</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-2.png" alt></p><p>整个过程发生了4次用户态和内核态的上下文切换和3次拷贝</p><ol><li>用户进程通过mmap()方法向操作系统发起调用，上下文从用户态转向内核态</li></ol><h5 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h5><p>相比mmap来说，sendfile同样减少了一次CPU拷贝，而且还减少了2次上下文切换。</p><p>sendfile是Linux2.1内核版本后引入的一个系统调用函数，通过使用sendfile数据可以直接在内核空间进行传输，因此避免了用户空间和内核空间的拷贝，同时由于使用sendfile替代了read+write从而节省了一次系统调用，也就是2次上下文切换。</p><p><img src="/images/blog/2021-04-05-3.png" alt></p><p>整个过程发生了2次用户态和内核态的上下文切换和3次拷贝，具体流程如下：</p><ol><li>用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态切换为内核态</li><li>DMA控制器把数据从硬盘中拷贝到读缓冲区</li><li>CPU将读缓冲区中数据拷贝到socket缓冲区</li><li>DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换为用户态，sendfile调用返回</li></ol><p><strong>sendfile方法IO数据对用户空间完全不可见，所以只能适用于完全不需要用户空间处理的情况，比如静态文件服务器。</strong></p><h5 id="sendfile-DMA-Scatter-Gather"><a href="#sendfile-DMA-Scatter-Gather" class="headerlink" title="sendfile+DMA Scatter/Gather"></a>sendfile+DMA Scatter/Gather</h5><p>Linux2.4内核版本之后对sendfile做了进一步优化，通过引入新的硬件支持，这个方式叫做DMA Scatter/Gather 分散/收集功能。</p><p>将读缓冲区中的数据描述信息–内存地址和偏移量记录到socket缓冲区，由 DMA 根据这些将数据从读缓冲区拷贝到网卡，相比之前版本减少了一次CPU拷贝的过程</p><blockquote><p>之前是把读缓冲区的数据拷贝到socket缓存中，实际上，仅仅需要把读缓冲区描述符传到socket缓冲区，再把数据长度传过去，这样DMA控制器直接将页缓存中的数据打包发送到网络中就可以了。</p></blockquote><p>依旧是系统调用sendfile()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sendfile(socket, file, len);</span><br></pre></td></tr></table></figure><p><img src="/images/blog/2021-04-05-4.png" alt></p><ol><li>用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态转向内核态</li><li>DMA控制器利用scatter把数据从硬盘中拷贝到读缓冲区离散存储</li><li>CPU把读缓冲区中的文件描述符和数据长度发送到socket缓冲区</li><li>DMA控制器根据文件描述符和数据长度，使用scatter/gather把数据从内核缓冲区拷贝到网卡</li><li>sendfile()调用返回，上下文从内核态切换回用户态</li></ol><p>DMA gather和sendfile一样数据对用户空间不可见，而且需要硬件支持，同时输入文件描述符只能是文件，但是过程中完全没有CPU拷贝过程，极大提升了性能。</p><blockquote><p>这种模式实现起来需要硬件的支持，但对于基于操作系统的用户来讲，操作系统已经屏蔽了这种差异，它会根据不同的硬件平台来实现这个系统调用</p></blockquote><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>RocketMQ和Kafka都使用到了零拷贝的技术</p><p>对于MQ而言，无非就是生产者发送数据到MQ然后持久化到磁盘，之后消费者从MQ读取数据。</p><p>对于RocketMQ来说这两个步骤使用的是mmap+write，而Kafka则是使用mmap+write持久化数据，发送数据使用sendfile。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>由于CPU和IO速度的差异问题，产生了DMA技术，通过DMA搬运来减少CPU的等待时间。</p><p>传统的IO read+write方式会产生2次DMA拷贝+2次CPU拷贝，同时有4次上下文切换。</p><p>而通过mmap+write方式则产生2次DMA拷贝+1次CPU拷贝，4次上下文切换，通过内存映射减少了一次CPU拷贝，可以减少内存使用，适合大文件的传输。</p><p>sendfile方式是新增的一个系统调用函数，产生2次DMA拷贝+1次CPU拷贝，但是只有2次上下文切换。因为只有一次调用，减少了上下文的切换，但是用户空间对IO数据不可见，适用于静态文件服务器。</p><p>sendfile+DMA gather方式产生2次DMA拷贝，没有CPU拷贝，而且也只有2次上下文切换。虽然极大地提升了性能，但是需要依赖新的硬件设备支持。</p><hr><p>参考链接</p><ul><li><a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA" target="_blank" rel="noopener">阿里二面：什么是mmap？</a></li><li><a href="https://www.jianshu.com/p/497e7640b57c" target="_blank" rel="noopener">零拷贝的原理及Java实现</a></li></ul>]]></content>
    
    <summary type="html">
    
      零拷贝技术
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka topic leader 均衡</title>
    <link href="http://yoursite.com/2021/03/10/kafka-leader-reassign/"/>
    <id>http://yoursite.com/2021/03/10/kafka-leader-reassign/</id>
    <published>2021-03-09T16:00:00.000Z</published>
    <updated>2021-03-19T07:54:56.657Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka常见痛点及优化方案</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>在创建一个topic时，partition会在Broker集群上均分，每个partition的所有replicas叫做”assigned replicas”，”assigned replicas”中的第一个replicas叫”preferred replica”。</p><p>刚创建的topic一般”preferred replica”是leader。leader replica负责所有的读写。</p><p>随着时间推移，broker可能会停机，会导致leader迁移，导致机群的负载不均衡。需要对topic的leader进行重新负载均衡，让partition选择”preferred replica”做为leader。</p><p>简单来说：leader 均衡就是让topic 的分区leader 选择的是优先副本</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>先查看 topic 情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic logdata-es</span><br></pre></td></tr></table></figure><p>生成主题列表 json 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;partitions&quot;:</span><br><span class="line">  [</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 0&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 1&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 2&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 3&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 4&#125;,</span><br><span class="line">    &#123;&quot;topic&quot;: &quot;logdata-es&quot;, &quot;partition&quot;: 5&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行均衡</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-preferred-replica-election.sh --zookeeper 127.0.0.1:2181 --path-to-json-file logdata-es-autu.json</span><br></pre></td></tr></table></figure><p>再查看 topic 情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic logdata-es</span><br></pre></td></tr></table></figure><p>Kafka 有个参数可以控制优先副本选举，即<code>auto.leader.rebalance.enable</code>参数，可以使得Kafka集群自动平衡Leader，只需要在server.properties文件中配置如下设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">leader.imbalance.check.interval.seconds&#x3D;300 ,每个300秒检查leader的负载均衡情况</span><br><span class="line">leader.imbalance.per.broker.percentage&#x3D;10，不平衡性超过阈值就自动触发负载均衡</span><br><span class="line">auto.leader.rebalance.enable&#x3D;true ，默认是开启的</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Kafka是允许分区保持一定的不均衡的，单个topic的优先副本均衡，也并不能代表整个集群的优先副本均衡</p><p>对于手动执行优先副本选举，也建议采取分批次的方式进行，避免同时进行多个大数据量topic的优先副本选举。</p><hr><p>参考链接</p><ul><li><a href="https://sukbeta.github.io/kafka-auto-loadblance-leader/" target="_blank" rel="noopener">kafka对topic leader 进行自动负载均衡</a></li><li><a href="https://blog.csdn.net/data2tech/article/details/108730602" target="_blank" rel="noopener">Kafka优先副本选举</a></li><li><a href="https://blog.csdn.net/qq_29493353/article/details/88532089" target="_blank" rel="noopener">Kafka集群Leader均衡(Balancing leadership)</a></li><li><a href="https://cloud.tencent.com/developer/article/1496413" target="_blank" rel="noopener">Kafka集群平滑扩容及Leader均衡【实战笔记】</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 痛点及优化方案
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 分区策略</title>
    <link href="http://yoursite.com/2021/02/14/kafka-partition-strategy/"/>
    <id>http://yoursite.com/2021/02/14/kafka-partition-strategy/</id>
    <published>2021-02-13T16:00:00.000Z</published>
    <updated>2021-02-14T13:19:32.680Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 分区策略</p><hr><h4 id="生产者分区选择配策略"><a href="#生产者分区选择配策略" class="headerlink" title="生产者分区选择配策略"></a>生产者分区选择配策略</h4><p>生产者在将消息发送到某个Topic，需要经过拦截器、序列化器和分区器（Partitioner）的一系列作用之后才能发送到对应的Broker，在发往Broker之前是需要确定它所发往的分区。</p><p>生产端将消息发送给Broker之前，会将producer发送的数据封装成一个 ProducerRecord 对象。是否依赖分区器看partition字段有无指定。</p><p><img src="/images/blog/2021-02-14-1.png" alt></p><p>是否依赖分区器看partition字段有无指定</p><ul><li>如果消息 ProducerRecord 指定了 partition 字段，那么就不需要分区器。</li><li>如果消息 ProducerRecord 没有指定 partition 字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。</li></ul><p>Kafka 中提供的默认分区器是 <a href="https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/DefaultPartitioner.java" target="_blank" rel="noopener">DefaultPartitioner</a> ，它实现了Partitioner接口（用户可以实现这个接口来自定义分区器）</p><p>用户可以通过实现kafka.producer.Partitioner接口实现自己的分区类（重载并实现partition方法），在生产端添加配置<code>partitioner.class</code>即可使用</p><blockquote><ul><li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值。</li><li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值。</li><li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</li><li>既没有 partition 值又指定了自定义的分区类，则按自定义分区类来得到 partition 值</li></ul></blockquote><h4 id="消费者分区分配策略"><a href="#消费者分区分配策略" class="headerlink" title="消费者分区分配策略"></a>消费者分区分配策略</h4><p>消费者以组的名义订阅主题，主题有多个分区，消费者组中有多个消费者实例，<strong>同一时刻，一条消息只能被组中的一个消费者实例消费</strong></p><ul><li>如果分区数大于或者等于组中的消费者实例数，一个消费者会负责多个分区</li><li>如果分区数小于组中的消费者实例数，有些消费者将处于空闲状态并且无法接收消息</li></ul><blockquote><p>如果多个消费者负责同一个分区，那么就意味着两个消费者同时读取分区的消息，由于消费者自己可以控制读取消息的Offset，就有可能C1才读到2，而C1读到1，C1还没处理完，C2已经读到3了，这就相当于多线程读取同一个消息，会造成消息处理的重复，且不能保证消息的顺序。</p></blockquote><p>在 Kafka 中存在着两种分区分配策略，通过 partition.assignment.strategy 来设置。</p><ul><li>RangeAssignor 范围分区策略，也是默认模式。</li><li>RoundRobinAssignor 分配策略，轮询分区模式。</li></ul><h5 id="RangeAssignor"><a href="#RangeAssignor" class="headerlink" title="RangeAssignor"></a>RangeAssignor</h5><p>range （默认分配策略）对应的实现类是 org.apache.kafka.clients.consumer.RangeAssignor</p><ol><li>将分区按数字顺序排行序，消费者按名称的字典序排序</li><li>用分区总数除以消费者总数。如果能够除尽，平均分配；若除不尽，则位于排序前面的消费者将多负责一个分区</li></ol><p>假如现在有 10 个分区，3 个消费者，排序后的分区将会是p0~p9。消费者排序完之后将会是C1-0、C2-0、C3-0。通过 Partitions数 / Consumer数 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C1-0</td><td>消费 0、1、2、3分区</td></tr><tr><td>C2-0</td><td>消费 4、5、6分区</td></tr><tr><td>C3-0</td><td>消费 7、8、9分区</td></tr></tbody></table><blockquote><p>Range 范围分区的弊端: </p><p>如上只是针对 1 个 topic 而言，C1-0 消费者多消费1个分区影响不是很大。如果有 N 多个 topic，那么针对每个 topic，消费者 C1-0 都将多消费 1 个分区，topic越多，C1-0 消费的分区会比其他消费者明显多消费 N 个分区。这就是 Range 范围分区的一个很明显的弊端了.</p></blockquote><h5 id="RoundRobinAssignor"><a href="#RoundRobinAssignor" class="headerlink" title="RoundRobinAssignor"></a>RoundRobinAssignor</h5><p>RoundRobin基于轮询算法，对应的实现类是 org.apache.kafka.clients.consumer.RoundRobinAssignor</p><ol><li>将所有主题的分区组成TopicAndPartition列表</li><li>对TopicAndPartition列表按照hashCode进行排序某个topic</li><li>最后通过轮询算法来分配 partition 给到各个消费者</li></ol><p>轮询分区分为如下两种情况：</p><ul><li>同一个 Consumer Group 内 Consumer  订阅信息相同</li><li>同一个 Consumer Group 内 Consumer  订阅信息不相同</li></ul><h6 id="订阅信息相同"><a href="#订阅信息相同" class="headerlink" title="订阅信息相同"></a>订阅信息相同</h6><p>如果同一消费组内，所有的消费者订阅的消息都是相同的，那么 RoundRobin 策略的分区分配会是均匀的。</p><p>例如同一消费者组中，有 3 个消费者C0、C1和C2，都订阅了 2 个主题 t0 和 t1，并且每个主题都有 3 个分区(p0、p1、p2)，那么所订阅的所以分区可以标识为t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。</p><p>最终分区分配结果如下</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C0</td><td>消费 t0p0、t1p0 分区</td></tr><tr><td>C1</td><td>消费 t0p1、t1p1 分区</td></tr><tr><td>C2</td><td>消费 t0p2、t1p2 分区</td></tr></tbody></table><h5 id="订阅信息不相同"><a href="#订阅信息不相同" class="headerlink" title="订阅信息不相同"></a>订阅信息不相同</h5><p>同一消费者组内，所订阅的消息是不相同的，那么分区分配就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个 topic，那么在分配分区的时候，此消费者将不会分配到这个 topic 的任何分区。</p><p>例如同一消费者组中有3个消费者C0、C1、C2，他们共订阅了 3 个主题t0、t1、t2，这 3 个主题分别有 1、2、3 个分区(即t0有1个分区(p0)，t1有2个分区(p0、p1)，t2有3个分区(p0、p1、p2))，即整个消费者所订阅的所有分区可以标识为 t0p0、t1p0、t1p1、t2p0、t2p1、t2p2。然后消费者 C0 订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2</p><p>最终分区分配结果如下</p><table><thead><tr><th>消费者</th><th>消费的分区</th></tr></thead><tbody><tr><td>C0</td><td>消费 t0p0 分区</td></tr><tr><td>C1</td><td>消费 t1p0 分区</td></tr><tr><td>C2</td><td>消费 t1p1、 t2p0、 t2p1、 t2p2 分区</td></tr></tbody></table><hr><p>参考链接</p><ul><li><a href="https://www.jianshu.com/p/99b4187a994d" target="_blank" rel="noopener">Kafka分区策略</a></li><li><a href="https://mp.weixin.qq.com/s/st-7k7WH5pvLZwA_o9jPpw" target="_blank" rel="noopener">六问 Kafka 为啥那么牛！</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 分区策略
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 分区迁移</title>
    <link href="http://yoursite.com/2021/02/14/kafka-partition-migration/"/>
    <id>http://yoursite.com/2021/02/14/kafka-partition-migration/</id>
    <published>2021-02-13T16:00:00.000Z</published>
    <updated>2021-03-10T14:50:00.136Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka集群扩容后将数据量大Topic迁移到新的Kafka节点上</p><hr><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>最近因数据量上涨，对Kafka集群进行扩容后，需将Topic量大的迁移到新Kafka节点上，缓解集群压力。</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>Kafka系统提供了一个分区重新分配工具（kafka-reassign-partitions.sh），该工具可用于在Broker之间迁移分区。</p><h5 id="生成待迁移topic的json"><a href="#生成待迁移topic的json" class="headerlink" title="生成待迁移topic的json"></a>生成待迁移topic的json</h5><p>新建文件topics-to-move.json，包含要迁移到Topic 列表。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat topic-to-move.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;topics&quot;: [&#123;&quot;topic&quot;: &quot;ke01&quot;&#125;,&#123;&quot;topic&quot;: &quot;ke02&quot;&#125;],</span><br><span class="line">    &quot;version&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="generate生成迁移计划"><a href="#generate生成迁移计划" class="headerlink" title="generate生成迁移计划"></a>generate生成迁移计划</h5><p>需要指定topics-to-move.json 文件和迁移目标节点的broker id</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist --topics-to-move-json-file topics-to-move.json --broker-list &quot;$brokerlist&quot; --generate &gt; generate.json</span><br></pre></td></tr></table></figure><p>查看generate.json文件结果类似如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Current partition replica assignment</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[61,62]&#125;,&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[62,61]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[140,141]&#125;,&#123;&quot;topic&quot;:&quot;sdk_counters&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[141,140]&#125;]&#125;</span><br></pre></td></tr></table></figure><p>将Current partition replica assignment 的内容保存到rollback-cluster-reassignment.json，用于回滚操作。</p><p>将Proposed partition reassignment configuration 的内容保存到expand-cluster-reassignment.json，用于执行迁移操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat generate.json  |grep -A1 &quot;Proposed partition reassignment configuration&quot; |tail -1 &gt; expand-cluster-reassignment.json</span><br></pre></td></tr></table></figure><h5 id="迁移执行generate-prop-json"><a href="#迁移执行generate-prop-json" class="headerlink" title="迁移执行generate_prop.json"></a>迁移执行generate_prop.json</h5><p>限制带宽大小为500Mb/s</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist --reassignment-json-file generate_prop.json --execute --throttle 50000000</span><br></pre></td></tr></table></figure><p>迁移操作会将指定Topic 的数据文件移动到新的节点目录下，这个过程可能需要等待很长时间，视Topic 的数据量而定。</p><p>可以运行以下命令查看执行状态。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-reassign-partitions.sh --zookeeper $zklist  --reassignment-json-file generate_prop.json --verify</span><br></pre></td></tr></table></figure><p>状态有两种，in progress 表示正在迁移，completed successlly 表示已经成功完成迁移。迁移完成后，原先的节点下将不存在该Topic 的数据文件。</p><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>如果要迁移的Topic 有大量数据（Topic 默认保留1天的数据），可以在迁移之前临时动态地调整retention.ms 来减少数据。</p><hr><p>参考链接</p><ul><li><a href="https://www.jianshu.com/p/626b147821cd" target="_blank" rel="noopener">Kafka扩容节点和分区迁移</a></li><li><a href="https://www.cnblogs.com/smartloli/p/10551165.html" target="_blank" rel="noopener">Kafka数据迁移</a></li><li><a href="https://objcoding.com/2019/10/26/kafka-expansion/" target="_blank" rel="noopener">记一次Kafka集群线上扩容</a></li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 分区迁移
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>滴滴开源 Logi-KafkaManager</title>
    <link href="http://yoursite.com/2021/02/11/didi-Logi-KafkaManager/"/>
    <id>http://yoursite.com/2021/02/11/didi-Logi-KafkaManager/</id>
    <published>2021-02-10T16:00:00.000Z</published>
    <updated>2021-02-10T16:25:22.457Z</updated>
    
    <content type="html"><![CDATA[<p>LogI-KafkaManager脱胎于滴滴内部多年的Kafka运营实践经验，是面向Kafka用户、Kafka运维人员打造的共享多租户Kafka云平台</p><hr><h4 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h4><p>文章介绍：</p><ul><li><a href="https://mp.weixin.qq.com/s/ebUY-9WCt05qDX4jet6Enw" target="_blank" rel="noopener">滴滴Logi-KafkaManager开源之路：一站式Kafka集群指标监控与运维管控平台</a></li><li><a href="https://mp.weixin.qq.com/s/JmVrypgR5mI8GH7BvgEs_g" target="_blank" rel="noopener">滴滴开源Logi-KafkaManager 一站式Kafka监控与管控平台</a></li></ul><p>GitHub地址：<a href="https://github.com/didi/Logi-KafkaManager" target="_blank" rel="noopener">Logi-KafkaManager</a></p>]]></content>
    
    <summary type="html">
    
      一站式Kafka集群指标监控与运维管控平台
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka 文件存储机制</title>
    <link href="http://yoursite.com/2021/02/10/Kafka-storage-mechanism/"/>
    <id>http://yoursite.com/2021/02/10/Kafka-storage-mechanism/</id>
    <published>2021-02-09T16:00:00.000Z</published>
    <updated>2021-02-14T08:34:12.584Z</updated>
    
    <content type="html"><![CDATA[<p>从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。</p><hr><h4 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h4><p>在美团上看到一个介绍Kafka 文件存储机制的文章感觉挺好的，适合新手阅读。</p><p>详细见<a href="https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html" target="_blank" rel="noopener">《Kafka文件存储机制那些事》</a></p><blockquote><p>PS：链接中说segment文件命名规则是19位数字字符长度，本人查看已部署的kafka服务确认为20个字符长度</p></blockquote><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>Kafka高效文件存储设计特点</p><ul><li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li><li>通过索引信息可以快速定位message和确定response的最大大小。</li><li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li><li>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</li></ul>]]></content>
    
    <summary type="html">
    
      Kafka 文件存储机制
    
    </summary>
    
    
      <category term="Kafka" scheme="http://yoursite.com/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Shell 2&gt;&amp;1 用法</title>
    <link href="http://yoursite.com/2021/01/25/Linux-Shell-redirection/"/>
    <id>http://yoursite.com/2021/01/25/Linux-Shell-redirection/</id>
    <published>2021-01-24T16:00:00.000Z</published>
    <updated>2021-01-26T14:10:05.086Z</updated>
    
    <content type="html"><![CDATA[<p>Shell 2&gt;&amp;1 用法</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>在Shell脚本中，默认情况下，总是有三个文件处于打开状态，标准输入(键盘输入)、标准输出（输出到屏幕）、标准错误（也是输出到屏幕），它们分别对应的文件描述符是0，1，2 。</p><p>&gt;  默认为标准输出重定向，与 1&gt; 相同</p><p>2&gt;&amp;1  意思是把 标准错误输出 重定向到 标准输出</p><p>同理 1&gt;&amp;2 意思是将标准输出 重定向到 标准错误输出</p><h4 id="运用"><a href="#运用" class="headerlink" title="运用"></a>运用</h4><p>遇到一个问题需要批量扫描机器的JDK版本是不是为1.8的，遇到无法在’java -version’输出中使用grep和awk的情况</p><p>出现这样的问题，主要就是这些消息默认情况下转到stderr，而不是stdout。所有需要先重定向到stdout，然后才能进行此类操作。</p><p>将stderr重定向到stdout</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">java_check&#x3D;$(java -version 2&gt;&amp;1)</span><br><span class="line"></span><br><span class="line">echo $java_check | grep 1.8.0_265-b01</span><br><span class="line">OpenJDK Runtime Environment Corretto-8.265.01.1 (build 1.8.0_265-b01)</span><br></pre></td></tr></table></figure><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>&amp;&gt;file  意思是把标准输出和标准错误输出都重定向到文件file中</p><p>/dev/null是一个文件，这个文件比较特殊，所有传给它的东西它都丢弃掉</p><hr><p>参考链接</p><ul><li><a href="https://blog.csdn.net/u011630575/article/details/52151995" target="_blank" rel="noopener">Shell重定向 ＆&gt;file、2&gt;&amp;1、1&gt;&amp;2 、/dev/null的区别</a></li><li><a href="https://blog.csdn.net/ITqingliang/article/details/103733038" target="_blank" rel="noopener">不能在’java -version’输出中grep和awk</a></li></ul>]]></content>
    
    <summary type="html">
    
      Shell 2&gt;&amp;1 用法
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 光标快速移动的快捷键</title>
    <link href="http://yoursite.com/2021/01/21/Linux-shortcut-keys/"/>
    <id>http://yoursite.com/2021/01/21/Linux-shortcut-keys/</id>
    <published>2021-01-20T16:00:00.000Z</published>
    <updated>2021-01-21T14:11:14.101Z</updated>
    
    <content type="html"><![CDATA[<p>Linux 快速移动光标的快捷键</p><hr><h4 id="光标快速切换到行尾行首"><a href="#光标快速切换到行尾行首" class="headerlink" title="光标快速切换到行尾行首"></a>光标快速切换到行尾行首</h4><p>ctrl+a 行首<br>ctrl+e 行尾</p><h4 id="删除至行尾"><a href="#删除至行尾" class="headerlink" title="删除至行尾"></a>删除至行尾</h4><p>ctrl+k</p><h4 id="左-右移动一个单词"><a href="#左-右移动一个单词" class="headerlink" title="左|右移动一个单词"></a>左|右移动一个单词</h4><p>Esc b 左移一个单词[back]<br>Esc f 右移一个单词[forward]</p><p><strong>注意：每次按下快捷键，需抬起后再按下快捷键，方可多次移动单词</strong></p><hr><p>参考链接</p><ul><li><a href="https://blog.csdn.net/u010865136/article/details/95628409" target="_blank" rel="noopener">Linux命令行——光标快速移动的快捷键</a></li></ul>]]></content>
    
    <summary type="html">
    
      Linux 命令行执行命令时，快速移动光标可节省不少时间
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux Pmap 命令</title>
    <link href="http://yoursite.com/2021/01/08/pmap/"/>
    <id>http://yoursite.com/2021/01/08/pmap/</id>
    <published>2021-01-07T16:00:00.000Z</published>
    <updated>2021-01-08T13:36:46.714Z</updated>
    
    <content type="html"><![CDATA[<p>pmap 命令用于显示一个或多个进程的内存状态</p><hr><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>pmap能更详细的查看进程内存映射情况。</p><p>pmap命令输出的内容来自于/proc/{pid}/maps和/proc/{pid}/smaps这两个文件，第一个文件包含了每段的一个大概描述，而后一个文件包含了更详细的信息。</p><h4 id="选项"><a href="#选项" class="headerlink" title="选项"></a>选项</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Usage: pmap [options] pid [pid ...]</span><br><span class="line">Options:</span><br><span class="line"> -x, --extended       show details  显示扩展格式</span><br><span class="line"> -X             show even more details</span><br><span class="line">      WARNING: format changes according to &#x2F;proc&#x2F;PID&#x2F;smaps</span><br><span class="line"> -XX             show everything the kernel provides</span><br><span class="line"> -c, --read-rc        read the default rc</span><br><span class="line"> -C, --read-rc-from&#x3D;&lt;file&gt;  read the rc from file</span><br><span class="line"> -n, --create-rc       create new default rc</span><br><span class="line"> -N, --create-rc-to&#x3D;&lt;file&gt;  create new rc to file</span><br><span class="line">      NOTE: pid arguments are not allowed with -n, -N</span><br><span class="line"> -d, --device        show the device format  显示设备格式</span><br><span class="line"> -q, --quiet         do not display header and footer</span><br><span class="line"> -p, --show-path       show path in the mapping</span><br><span class="line"> -A, --range&#x3D;&lt;low&gt;[,&lt;high&gt;] limit results to the given range</span><br><span class="line"> -h, --help   display this help and exit -V, --version output version information and exit</span><br><span class="line">For more details see pmap(1).</span><br></pre></td></tr></table></figure><h4 id="扩展和设备格式"><a href="#扩展和设备格式" class="headerlink" title="扩展和设备格式"></a>扩展和设备格式</h4><p>Address: 映像起始地址<br>Kbytes: 映像大小<br>RSS: 驻留集大小<br>Dirty: 脏页大小<br>Mode: permissions on map 映像权限: r=read, w=write, x=execute, s=shared, p=private (copy on write)<br>Mapping: 映像支持文件；[anon]为已分配内存，可以理解为匿名块；[stack]为程序堆栈<br>Offset: 文件偏移<br>Device: 设备名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@C44 ~]# pmap -d 1</span><br><span class="line">1:  init [5]          </span><br><span class="line">Address  Kbytes Mode Offset      Device  Mapping</span><br><span class="line">00934000   88 r-x-- 0000000000000000 008:00005 ld-2.3.4.so</span><br><span class="line">0094a000    4 r---- 0000000000015000 008:00005 ld-2.3.4.so</span><br><span class="line">0094b000    4 rw--- 0000000000016000 008:00005 ld-2.3.4.so</span><br><span class="line">0094e000  1188 r-x-- 0000000000000000 008:00005 libc-2.3.4.so</span><br><span class="line">00a77000    8 r---- 0000000000129000 008:00005 libc-2.3.4.so</span><br><span class="line">00a79000    8 rw--- 000000000012b000 008:00005 libc-2.3.4.so</span><br><span class="line">00a7b000    8 rw--- 0000000000a7b000 000:00000  [ anon ]</span><br><span class="line">00a85000   52 r-x-- 0000000000000000 008:00005 libsepol.so.1</span><br><span class="line">00a92000    4 rw--- 000000000000c000 008:00005 libsepol.so.1</span><br><span class="line">00a93000   32 rw--- 0000000000a93000 000:00000  [ anon ]</span><br><span class="line">00d9d000   52 r-x-- 0000000000000000 008:00005 libselinux.so.1</span><br><span class="line">00daa000    4 rw--- 000000000000d000 008:00005 libselinux.so.1</span><br><span class="line">08048000   28 r-x-- 0000000000000000 008:00005 init</span><br><span class="line">0804f000    4 rw--- 0000000000007000 008:00005 init</span><br><span class="line">084e1000   132 rw--- 00000000084e1000 000:00000  [ anon ]</span><br><span class="line">b7f5d000    8 rw--- 00000000b7f5d000 000:00000  [ anon ]</span><br><span class="line">bffee000   72 rw--- 00000000bffee000 000:00000  [ stack ]</span><br><span class="line">ffffe000    4 ----- 0000000000000000 000:00000  [ anon ]</span><br><span class="line">mapped: 1700K  writeable&#x2F;private: 276K  shared: 0K</span><br></pre></td></tr></table></figure><p>最后一行的值</p><p>mapped 表示该进程映射的虚拟地址空间大小，也就是该进程预先分配的虚拟内存大小，即ps出的vsz</p><p>writeable/private  表示进程所占用的私有地址空间大小，也就是该进程实际使用的内存大小</p><p>shared 表示进程和其他进程共享的内存大小</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@info ~]# pmap -x 1013</span><br><span class="line">1013: &#x2F;usr&#x2F;sbin&#x2F;sshd</span><br><span class="line">Address Kbytes RSS Dirty Mode Mapping</span><br><span class="line">00110000 1480 92 0 r-x- libcrypto.so.1.0.0</span><br><span class="line">00282000 80 80 80 rw-- libcrypto.so.1.0.0</span><br><span class="line">00296000 12 8 4 rw-- [ anon ]</span><br><span class="line">00299000 36 0 0 r-x- libkrb5support.so.0.1</span><br><span class="line">002a2000 4 4 4 rw-- libkrb5support.so.0.1</span><br><span class="line">002a3000 16 0 0 r-x- libplc4.so</span><br><span class="line">002a7000 4 4 4 rw-- libplc4.so</span><br><span class="line">002ab000 88 4 0 r-x- libaudit.so.1.0.0</span><br><span class="line">002c1000 4 4 4 r--- libaudit.so.1.0.0</span><br><span class="line">002c2000 4 4 4 rw-- libaudit.so.1.0.0</span><br><span class="line">002c3000 216 4 0 r-x- libgssapi_krb5.so.2.2</span><br><span class="line">002f9000 4 4 4 rw-- libgssapi_krb5.so.2.2</span><br><span class="line">002fa000 808 4 0 r-x- libkrb5.so.3.3</span><br><span class="line">003c4000 24 24 24 rw-- libkrb5.so.3.3</span><br><span class="line">003ca000 152 4 0 r-x- libk5crypto.so.3.1</span><br><span class="line">003f0000 4 4 4 rw-- libk5crypto.so.3.1</span><br><span class="line">003f1000 92 0 0 r-x- libnssutil3.so</span><br><span class="line">00408000 12 12 12 rw-- libnssutil3.so</span><br><span class="line">0040b000 12 0 0 r-x- libplds4.so</span><br><span class="line">0040e000 4 4 4 rw-- libplds4.so</span><br><span class="line"> </span><br><span class="line">--- --- --- --- ---</span><br><span class="line">total kB 8232 - - -</span><br></pre></td></tr></table></figure><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>/proc/pid/smaps各字段含义</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">01785000-017a6000 rw-p 00000000 00:00 0                                  [heap]</span><br><span class="line">Size:                132 kB</span><br><span class="line">Rss:                  12 kB</span><br><span class="line">Pss:                  12 kB</span><br><span class="line">Shared_Clean:          0 kB</span><br><span class="line">Shared_Dirty:          0 kB</span><br><span class="line">Private_Clean:         0 kB</span><br><span class="line">Private_Dirty:        12 kB</span><br><span class="line">Referenced:           12 kB</span><br><span class="line">Anonymous:            12 kB</span><br><span class="line">AnonHugePages:         0 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">KernelPageSize:        4 kB</span><br><span class="line">MMUPageSize:           4 kB</span><br></pre></td></tr></table></figure><p>见<a href="https://blog.csdn.net/u010902721/article/details/46446031" target="_blank" rel="noopener">linux /proc/pid/smaps各字段含义</a></p><hr><p>参考链接</p><ul><li><a href="https://segmentfault.com/a/1190000008125059" target="_blank" rel="noopener">Linux进程的内存使用情况</a></li><li><a href="https://www.jb51.net/article/124947.htm" target="_blank" rel="noopener">Linux性能测试 pmap命令详解</a></li></ul>]]></content>
    
    <summary type="html">
    
      pmap 命令用于显示一个或多个进程的内存状态
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
</feed>
